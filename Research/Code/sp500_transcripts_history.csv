company,quarter,year,title,url,content
Apple Inc. (AAPL),Q1,2025,Apple (AAPL) Q1 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/01/30/apple-aapl-q1-2025-earnings-call-transcript/,"Apple
(
AAPL
+0.28%
)
Q1 2025 Earnings Call
Jan 30, 2025
,
5:00 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Suhasini Chandramouli
--
Director, Investor Relations
Good afternoon, and welcome to the Apple Q1 fiscal year 2025 earnings conference call. My name is Suhasini Chandramouli, Director of investor relations. Today's call is being recorded. Speaking first today are Apple CEO, Tim Cook; and he'll be followed by CFO, Kevan Parekh.
After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook, including the potential impact of macroeconomic conditions on the company's business and results of operations. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast. For more information, please refer to the risk factors discussed in Apple's most recently filed annual report on Form 10-K and the Form 8-K filed with the SEC today, along with the associated press release.
Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.
Timothy Donald Cook
--
Chief Executive Officer
Thank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Before I talk about our results, I'd like to take a moment to acknowledge the devastating wildfires that impacted the Los Angeles area this month. From our retail teams to Apple TV+, Apple Music, Fitness+, Beats, and more, L.A.
is home to many of our team members. Our thoughts are with everyone who is beginning the road to recovery. For our part, we are contributing to the relief efforts, and we will continue to support our teams and the local community. Now, turning to the quarter.
Today, Apple is reporting revenue of $124.3 billion for the December quarter, up 4% from a year ago and an all-time record. EPS also set an all-time record of $2.40, 10% higher year over year. We achieved all-time revenue records across the majority of the countries and regions we track, including the Americas, Europe, Japan, and the rest of Asia Pacific. We also continue to see momentum in emerging markets, setting all-time revenue records in a number of markets, including Latin America, the Middle East, and South Asia, among others.
In services, we achieved an all-time revenue record. And in the past year, we've seen nearly $100 billion in revenue from our services business. I'm also pleased to announce that we reached a new record for our install base with over 2.35 billion active devices. In October, we released the first set of Apple Intelligence features in U.S.
English for iPhone, iPad, and Mac, and we rolled out more features and expanded to more countries in December. Now, users can discover the benefits of these new features in the things they do every day. They can use Writing Tools to help find just the right words, create fun and unique images with Image Playground and Genmoji, handle daily tasks and seek out information with a more natural and conversational Siri, create movies of their memories with a simple prompt, and touch up their photos with Clean Up. We introduce visual intelligence with camera control to help users instantly learn about their surroundings.
Users can also seamlessly access ChatGPT across iOS, iPadOS, and macOS. And we were excited to recently begin our international expansion with Apple Intelligence now available in Australia, Canada, New Zealand, South Africa, and the U.K. We're working hard to take Apple Intelligence even further. In April, we're bringing Apple Intelligence to more languages, including French, German, Italian, Portuguese, Spanish, Japanese, Korean, and simplified Chinese, as well as localized English to Singapore and India.
And we'll continue to roll out more features in the future, including an even more capable Siri. Apple Intelligence builds on years of innovations we've made across hardware and software to transform how users experience our products. Apple Intelligence also empowers users by delivering personal context that's relevant to them. And importantly, Apple Intelligence is a breakthrough for privacy and AI with innovations like private cloud compute, which extends the industry-leading security and privacy of Apple devices into the cloud.
Apple Intelligence opens up an exciting new frontier and is already elevating experiences across iPhone, iPad, and Mac. We're going to keep investing in innovation and in transformative tools that help users in their everyday lives. Let me now turn to our results for the quarter, starting with iPhone. iPhone revenue came in at $69.1 billion, reaching all-time iPhone revenue records in dozens of markets and regions.
Our iPhone 16 lineup takes the smartphone experience to the next level in so many ways, and Apple intelligence is one of many reasons why customers are excited. With the A18 powered iPhone 16 and iPhone 16 Plus, users are getting a big boost in battery life and incredible camera experiences with camera control. Our amazingly powerful iPhone 16 Pro models go even further with larger-than-ever displays and a pro camera system so advanced, it can turn moments into masterpieces. In Mac, revenue was $9 billion for the December quarter, 16% higher year over year, driven by significant excitement around the world for our latest Mac lineup.
The Mac is more than just a powerful tool. It's a launch pad to enable users to bring their best ideas and boldest creations to life. And there are so many reasons to choose Mac, from the breathtaking performance of the M4 family of chips, to the groundbreaking and growing capabilities of Apple Intelligence. Every product in the Mac lineup offers something extraordinary, whether that's the super-portable MacBook Air, the powerhouse MacBook Pro, the world's best all-in-one iMac, or the small wonder that is the Mac Mini, which is not only stunningly capable but is our first carbon-neutral Mac.
All of this is enabled by the unparalleled power of Apple silicon. iPad revenue was $8.1 billion, up 15% from a year ago, driven by strong interest for our latest products. We love hearing from customers who are discovering for the first time the versatility of iPad, from the ultra portable iPad Mini built from the ground up for Apple intelligence, to the powerful M4 iPad Pro in a stunningly thin and light design. iPad is there for our users whenever they need it and wherever they go, and we are pleased to see so much excitement and enthusiasm for our lineup.
Wearables, home, and accessories revenue came in at $11.7 billion. With its most advanced display yet and a thinner, more comfortable design, the all-new Apple Watch Series 10 is the perfect companion to help users pursue their health and fitness goals this year. From the powerful Vitals app to more customizable activity rings, users have an ever-increasing set of innovative health tools at their fingertips in watchOS 11. Health innovation has long been a focus for us, and we're committed to continuing to advance this work because we know how much it matters to our users.
We've introduced new hearing health features on AirPods Pro 2. And new sleep apnea notifications on Apple Watch are also helping users learn of a potentially serious condition that's thought to affect up to a billion people worldwide. During the quarter, we also brought Apple Vision Pro to even more countries, enabling more customers to discover the magic of spatial computing. Users are enjoying incredible immersive entertainment experiences and powerful new features and enhancements to Mac virtual display.
Vision Pro is also supercharging the creative process, and the incredibly talented director, Jon M. Chu, recently shared how its extraordinary capabilities helped him bring the movie ""Wicked"" to life. Turning to services, we set an all-time revenue record of $26.3 billion for the December quarter, growing 14% from a year ago. We set all-time records in the Americas, Europe, and rest of Asia Pacific, and a December quarter record in Japan.
Five years since launch, Apple TV+ continues to be home to incredible storytelling that viewers love. There's nothing quite like the anticipation that comes when a fan favorite returns, and we were thrilled to debut the second season of ""Severance"" earlier this month. We have so much in store for our subscribers this year with new shows like ""The Studio"" and ""Your Friends and Neighbors."" And we can't wait for the premiere of ""Formula 1"" starring Brad Pitt on June 27th, which will take viewers inside the sport in a truly unprecedented way. We're excited that Apple TV Plus continues to draw attention and accolades.
Today, Apple TV+ productions have earned more than 2,500 nominations and 538 wins. During the quarter, we were also excited to launch a new Find My service that can help our users when they lose their luggage. For the first time, if you put an AirTag in your suitcase, you'll be able to share its location information with many major airlines so they can quickly track down your bags if they get lost. Turning to retail, our teams went above and beyond to help customers find the perfect gift throughout the holiday season.
We also celebrated openings of new stores in China, Spain, and the U.S. And we were excited to announce plans to connect with even more customers this year by adding a fifth store in the UAE and bringing our online store to Saudi Arabia this summer. We can't wait to welcome customers to the first of several flagship store locations in Saudi Arabia that were opening beginning in 2026. I just had the chance to visit both countries last month, and I had a great time meeting with customers and team members.
There's an incredible energy and passion for technology in these growing markets. Every day, I get deeply moving notes about the many ways our technology is enriching our users' lives. I recently got a note from a customer who put his watch on his father's wrist when he feared something was wrong with him. The watch alerted them that the father was in AFib and they were able to get him to the hospital for potentially life-saving treatment.
Another user put his new watch on for the first time and within 15 minutes was notified of a low heart rate that led to a necessary pacemaker. And there are so many touching notes around the profound impact of our new hearing health feature, like a recent user who told me it had changed her life, allowing her to take part in conversations with her children and grandchildren. These are the kind of stories that remind us of how profoundly important our work is, and it drives us to innovate each and every day. At Apple, the future is full of promise and potential.
We're always searching across a world of possibilities, finding those places where we can do the most good and putting all of our energy and ingenuity into making something special. With that, I'll turn it over to Kevan.
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Thanks, Tim, and good afternoon, everyone. I'm going to cover the results for the first quarter of our fiscal year. We are very pleased to report an all-time high for revenue, with December quarter revenue of $124.3 billion, up 4% year over year. We achieved all-time revenue records in the Americas, Europe, Japan, and rest of Asia Pacific and grew in the vast majority of markets we track.
Products revenue was $98 billion, up 2% year over year, driven by growth from iPad and Mac. Thanks to our incredible customer satisfaction and strong loyalty, our install base of active devices reached an all-time high across all products and geographic segments and is now over 2.35 billion active devices. Services revenue reached an all-time record of $26.3 billion, up 14% year over year. We grew in every geographic segment and achieved all-time records in both developed and emerging markets.
Company gross margin was 46.9% at the high end of our guidance range and up 70 basis points sequentially, primarily driven by favorable mix. Products gross margin was 39.3%, up 300 basis points sequentially, primarily driven by favorable mix and leverage. Services gross margin was 75%, up 100 basis points sequentially, primarily driven by mix. Operating expenses of $15.4 billion landed at the midpoint of our guidance range and up 7% year over year.
This strong business performance resulted in all-time records for both net income at $36.3 billion and diluted earnings per share of $2.40, up 10% year over year. Operating cashflow is also strong at $29.9 billion, which included the impact of the $11.9 billion we paid during the quarter in connection with the state aid decision. Now, I'm going to provide some more details for each of our revenue categories. iPhone revenue was $69.1 billion, roughly flat to the prior year.
We grew in the majority of markets we track and reached all-time revenue records in several developed markets, including Canada, Western Europe, and Japan, and in emerging markets like Latin America, the Middle East, and South Asia. The iPhone active install base grew to an all-time high in total in an average geographic segment. We also set an all-time record for upgraders. According to a recent survey from Kantar, during the December quarter, iPhone was a top-selling model in the U.S., urban China, India, the U.K., France, Australia, and Japan.
We continue to see high levels of customer satisfaction in the U.S. at 96% as measured by 451 research. Mac generated $9 billion in revenue, up 16% year over year. We saw strength across our lineup, from the new Mac mini to the latest MacBook Air and MacBook Pro models.
This incredible performance was broad-based with double-digit growth in every geographic segment. With our latest advances in Apple silicon and our fastest neural engine ever, customers are able to take advantage of the full capabilities of AI and Mac. The Mac install base reached an all-time high, and we saw a double-digit growth for both upgraders and customers new to the Mac. Additionally, customer satisfaction in the U.S.
was recently measured at 94%. iPad revenue was $8.1 billion, up 15% year over year, driven by the new iPad mini and latest iPad Air. The iPad install base reached another all-time high, and over half of the customers who purchased an iPad during the quarter were new to the product. Customer satisfaction was at 96% in the U.S.
based on the latest reports from 451 Research. Wearables, home, and accessories revenue was $11.7 billion, down 2% year over year. Customers are excited about the new AirPods 4 and the latest hearing health features in AirPods Pro 2. On watch, although we faced a difficult compare against the Watch Ultra 2 launch last year, the Apple Watch install base reached a new all-time high, with over half of customers purchasing an Apple Watch during the quarter being new to the product.
Customer satisfaction for watch in the U.S. was reported at 94%. Our services revenue reached an all-time high of $26.3 billion, up 14% year over year. Services continues to see strong momentum, and the growth of our install base of active devices gives us great opportunities for the future.
We also see increased customer engagement with our services offerings. Both transacting and paid accounts reached new all-time highs with paid accounts growing double digits year over year. Paid subscriptions also grew double digits. We have well over a billion paid subscriptions across the services on our platform.
We remain focused on improving the breadth and quality of our services offerings, from new games on Apple Arcade to exciting new programming on Fitness+, and the continued expansion of features like Tap to Pay now live in 20 markets. Turning to enterprise, we have seen businesses continue to expand their deployments of our products and services. Deutsche Bank launched its Mac as Choice program for the developers and also issued the latest MacBook Air as a standard computer for their entire mortgage lending division. And we're excited to see leading enterprises, such as SAP leverage Apple Intelligence in the U.S.
with features like writing tools, summarize, and priority notifications to enhance both their employee and customer experiences. We also see strong demand in our emerging markets. For example, Zomato, a leading food ordering and delivery company in India, has deployed thousands of Macs across their workforce to foster innovation. And Vision Pro continues to see more use cases in enterprise with Cisco's new spatial meetings, delivering a fully immersive video conferencing experience for remote collaboration and learning.
Let me quickly summarize our cash position and capital return program. We ended the quarter with $141 billion in cash and marketable securities. We repaid $1 billion in maturing debt and decreased commercial paper by $8 billion, resulting in $97 billion in total debt. Therefore, net cash at the end of the quarter was $45 billion.
During the quarter, we returned over $30 billion to shareholders. This included $3.9 billion in dividends and equivalents and $23.3 billion through open market repurchases of 100 million Apple shares. As usual, we will provide an update to our capital return program when we report results for the March quarter. As we move ahead into the March quarter, I'd like to review our outlook, which includes the types of forward-looking information that Suhasini referred to at the beginning of the call.
The color we're providing today assumes that the macroeconomic outlook doesn't worsen from what we're projecting today for the current quarter. As the dollar strengthens significantly, we expect foreign exchange to be a headwind and to have a negative impact on revenue of about 2.5 percentage points on a year-over-year basis. Despite that headwind, we expect our March quarter total company revenue to grow low to mid single digits year over year. We expect services revenue to grow low double digits year over year.
When you remove the negative impact of the foreign exchange headwinds I described earlier, the year-over-year growth rate would be comparable to that of the December quarter. We expect gross margin to be between 46.5% and 47.5%. We expect operating expenses to be between $15.1 billion and $15.3 billion. We expect OI&E to be around negative $300 million, excluding any potential impact from the mark-to-market of minority investments and our tax rate to be around 16%.
Finally, today, our board of directors has declared a cash dividend of $0.25 per share of common stock payable on February 13th, 2025 to shareholders of record as of February 10, 2025. With that, let's open to call the questions.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Kevan. We ask that you limit yourself to two questions. Operator, may we have the first question, please?
Questions & Answers:
Operator
Certainly. We will go ahead and take our first question from Erik Woodring with Morgan Stanley. Please go ahead.
Erik Woodring
--
Analyst
Great, guys. Thanks so much for taking my questions. You know, Tim, in your prepared remarks, you had noted that iPhone 16 models are selling better in markets where Apple Intelligence is available. And I'm just wondering if you could double-click on that comment a bit and share any other details you believe could, you know, better help us understand how Apple Intelligence is really impacting iPhone demand and/or what features you find that users are using most often already.
And then, I just have a quick follow-up. Thank you.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, Erik. Hi, it's Tim. The -- we did see that the markets where we had rolled out Apple Intelligence that the year over year performance on the iPhone 16 family was stronger than those where Apple Intelligence was not available. In terms of the features that people are using, they're using all of the ones that I'd referenced in my opening comments, from Writing Tools to Image Playground and Genmoji, to visual intelligence and more.
And so, we see all of those being used. The Clean Up is another one that is popular, and people love seeing that when demoed in the stores as well. We only had two, two and a half weeks or so during the December quarter of the second release of 18.2. And then, only had the U.K.
and the other English language countries for the two and a half weeks. And so, we've got, you know, just the early indications at the moment. But we were glad --
Erik Woodring
--
Analyst
OK. That's really helpful.
Timothy Donald Cook
--
Chief Executive Officer
Yeah. Go ahead.
Erik Woodring
--
Analyst
OK. Thank you for that, Tim. It's helpful. And then, you know, if we just touch on China, obviously, in the news fairly frequently.
If we set aside China macro, which I understand is still challenging, can you maybe talk about the headwinds that Apple faces, whether that's, you know, shifting preferences for Western technology brands in favor of domestic vendors, or is this just a function of not necessarily having Apple Intelligence available with the iPhone 16, which is, you know, not necessarily helping replacement cycles? Just maybe double-clicking on what you think and what you're hearing in China as a regard -- as it relates to the iPhone. Thanks so much.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, sure. If you look at our greater China revenue for the quarter, we were down 11% year over year. And over half of the decline that we experienced was driven by change in channel inventory from the beginning to the end of the quarter. And, of course, on the Apple Intelligence side, we have not rolled out in China.
And as we just talked about, we did see better results in the markets that we had rolled out in than markets we hadn't rolled out in. And, of course, it's the most competitive market in the world. And so, all of those things are true. In terms of the macro situation, there was a fiscal stimulus or subsidy announced in -- very recently in January that did not affect the December quarter.
There were some provincial subsidies in the December quarter, but the national program was announced, I believe, on January 20th. And it does cover the categories that we have products in from smartphones to tablets and PCs and smartwatches up to a certain maximum price point. And so, we do see fiscal stimulus occurring, and we'll be glad to talk about what that looks like on the next call.
Erik Woodring
--
Analyst
Great. Thanks so much, Tim. Good luck.
Timothy Donald Cook
--
Chief Executive Officer
Thank you.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Erik. Operator, can we have the next question, please?
Operator
Our next question is from Ben Reitzes with Melius. Please go ahead.
Ben Reitzes
--
Analyst
Hey, guys. Thanks a lot for the question. And hey, Tim, wanted to ask you who -- you knew this one was coming, but there's a perception that you're a big beneficiary of lower cost of compute. And I was wondering if you could give your worldly perspective here on the DeepSeek situation and if you are are going to -- if anything's happened that changed your views in terms of a tailwind to margins and your ability to execute even due to the potential for cost to come down due to that development and probably what was going to happen anyway.
But I'd love your perspective on that, and then I have a quick follow-up. Thanks.
Timothy Donald Cook
--
Chief Executive Officer
Sure. In general, I think innovation that drives efficiency is a good thing. And, you know, that's what you see in that model. Our tight integration of silicon and software, I think, will continue to serve us very well.
As you know, we do things on the device, and we do things in the private cloud, and which mimics from an architectural point of view what happens on device. And from a capex point of view, we've always taken a very prudent and deliberate approach to our expenditure, and we continue to leverage a hybrid model, which, I think, continues to serve us well.
Ben Reitzes
--
Analyst
Great. All right. Thanks, Tim. And then, you know, just with regard to, you know, the iPhone trajectory, do you feel like -- I guess, what do -- you know, you obviously don't talk about new products and stuff like that, but do you feel that there's a lot of room for form factor innovation in the future? Or do you feel that the -- you know, that the current lineup kind of shows where you're going? I guess, without pulling punches, wondering if you thought, in terms of the phone innovation, if there's a lot more to come and you could see the kind of current market changing a bit over the next two to three years.
Thanks.
Timothy Donald Cook
--
Chief Executive Officer
I think -- Ben, I think there's a lot more to come, and I could not feel more optimistic about our product pipeline. So, I think there's a lot of innovation left on the smartphone.
Ben Reitzes
--
Analyst
Thanks a lot, Tim.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, thank you.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Ben. Operator, could we have the next question, please?
Operator
Our next question is from Michael Ng with Goldman Sachs. Please go ahead.
Mike Ng
--
Goldman Sachs -- Analyst
Good afternoon. Thank you for the question. I have two as well. First, it was encouraging to hear about the record for iPhone operators, which I think is something you haven't said for about a year now.
I was wondering if you could talk a little bit about what you would attribute this upgrade strength to. Has Apple Intelligence played a role in helping upgrades in the markets that you've launched in? Thanks.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, thank you for the question. If you look at iPhone, we did set an all-time record for upgraders, so we've never seen a higher level of upgraders before. The install base hit a new all-time high as well. And if you look at the 16 compared to the 15 from launch, which occurred, as you know, in September, so this is across now two quarters from September to the end of the December fiscal quarter, the 16 outperformed the 15.
And so, I think you can conclude from that that there are compelling reasons to upgrade. And in the markets where we had launched Apple Intelligence, they outperformed the markets that we did not. So, lots --
Mike Ng
--
Goldman Sachs -- Analyst
Great, thank you, Tim. That's --
Timothy Donald Cook
--
Chief Executive Officer
Yeah, lots of good color there.
Mike Ng
--
Goldman Sachs -- Analyst
Great, thank you, Tim. That's very clear. And then, I had one about the iPad Pro and for the thinner version. I was just wondering if you could talk about that thin form factor for the iPad Pro.
You know, how did it help iPad sales overall? And what did your kind of marketing consumer research tell you about how consumers valued that thin product form factor? Thank you.
Timothy Donald Cook
--
Chief Executive Officer
It's a good question. iPad overall grew 15% for the quarter. And it was more driven by iPad Air and the entry-level iPad than it was the top-level iPad. But overall, we could not be more pleased with the iPad category growing 15%.
It's a great achievement for the quarter. And probably, what is most important is that over half of the sales in the December quarter went to customers who were new to the iPad. So, that tells us that, you know, there's a good amount of customers there to attract.
Mike Ng
--
Goldman Sachs -- Analyst
Thank you very much, Tim.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, thank you.
Suhasini Chandramouli
--
Director, Investor Relations
Thanks, Mike. Operator, could we have the next question, please?
Operator
Our next question is from Amit Daryanani from Evercore. Please go ahead.
Amit Daryanani
--
Analyst
Good afternoon everyone. I have two as well. Maybe to start with, you folks are seeing some very robust growth trends in emerging markets right now for Apple products. Can you just at a high level just talk about the durability of growth that you see in emerging markets? And then, do you think the summation of these emerging markets are starting to get big enough or, perhaps, starting to grow fast enough that it can actually offset some of the China headwinds you're going through?
Timothy Donald Cook
--
Chief Executive Officer
We have great results in a number of emerging markets. And as you know, from past calls, I'm particularly keen on India. India set a December quarter record during the quarter. And we're opening more stores there.
We've announced that we're going to open four new stores there. We also -- the iPhone was the top-selling model in India for the quarter. And it's the second largest smartphone market in the world and the third largest for PCs and tablets, and so there's a huge market. And we have very modest share in these markets, and so I think there's lots of upside there.
And that's just one of the emerging markets.
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
And maybe I'll add, Amit, that in emerging markets, we're also seeing double-digit growth on the install base, both in total and for the iPhone as well, so that's also an encouraging sign.
Amit Daryanani
--
Analyst
Perfect. Thank you. And then, I guess, just a question on gross margins for the March quarter. You folks are guiding gross margins flattish on a sequential basis.
Typically, I think it tends to be guided up a little bit, 50 basis points, so sequentially. Can we just touch on what are the offsets of the puts and takes you see here on gross margin? And, you know, Kevan, maybe you can just talk about is FX having an outside impact in your margin profile as well in March.
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Yes, Amit, let me take that one. You know, as I mentioned in my remarks, we're guiding to 46.5% to 47.5 %. So, we think we're very pleased with that level of guidance. As you mentioned, there's always puts and takes.
We do think there's going to be some FX headwinds, which we talked about, that's going to affect, you know, our revenue growth as well. It'll have an impact here on the margin, a sequential impact on margins. But we think that's going to be offset by, you know, favorable costs and the relative mix of services. We also -- as you know, when we move from Q1 to Q2, especially on the product side, because Q1 is such a large quarter for a products business, we do have, you know, a loss of leverage.
So, there are some puts and takes, and, you know, I think we feel good about the range. We think it's a very, very strong guide for gross margin.
Suhasini Chandramouli
--
Director, Investor Relations
Thanks, Amit. Operator, could we get the next question, please?
Operator
Our next question is from Wamsi Mohan with Bank of America. Please go ahead.
Wamsi Mohan
--
Analyst
Yes, thank you so much. Tim, I want to follow up on your comment about channel inventory in China. I was wondering if you could maybe address more broadly channel inventory across your different product lines and regions. Do you feel they are elevated or out of range in any other regions? And given the clearing event that kind of happened in China, I guess, in the quarter, should we think of a more normal progression quarter on quarter into the March quarter in China in particular? And I have a follow-up.
Timothy Donald Cook
--
Chief Executive Officer
You know, I don't want to project sales for the current quarter by region. But if you look at the channel inventory and look at iPhone in the aggregate, so on a worldwide basis, we're very comfortable with our channel inventory position. In China, my point was that our channel inventory reduced from the beginning of the quarter to the end of the quarter, and that was over half of the reduction in the reported results. If you look -- part of the reason for that is that our sales were a bit higher than we forecasted them to be toward the end of the quarter.
And so, we ended a little leaner than we had expected to.
Wamsi Mohan
--
Analyst
OK. That's very clear. Thank you.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, thank you.
Wamsi Mohan
--
Analyst
And then, maybe as my follow-up, your services growth has been very strong, and I know you've kind of been navigating some pretty challenging regulatory burdens on the business globally. So, how should investors think about maybe either a top line or margin headwind that, let's say, you're currently absorbing in your results that could potentially maybe reverse in a more balanced regulatory environment? Thank you so much.
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Yeah. So, I think, one, I just wanted to kind of reiterate the fact that, you know, our services business had an all-time record for December quarter at 14%. And that was a -- one strength that we saw across all geographic segments and also was very broad-based across all of our services. So, we have, as you know, a very broad services portfolio.
And so we do see, you know, good momentum across the board. And as well, you know, we continue to see, you know, increasing engagement across the customer base, across all of the service offerings, both transacting and paid accounts. We talked about, you know, reaching all-time highs. And we have over now a billion paid subscriptions across the services platform.
Suhasini Chandramouli
--
Director, Investor Relations
All right. Thanks, Wamsi. Operator, could we get the next question, please?
Operator
Our next question is from Samik Chatterjee with JPMorgan. Please go ahead.
Samik Chatterjee
--
Analyst
Hi. Thanks for taking my questions. I guess, for the first one, if I -- I mean, you had a great quarter on Macs and iPads, both. And I'm just curious in terms of if you can help us think about the sustainability of this double-digit growth that you saw in both the product lines.
And more interest also here, we are talking about Apple Intelligence sort of influencing volumes on iPhones, but any thoughts on sort of how -- what does that influence look like in terms of volumes for Macs, for example, where, I think, there's a lot of conversation around AI PCs, how you're thinking about the impact there? And I have a quick follow-up. Thank you.
Timothy Donald Cook
--
Chief Executive Officer
Yeah. If you look at Mac, Mac was up 16%. And on iPad, we were up 15%. The Mac was driven by a very strong uptake on our new products during the quarter and the continued success of the MacBook Air.
And so, as you know, we've launched an M4-based MacBook Pro, an iMac, and a Mac Mini during the quarter. We believe we've got the best AI PC out there for running workloads. The silicon in the Mac is, and it has been for several years now, designed by us and really designed for these workloads. And so, I don't want to project at the category level for the future, but we're incredibly pleased with both the Mac and the iPad for the quarter.
Samik Chatterjee
--
Analyst
And I'm going to use your earlier discussion about India as a strong emerging market to sort of ask you about the supply chain planning there in terms of how much of the supply chain planning that you're doing is more of a reflection of the growth expectations from that market relative to in terms of more diversification of the supply chain. And how should we sort of think about that strategy related to that particular country? Thank you.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, if you look at the manufacturing we do there, we do manufacturing both for the domestic market, and we export. And so, in -- our business needs a certain economies of scale for it to make sense to manufacture in-country. And so, that really means that we're going to be both a use for the domestic market and an export market.
Samik Chatterjee
--
Analyst
OK. Thank you.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, thanks.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Samik. Operator, could we get the next question, please?
Operator
Our next question is from David Vogt with UBS. Please go ahead.
David Vogt
--
Analyst
Great. Thanks guys for taking my question. So, maybe, Tim, this is for you. I'm trying to think about your commentary around Apple Intelligence being sort of a momentum driver for the iPhone business.
But when I think about your kind of framework for the March quarter and if I kind of adjust for channel inventory over the last couple of years, kind of feels like your iPhone revenue for the March quarter is going to be relatively similar to the quarter two years ago and even the quarter last year. So, how do we square kind of the momentum versus kind of the iPhone business effectively really kind of unchanged over the last couple of years? And then, second, when I think about kind of the gross margin profile of the business, you know, obviously, it's done a great job in taking gross margins up. Where do you think we sit in terms of on the services side at least where margins could go -- it looks like, you know, the 75% margin spending, incredibly successful quarter, but just trying to get a sense for where do you think this number could go over the -- you know, over the intermediate term? Thank you.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, if you look at Apple Intelligence, what my point earlier was that markets where we had rolled out Apple Intelligence during the Q1 period performed better on a year-over-year basis than markets where we had not. And so, that gives us a, you know, positive indicator that we were pleased with. There are many compelling reasons to upgrade. And the other thing I would say that I think I mentioned earlier is that if you look at it from a launch to the end of the December quarter, and so, that goes back to September, the 16 family is outperforming the 15 family.
And so, I think those are two good data points. Our next round of language rollouts will be in April. And so, it will be at the -- in our Q3 quarter. And I'll let Kevan take the gross margin question.
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Yeah, great. Hi, David, how are you? So, on the services gross margin, I think maybe stepping back a second, you know, services business in general is -- in aggregate, is accretive to the overall company margin. And one of the things is an important reminder is we've got a very broad services portfolio. And those businesses have very different margin profiles.
And so, I think one is because of the nature of those businesses and in part also because of the way we account for them. And so, one of the big factors that drives the services gross margins are relative performance of those different businesses within the portfolio. We also have the dynamic of some scale businesses like payment services, iCloud that are actually growing. And there, when we add incremental users, those end up being, you know, accretive to margins as well.
And so, in general, what we saw in the December quarter was nice momentum across our entire services business that allows us to deliver, you know, that 75% margin at the services level. And I think our guidance takes into consideration, you know, what we think we're going to land from a company standpoint at 46.5 to 47.5, which, again, we think is a strong guide.
David Vogt
--
Analyst
Great. Thanks, guys.
Suhasini Chandramouli
--
Director, Investor Relations
All right. Thank you, David. Operator, could we have the next question, please?
Operator
Our next question is from Krish Sankar with TD Cowen. Please go ahead.
Krish Sankar
--
Analyst
Yeah. Thanks for taking my question. I also had two of them. One, the first one for Tim.
You had very strong Mac growth, 16% year over year last quarter. Just wondering how much of that is driven by some of the Mac silicon innovation versus a replacement cycle for Mac.
Timothy Donald Cook
--
Chief Executive Officer
I don't know the answer to your question precisely, but I think it is a combination of these products are so compelling. The M4-based products are so compelling that it's driving both upgrades at the double-digit level, and it's driving switchers at a double-digit level. And so, we're seeing both come out, and I think it's just because of the compelling products.
Krish Sankar
--
Analyst
Got it. Got it. Thanks for that, Tim. And then, a follow-up for Kevan on the growth margin.
I want to ask you more on the product side. You know, last quarter, you had 39.3%, which is very strong, similar to the year-ago period. I'm kind of curious, how much more levels do you have on the product side to improve the gross margin? Or do you think some of the more new AI-related devices, there's more upside to gross margin from here on the product hardware side?
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Yeah, thanks, Krish, for the question. So, on the product side, as you mentioned, you know, we had pretty strong sequential improvement, 300 basis points for the December quarter. You know, that was really driven by -- we talked about favorable mix and leverage. As you know, in Q1, again, it's a launch quarter for many products, and so we tend to benefit from the leverage that we get from that higher volume.
I would say, in general, you know, our gross margin of products is driven by a number of factors. One of them is the, you know, various product launches that we have, different products do have different margin profiles. And so, that mix does make a difference. And in particular, what we're seeing is, for example, many of our mixes across like phone, for example, we're seeing customers gravitate toward our pro products, you know, because of things like affordability that allows our customers to get, you know, into our best products, which have, you know, favorable gross margins.
So, we're continuing to see that trend, you know, the impact of this in the December quarter. As well, I think we're in a favorable commodity environment from a cost standpoint. And so, you know, we're benefiting from that as well in the December quarter. And then, you know, that's going to be, as we talked about, we're going to have a foreign exchange headwind heading into the March quarter.
But we figured, you know, that's contemplated in the guidance range that we gave in the 46.5% to 47.5%.
Krish Sankar
--
Analyst
Thanks, Kevan. Thanks Tim.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Krish. Operator, could we get the next question, please?
Operator
Our next question is from Richard Kramer with Arete Research. Please go ahead.
Richard Kramer
--
Arete Research -- Analyst
Thanks very much. My first question is for Tim. I'd like to ask about what might accelerate the pace of Apple Intelligence adoption. I guess, do you see this simply as a question of time, i.e., to launch more markets and languages, or increase the percentage of install base devices that can support it? Or is it a question of money, i.e., shifting R&D or marketing spend toward AI.
And based on other prior Apple services, do you expect a sort of tipping point where adoption will go mainstream? Thanks.
Timothy Donald Cook
--
Chief Executive Officer
I do believe it will go mainstream. I'm getting feedback from people using different features today. And this is -- keep in mind that on the iPhone side of our business, you either have to have an iPhone 15 Pro or iPhone 16 to use Apple Intelligence. And so, as that base grows, I think the usage will continue to grow.
And I think -- I know from my own personal experience, once you start using the features, you can't imagine not using them anymore. I know I get hundreds of emails a day, and the summarization function is so important. So, I think it's a combination of that. And, of course, in April we roll out a whole series of new languages that we had mentioned, and so the base grows further.
Richard Kramer
--
Arete Research -- Analyst
OK, thank you. And then, Kevan, one of Luca's legacies was really getting Apple to record margin levels and also maintaining very consistent pricing across the product range. But taking the current high levels of profitability is fairly stable. What observations might you share about price sensitivity of users and whether having a wider range of pricing across the products might unlock potentially further market share gains or boost overall product growth?
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Yeah, it's a good question. I think, you know, one, I don't think we're going to really depart from what served us pretty well to now. I mean, we always take into consideration, you know, looking at short-term, you know, comparisons between short term and the long term. I think we've had a pretty disciplined pricing strategy which would serve us pretty well.
And I think we're going to, you know, continually kind of stick with that as far as I can tell.
Richard Kramer
--
Arete Research -- Analyst
OK. Thanks.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Richard. Operator, could we get the next question, please?
Operator
Our next question is from Atif Malik with Citi. Please go ahead.
Atif Malik
--
Analyst
Hi. Thank you for taking my question. How do you guys see the potential tariff impact to your product or consumer demand under Trump 2.0? You guys did fine under Trump 1.0.
Timothy Donald Cook
--
Chief Executive Officer
We are monitoring the situation and don't have anything more to add than that.
Atif Malik
--
Analyst
Great. And, Tim, as a follow-up, there is a lot of discussion on agentic AI, the use of agents. Do you guys see the upgraded Siri expected in April as something that will, let's say, be the killer application among the suite of features that you have announced on Apple Intelligence?
Timothy Donald Cook
--
Chief Executive Officer
I think the killer feature is different for different people. And -- but I think for most, they're going to find that they're going to use many of the features every day. And, certainly, one of those is the -- is Siri, and that will be coming over the next several months.
Atif Malik
--
Analyst
Thank you.
Suhasini Chandramouli
--
Director, Investor Relations
Thank you, Atif. Operator, could we please get the last question?
Operator
Our last question is from Ben Bollin from Cleveland Research Company. Please go ahead.
Benjamin Bollin
--
Analyst
Good evening, everyone. Thanks for taking the question. Tim, I'm interested in your thoughts in how you would have us think about the average useful life of these devices in the wild. And, in particular, curious if you look at the strengths you saw in fiscal '21 and how that might support, you know, accelerated refresh opportunity into the future.
Timothy Donald Cook
--
Chief Executive Officer
Yeah, Ben, I think it's different for different types of users. I mean, you have very early adopter kind of users that are very quick to jump on the latest technology that upgrade very frequently. And then, you have people that are on the entire opposite side of that barbell. And most people are between those two points.
And so, I do think there were lots of units that are sold during the COVID period of time, and it's a huge opportunity for us as a company to -- for more than one of the product categories.
Benjamin Bollin
--
Analyst
That's it for me. Thanks, Tim.
Timothy Donald Cook
--
Chief Executive Officer
Thank you.
Suhasini Chandramouli
--
Director, Investor Relations
All right. Thanks, Ben. A replay of today's call will be available for two weeks on Apple Podcasts or as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035.
Please enter confirmation code 739-8532 followed by the pound sign. These replays will be available by approximately 5 p.m. at Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142.
And financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thanks again for joining us here today.
Operator
Once again, this does conclude today's conference. [Operator signoff]
Duration: 0 minutes
Call participants:
Suhasini Chandramouli
--
Director, Investor Relations
Timothy Donald Cook
--
Chief Executive Officer
Kevan Parekh
--
Senior Vice President, Chief Financial Officer
Erik Woodring
--
Analyst
Tim Cook
--
Chief Executive Officer
Ben Reitzes
--
Analyst
Mike Ng
--
Goldman Sachs -- Analyst
Amit Daryanani
--
Analyst
Wamsi Mohan
--
Analyst
Samik Chatterjee
--
Analyst
David Vogt
--
Analyst
Krish Sankar
--
Analyst
Richard Kramer
--
Arete Research -- Analyst
Atif Malik
--
Analyst
Benjamin Bollin
--
Analyst
Ben Bollin
--
Analyst
More AAPL analysis
All earnings call transcripts"
Apple Inc. (AAPL),Q3,2025,Apple (AAPL) Q3 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/08/01/apple-aapl-q3-2025-earnings-call-transcript/,"DATE
Thursday, July 31, 2025 at 5 p.m. ET
CALL PARTICIPANTS
Chief Executive Officer — Timothy D. Cook
Chief Financial Officer — Kevan Parekh
Head of Investor Relations — Suhasini Chandramouli
Need a quote from one of our analysts? Email pr@fool.com
RISKS
Apple
(
AAPL
+0.24%
)
incurred approximately $800 million in tariff-related costs and estimates $1.1 billion in additional tariffs for the next quarter, with management stating, ""This estimate should not be used to make projections for future quarters as there are many factors that could change, including tariff rates.""
iPad and Wearables Revenue Decline
— iPad revenue was $6.6 billion, down 8% year-over-year, and Wearables, Home and Accessories revenue decreased 9% year-over-year, with management citing ""difficult compare"" against the prior-year launches as a contributing factor.
TAKEAWAYS
Total Revenue
— $94 billion, up 10%, marking a June quarter record.
Earnings per Share (EPS)
— $1.57, up 12%, achieving a June quarter record.
iPhone Revenue
— $44.6 billion, up 13%, with growth in every geographic segment and a record number of upgraders.
Mac Revenue
— Mac revenue was $8 billion, up 15% year-over-year, driven by the M4 MacBook Air and growth across all regions.
iPad Revenue
— iPad revenue was $6.6 billion, down 8% year-over-year, reflecting a challenging compare to prior product launches.
Wearables, Home and Accessories Revenue
— Wearables, Home and Accessories revenue was $7.4 billion, down 9% year-over-year, attributed to a difficult compare related to previous iPad launches.
Services Revenue
— $27.4 billion, up 13%, setting an all-time record.
Gross Margin
— Company gross margin was 46.5%, down 60 basis points sequentially, primarily due to tariff costs.
Product and Services Gross Margin
— Products gross margin was 34.5% (down 140 basis points sequentially). Services gross margin was 75.6% (down 10 basis points sequentially).
Operating Expenses
— Operating expenses were $15.5 billion, up 8% year-over-year.
Net Income
— $23.4 billion, a June quarter record.
Operating Cash Flow
— Operating cash flow was $27.9 billion.
Shareholder Returns
— $27 billion returned via $3.9 billion in dividends and $21 billion in share repurchases.
Active Installed Base
— All-time high across all products and regions.
Paid Subscriptions
— Over 1 billion paid subscriptions across services, reflecting double-digit year-over-year growth.
Geographic Performance
— Revenue records were set in the U.S., Canada, Latin America, Western Europe, the Middle East, India, and South Asia.
Guidance for Next Quarter
— Revenue growth expected at mid- to high single-digit percent for the next quarter; Services growth rate to match the June quarter; Gross margin is expected to be between 46%-47% for the next quarter, including $1.1 billion in tariff costs; operating expenses between $15.6 billion and $15.8 billion.
AI and Capital Expenditure
— Significant increase in AI-related investment is driving higher capital expenditures, with ongoing expansion in private cloud compute and first-party data centers, as discussed for the current year and next.
Dividend
— Cash dividend of $0.26 per share declared, payable August 14, 2025.
Tariff Pull-Ahead Effect
— Management estimated ""pull forward of demand into April, specifically to be about 1 point of the 10 points"" growth due to tariff discussions.
Customer Satisfaction
— Recent U.S. surveys show customer satisfaction at 97% for Mac, 98% for iPad, and 97% for Apple Watch.
SUMMARY
Management reported 10% revenue growth and 12% EPS growth, crediting record performance across iPhone, Mac, and Services, despite declines in iPad and Wearables. The iPhone 16 family outperformed earlier models, contributing to a record number of upgraders and an all-time high installed base. AI investment is accelerating, with expanded capital spending on both in-house data centers and a hybrid cloud strategy, as well as a planned $500 billion investment in the U.S. over the next four years. Gross margin and product margins (GAAP) saw sequential declines due to increased tariff-related costs. Guidance anticipates continued strong Services growth and mid- to high single-digit overall revenue growth next quarter, with exposure to tariff cost volatility and ongoing macroeconomic, legal, and regulatory uncertainties explicitly acknowledged in the outlook.
CEO Cook stated, ""We incurred approximately $800 million of tariff-related costs."" and projected next quarter's costs at $1.1 billion if tariff policies remain unchanged.
Management attributed above-seasonal strength, in part, to ""pull forward of demand into April,"" quantified as roughly 1 percentage point of total company growth.
iPhone channel inventory was reduced to the ""low end of our targeted range"" by quarter-end, according to Cook.
Paid accounts and subscriptions reached new all-time highs, with transacting and paid accounts growing double digits year-over-year across the Services segment.
Management confirmed iPhone growth in every region, and noted the highest-ever iPhone installed base and upgrader record for Mainland China.
U.S. supply chain investments include $0.5 billion with MP Materials and the opening of an Apple Manufacturing Academy in Detroit as part of a $500 billion U.S. commitment over the next four years.
Guidance includes a gross margin range lowered by the expected $1.1 billion tariff cost and operating expenses as high as $15.8 billion.
AI development is prioritized, with more than 20 Apple Intelligence features released and continued significant increases in resource allocation and capital expenditure.
INDUSTRY GLOSSARY
Apple Intelligence
: Apple’s suite of generative AI technologies and features integrated across its hardware and software platforms, designed for privacy and on-device capability.
Installed Base
: The total number of actively used Apple devices in the market across all product categories.
Upgraders
: Customers who replace their existing device with a newer model within the Apple product line during the reporting period.
Private Cloud Compute
: Apple's proprietary cloud infrastructure which processes certain advanced AI tasks while preserving privacy architecture.
Full Conference Call Transcript
Timothy D. Cook:
Thank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Today, we are proud to report a June quarter revenue record of $94 billion, up 10% from a year ago, which was better than we expected. EPS set a June quarter record of $1.57, up 12% year-over-year. We saw an acceleration of growth around the world in the vast majority of markets we track, including Greater China and many emerging markets. And we had June quarter revenue records in more than two dozen countries and regions, including the U.S., Canada, Latin America, Western Europe, the Middle East, India and South Asia. These results were driven by double-digit growth across iPhone, Mac and Services.
We set a June quarter record for iPhone, which grew a strong 13% year-over-year. We saw iPhone growth in every geographic segment and double-digit growth in emerging markets, including India, the Middle East, South Asia and Brazil. Mac continued to see excellent results with revenue up 15% year-over-year. And we set another all-time revenue record in Services, which grew 13% with double-digit growth in both developed and emerging markets. Last month, we hosted WWDC, an incredible event for our developer community with millions joining us online and more than 1,000 developers here in person at Apple Park.
We shared some truly exciting updates, including a stunning new design crafted from a material we call Liquid Glass, it's both beautiful and expressive. And for the first time ever this design extends across all of our platforms. We can't wait for users everywhere to experience it this fall. And we were excited to share some updates across our AI work. We announced even more capabilities coming later this year, including live translation and Workout Buddy. In addition to those new features, we announced new support for a number of languages, and we opened up access to the on-device foundation models at the core of Apple Intelligence, enabling developers to build a whole new experience for our users.
It's wonderful to see great momentum building for our platforms. iOS 26, macOS 26 and iPadOS 26 are by far the most popular developer betas we've had. Taking a step back, we see AI as one of the most profound technologies of our lifetime. We are embedding it across our devices and platforms and across the company. We are also significantly growing our investments. Apple has always been about taking the most advanced technologies and making them easy to use and accessible for everyone. And that's at the heart of our AI strategy. With Apple Intelligence, we're integrating AI features across our platforms in a way that is deeply personal, private and seamless, right where users need them.
We've already released more than 20 Apple Intelligence features, including visual intelligence, cleanup and powerful writing tools. We're making good progress on a more personalized Siri, and as we've said before, we expect to release these features next year. Apple silicon is at the heart of all of these experiences, enabling powerful Apple Intelligence features to run directly on device. For more advanced tasks, our servers also powered by Apple silicon deliver even greater capabilities while preserving user privacy through our private cloud compute architecture. We believe our platforms offer the best way for users to experience the full potential of generative AI.
Thanks to the exceptional performance of our systems, our users are able to run generative AI models right on their Mac, iPad and iPhone. We're excited about the work we're doing in this space, and it's incredibly rewarding to see the strong momentum building. Now let me turn to more details about our results for the quarter, starting with iPhone. iPhone revenue was $44.6 billion, up 13% from a year ago, and we set a June quarter record for upgraders. This strong broad-based performance was driven by the incredible popularity of the iPhone 16 family, which was up strong double digits year-over-year as compared to the 15 family. We also recently marked a significant milestone.
We shipped the 3 billionth iPhone since its launch in 2007. From the Pro models with the powerhouse A18 Pro and innovative Pro camera features to the iPhone 16e with breakthrough battery life and a 2-in-1 camera system, users are finding so many reasons to love the best iPhone lineup we've ever created. And iOS 26 will take that experience even further. In addition to the beautiful new design and powerful Apple Intelligence features, it introduces a range of meaningful updates like real-time call screening and hold assist in the phone app, smarter messaging tools and new live translation features.
It all adds up to a smarter, more personal iPhone experience that we can't wait for users everywhere to enjoy this fall. In Mac, we had another strong quarter with revenue of $8 billion, up 15% year-over-year, largely driven by the strength of the M4 MacBook Air. We set a June quarter record for upgraders on Mac, and we saw great performance in emerging markets with strong double-digit growth on revenue as well as strong double-digit growth on both upgraders and customers new to Mac. MacBook Air, the world's most popular laptop, unlocks a whole new level of performance with the power of M4.
MacBook Pro customers meanwhile continue to be drawn to its incredible power and the longest battery life we've ever had on a Mac. Customers are also loving the newest Mac Studio, which is the most powerful Mac we've ever made with next-level capabilities to tackle even the most demanding AI workflows. At the same time, Mac mini continues to win over customers by packing so much performance into an ultracompact design. And with fantastic new updates in macOS Tahoe 26 6 from the phone app to live activities to our biggest ever update to Spotlight, Mac users across our entire lineup are going to find delightful new ways to stay connected and productive.
For iPad, June quarter revenue was $6.6 billion. Our incredibly versatile iPad lineup brings together power and portability like never before. And users are already excited for our biggest iPad software update ever with the upcoming release of iPadOS 26. It starts with a new windowing system that's remarkably intuitive, giving users more control than ever of their iPad experience. An enhanced files app makes it easier than ever to stay organized. And that's all on top of a beautiful new software design that brings these updates to life. Turning to Wearables, Home and Accessories. Revenue was $7.4 billion, and we saw a June quarter record for upgraders to Apple Watch.
During the quarter, we marked the 10-year anniversary of Apple Watch, celebrating a decade of helping users navigate their health and fitness journeys. And with watchOS 26 Apple Watch will be more intelligent than ever with smart updates to the workout app and Smart Stack, along with a fresh new design that feels both dynamic and personal. We're also thrilled about what's coming to Apple Vision Pro with visionOS 26 introducing spatial widgets that let users customize their digital space, more life-like personas and new enterprise APIs that empower companies to build their own spatial experiences.
And this fall, new features for our latest AirPods lineup will unlock even more possibilities from studio quality audio recording to using AirPods as a camera remote, giving users powerful new ways to capture content and stay connected. As we're innovating across our lineup, we're especially proud of the work we're doing to help our users live healthier lives. Since we first launched our hearing health features for AirPods Pro 2, I've received notes from people who are delighted to be able to connect more deeply with loved ones.
Whether it's with AirPods Pro 2 or Apple Watch or iPhone, it's amazing to see the power of our health and safety features from hearing tests to fall detection alerts to irregular rhythm notifications having such a profound impact. Turning to Services. Revenue for the June quarter was $27.4 billion, up 13% from a year ago and an all-time record. Apple TV+ scored 81 nominations, a record for the platform across nearly every eligible category for this year's Emmy Awards. Severance leads all Emmy nominees with 27 nominations and The Studio follows close behind with 23 nominations, more than any other freshman comedy series ever.
It's amazing to see how these and other Apple TV shows have captured the popular imagination. To date, Apple TV+ has earned more than 2,700 award nominations and 585 wins on the strength of the highest-rated original content of any streaming network. And we continue to see very positive trends in the June quarter with TV+ viewership up strong double digits year-over-year. In June, we were also thrilled to release F1 in theaters around the world, one of the summer's most unforgettable blockbusters. During the quarter, we celebrated a big anniversary with 10 years of Apple Music. To mark the occasion, we launched an all-new studio space in Los Angeles for artists to create content and connect with fans.
And later this year, we're bringing Apple Music users even more to love from an enhanced listening experience with AutoMix, which mixes songs like a DJ to lyrics translation and more. The App Store meanwhile continues to be the very best place to discover the latest apps from developers around the world in a safe and trusted way and App Store revenue grew double digits year-over-year, setting a June quarter record. In retail, we continue to find opportunities in emerging markets to connect with even more customers. We recently launched the Apple Store online in Saudi Arabia, and we couldn't be more excited to open new stores in the UAE and India later this year.
We were also delighted to welcome customers in Japan to a new location in the heart of Osaka. Across everything we do at Apple, we show up by leading with our values. We feel strongly that the benefits of technology should be shared by everyone. That's why we make technology for everyone. In May, to mark Global Accessibility Awareness Day, we announced updates to help users learn, connect and interact with their worlds, including magnifier for Mac, a new braille experience and accessibility reader, a new system-wide reading mode to make it easier to understand content.
And we're proud to introduce accessibility nutrition labels, giving users an understanding of accessibility features before they download an app while helping developers educate people on features their app support. This month, we also announced a $0.5 billion commitment with MP Materials to strengthen the supply of vital recycled rare earth materials in the U.S. and support American industry. And in August, we're opening our all-new Apple Manufacturing Academy in Detroit to train and support American manufacturers. These investments are part of Apple's largest ever spend commitment, which we announced earlier this year.
Over the next 4 years, Apple is investing $500 billion in the U.S., driving innovation and creating jobs in cutting-edge fields like advanced manufacturing, silicon engineering and artificial intelligence. We're proud of this work and all that we're doing to tap into American innovation and bring the best technology experiences to users across the globe. And we continue to look for further opportunities to do even more. Finally, the situation around tariffs is evolving, so let me provide some color there. For the June quarter, we incurred approximately $800 million of tariff-related costs.
For the September quarter, assuming the current global tariff rates, policies and applications do not change for the balance of the quarter and no new tariffs are added, we estimate the impact to add about $1.1 billion to our costs. This estimate should not be used to make projections for future quarters as there are many factors that could change, including tariff rates. We're really proud of our results for the June quarter, and I want to thank our teams and our customers. In everything we do, we're driven by transformative innovation, delivering the most exceptional products and services we've ever created, and we're especially excited about what's ahead. With that, I'll turn it over to Kevan.
Kevan Parekh:
Thanks, Tim, and good afternoon, everyone. Our revenue of $94 billion was up 10% year-over-year and is a new June quarter record. We grew in every geographic segment and in the vast majority of the markets we track. Products revenue was $66.6 billion, up 8% year-over-year, driven by growth across iPhone and Mac. And thanks to our high levels of customer satisfaction and strong loyalty, our installed base of active devices reached another all-time high across all product categories and geographic segments. Services revenue was $27.4 billion, up 13% year-over-year and an all-time record. We saw strength across the world with double-digit growth in the majority of our markets.
Company gross margin was 46.5% at the high end of our guidance range and down 60 basis points sequentially, primarily driven by approximately $800 million in tariff-related costs Tim mentioned earlier. Products gross margin was 34.5%, down 140 basis points sequentially, driven by mix and tariff-related costs, partly offset by cost savings. Services gross margin was 75.6%, down 10 basis points sequentially. Operating expenses landed at $15.5 billion, up 8% year- over-year. This strong business performance led to June quarter records for both net income at $23.4 billion and diluted earnings per share of $1.57, which was up 12% year-over-year. Operating cash flow was also strong at $27.9 billion.
Now I'm going to provide some more details for each of our revenue categories. iPhone revenue was $44.6 billion, up 13% year-over- year, driven by the iPhone 16 family. As Tim noted, we saw iPhone growth in every geographic segment and double-digit growth in many emerging markets. The iPhone active installed base grew to an all-time high in total and in every geographic segment, and we reached a June quarter record for upgraders. According to a recent survey from Worldpanel, formerly of Kantar, iPhone was a top-selling model in the U.S., Urban China, the U.K., Australia and Japan during the June quarter.
And we continue to see very high levels of customer satisfaction in the U.S. at 98% as measured by 451 Research. Mac revenue was $8 billion, up 15% year-over-year, driven by continued strength across the portfolio, including MacBook Air, Mac mini and MacBook Pro. We grew in every geographic segment and saw double-digit growth in Europe, Greater China and the rest of Asia Pacific. The Mac installed base reached an all-time high, and we hit a June quarter record for upgraders.
In the U.S., customer satisfaction was recently measured at 97%. iPad revenue was $6.6 billion, down 8% year-over-year, which was expected given the difficult compare against the launch of the iPad Air and iPad Pro in the year ago quarter. At the same time, the iPad installed base reached another all-time high and over half of the customers who purchased an iPad during the quarter were new to the product. And based on the latest reports from 451 Research, customer satisfaction was 98% in the U.S. Wearables, Home and Accessories revenue was $7.4 billion, down 9% year-over-year. This was driven by a difficult compare on accessories due to the prior year's iPad launches that I just referred to.
The Apple Watch installed base reached a new all-time high with over half of customers purchasing an Apple Watch during the quarter being new to the product. We also set a quarterly record for upgraders on Apple Watch and the latest customer satisfaction for Watch in the U.S. was reported at 97%. Our Services revenue reached an all-time high of $27.4 billion, up 13% year-over-year. The performance in the June quarter was broad-based. We saw a sequential acceleration across the majority of the categories, including cloud services, where we reached an all-time revenue record, driven by the year-over-year growth of iCloud paying accounts.
We saw strong momentum during the June quarter and the growth of our installed base of active devices gives us great opportunities for the future. Customer engagement across our Services offerings also continued to grow. Both transacting and paid accounts reached new all- time highs with paid accounts growing double digits year-over-year. Paid subscriptions also grew double digits. We have well over 1 billion paid subscriptions across the Services on our platform. We continue to improve the quality and breadth of our Service offerings from the new Apple Games app to a continued expansion of Tap to Pay and Wallet. Turning to enterprise. Organizations are continuing to invest in Apple products to drive employee innovation and productivity.
With companies like PayPal and Roche deploying more Macs for their workforce, we had the best June quarter ever for Mac in enterprise. In Thailand, Siam Commercial Bank, one of the largest Thai banks, has deployed thousands of iPads across their branches to enhance the quality and efficiency of their banking operations from loan services to wealth management. CAE, a leader in pilot training and simulation technology is using Apple Vision Pro to enable pilots to become more familiar with aircraft procedures, leading to more productive in-person flight simulator training outcomes. Let's turn to our cash position and capital return program. We ended the quarter with $133 billion in cash and marketable securities.
We had $5.7 billion of debt maturities, issued $4.5 billion of new debt and increased commercial paper by $4 billion, resulting in $102 billion in total debt. Therefore, at the end of the quarter, net cash was $31 billion. During the quarter, we returned over $27 billion to shareholders. This included $3.9 billion in dividends and equivalents and $21 billion through open market repurchases of 104 million Apple shares. As we move into the September quarter, I'd like to review our outlook, which includes the types of forward-looking information that Suhasini referred to.
Importantly, the color we're providing assumes that the global tariff rates, policies and application remain in effect as of this call, the global macroeconomic outlook does not worsen from today and the current revenue share agreement with Google continues. We expect our September quarter total company revenue to grow mid- to high single digits year-over-year. We expect Services revenue to grow at a year-over-year rate similar to what we reported in the June quarter. We expect gross margin to be between 46% and 47%, which includes the estimated impact of the $1.1 billion tariff-related costs that Tim referred to earlier. We expect operating expenses to be between $15.6 billion and $15.8 billion.
We expect OI&E to be around negative $25 million, excluding any potential impact from the mark-to-market of minority investments and our tax rate to be around 17%. Finally, today, our Board of Directors has declared a cash dividend of $0.26 per share of common stock payable on August 14, 2025, to shareholders of record as of August 11, 2025. With that let's open the call to questions.
Suhasini Chandramouli:
Thank you, Kevan.
[Operator Instructions]
. Operator, may we have the first question, please?
Operator:
Certainly, we'll go ahead and take our first question from Michael Ng with Goldman Sachs.
Michael Ng:
I just have one on upgrade rates and one on CapEx. First, on the upgrade rates, it's encouraging to see the records on iPhone, Mac and Watch. I was wondering if you're seeing strength in the upgrade rates? Or is the records more a function of the growing installed base? What is your research showing that made upgrades particularly compelling this year? For example, is it product features, tariff pull forward, perhaps Apple Intelligence? And then I'll give my follow-up on CapEx.
Timothy D. Cook:
You'll do CapEx first.
Kevan Parekh:
Yes, I'll do CapEx first.
Michael Ng:
Just on the CapEx, it's up notably year-to-date. Could you just comment on your capital spending plan this year and next and provide some qualitative color in terms of what's driving that growth? Is it AI-related or supply chain diversification, for instance?
Kevan Parekh:
Yes, Mike, it's a combination of factors. I would say, a pretty significant driver as Tim talked about, is the fact we are increasing our investment significantly in AI. So that is certainly a component of it. As you know, we've been investing in private cloud compute, which is also in our first-party data centers. The other piece, as you know, is we do have a hybrid strategy where in cases we do use third parties to make capital investments, and we also invest in our own. So you are going to see an increase in CapEx.
We also, from time to time, have other investments in facilities, in toolings, but I would say a significant portion of the driver of growth that you're seeing now is really driven by some of our AI-related investments.
Timothy D. Cook:
On the upgrades, Michael, if you look at iPhone, the 16 family grew double digit as opposed to the 15 family from the year ago quarter. And so we did set an upgrade record. I think it directly is because of the strength of the product. Mac also set records on upgrade, and I think we continue to see a move to Apple silicon and the performance of Apple silicon is playing a very key role. And so it was an incredible quarter.
In terms of -- if you're wondering about pull forward, we would estimate the pull forward of demand into April, specifically to be about 1 point of the 10 points in terms of people buying because of discussions about tariffs.
Operator:
Our next question is from Erik Woodring with Morgan Stanley.
Erik William Richard Woodring:
I have two as well. Tim maybe starting with you, shortly after March quarter earnings, there were some reports about searches on Safari declining in April for the first time, I think, in over 2 decades. Judging by your 13% Services growth this quarter, it doesn't seem to indicate that April trends necessarily played out through the remainder of the June quarter. And so I'm really just looking for a little bit more color on really how the rest of the quarter played out. And if you believe Apple products as kind of search access points are losing their strategic value as AI platforms become more valuable, popular or increasing in strategic value. And then I have a follow-up.
Timothy D. Cook:
I think they continue to be very valuable. I think that consumers' behaviors are evolving, and we're monitoring it very closely.
Erik William Richard Woodring:
Okay. I appreciate that color. And then maybe second to that, I'd love if you could maybe elaborate a bit on what you're seeing in China. I think in an interview earlier this afternoon, you alluded to some of the promotions being tailwinds. But just bigger picture, if we take a step back in China, how would you characterize demand interest in the iPhone 16 and some of your other products? Is that shifting or maybe were some of the trends in the June quarter maybe a bit more onetime and unique in nature?
Timothy D. Cook:
Yes. We did grow in Greater China by 4% during the quarter versus the previous quarter, it was driven by an acceleration by iPhone, although we also had substantial growth on the Mac year-over-year. From a -- as you know, the government has placed certain subsidies that affects some of our products, not all of them, but there are some of them. And I think that had some effect. It was the first full quarter of the subsidy playing out, that cut in during a portion of the previous quarter. The other things I would say are that the installed base hit a record high in Greater China, and we set an all-time record for the iPhone installed base.
The iPhone upgraders in Mainland China set a record for the June quarter. And according to Worldpanel, which was formerly known as Kantar, iPhone had the top 3 models in Urban China, which is extraordinary. Also, if you look at the other products, Mac, iPad and Watch, the majority of customers that are buying in China Mainland were new to the product. So lots of good things there. And the other thing I would point out, which is an interesting point, The MacBook Air was the top-selling laptop model in all of China, and the Mac mini was the top-selling desktop model in all of China. So overall, a positive -- very positive quarter.
Operator:
Our next question is from Ben Reitzes with Melius Research.
Benjamin Alexander Reitzes:
I really appreciate it. I wanted to ask about Siri, Tim, and just overall AI investment. There's a perception that Siri is going to help drive other new products potentially that maybe where voice is quite needed. And just wondering how's your confidence towards launching that next year? Is there anything that's been done internally to increase that confidence? Is it tied to the investment? I just think folks would love to know a little bit more about your confidence in how that's going? And then I have a follow-up.
Timothy D. Cook:
Yes. Thanks for the question. We're making good progress on a more personalized Siri, and we do expect to release the features next year, as we had said earlier, our focus from an AI point of view is on putting AI features across the platform that are deeply personal, private and seamlessly integrated. And of course, we've done that with more than 20 Apple Intelligence features so far from visual intelligence to cleanup to writing tools and all the rest. We are significantly growing our investment, we did during the June quarter, we will again in the September quarter.
I'm not putting specific numbers behind that at this point, but you can probably tell from the guidance that things are moving up. We are also reallocating a fair number of people to focus on AI features within the company. That are -- we have a great team, and we're putting all of our energy behind it. In terms of other products, I don't want to really comment on specific other products. But we have an exciting road map ahead and I could not be more excited about it.
Benjamin Alexander Reitzes:
That's great, Tim. Just with regard to my second question, it's about the overall revenue guide. And I appreciate that you guide the best you can see it. But I just wanted to challenge it from a different way is, why would it decelerate if Services is staying the same at 13%. What -- is there a conservatism there? I would think even currency is just as favorable, if not more favorable. So why would it decelerate to the higher single digits from where you were in the quarter? Or is it just being conservative? And if there's something decelerating or comp, do you mind just pointing that out?
Kevan Parekh:
Yes, Ben, this is Kevan. Thanks for the question. I think when you look at the growth from Q3, we just reported to the mid- to high single-digit guide. I think you have to kind of keep in mind two components. The first is the effect of the tariff-related pull-ahead in demand that Tim referenced earlier, which we estimated to be about 1 point of the 10 points that we ended up doing in Q3. And then the other factor that I think you have to take into consideration is the fact that in September quarter a year ago, we had the full quarter impact of the iPad launches, which also leads to a difficult compare this year.
So those two components are things you have to take into consideration as you think about the move from Q3 to Q4. I would say foreign exchange is a very minor tailwind going from Q3 to Q4, so not really a major factor.
Operator:
Our next question is from Wamsi Mohan with Bank of America. .
Wamsi Mohan:
Tim, I know you said similar growth in Services, and that's predicated with Google payments continuing. Is there any way for us to dimensionalize sort of -- or maybe just conceptually talk about maybe options if, if the counter were to happen, if the payments were not allowed in some way, what are some of the things that Apple could do given that it is a significant chunk of profitability? And I have a follow-up.
Timothy D. Cook:
Yes, Wamsi, I don't really want to speculate on the court ruling and how they would rule and what we would do as a consequence of it.
Wamsi Mohan:
Okay. Okay. I guess we'll wait for that ruling to come out. I guess, separately, Tim, at a high level, when you look at some of what is perceived fears of new form factors and ways to interact with devices. There was some worry that given some of the developments in AI that there could be a world where dependence on screen-based devices significantly diminishes. And I'm kind of curious to get your thoughts on if do you think that would happen and rate and pace in which? And how do you think Apple is preparing in that case?
Timothy D. Cook:
When you think about all the things an iPhone can do from connecting people to bringing app and game experiences to life to taking photos and videos to helping users explore the world and conduct their financial lives and pay for things and so much more. It's difficult to see a world where iPhone is not living in it. And that doesn't mean that we are not thinking about other things as well. But I think that, that the devices are likely to be complementary devices, not substitution.
Operator:
Our next question is from Amit Daryanani with Evercore.
Amit Jawaharlaz Daryanani:
I guess just to start with -- Tim, the tariff assumption of $1.1 billion in the September quarter, I kind of -- I understand the uptick you folks are talking about. But can you just talk about assuming tariffs remain at these levels or even they evolve under Section 232, how do you eventually think about offsetting this headwind to your P&L? And when do you decide to execute on the levers to offset this headwind versus just flowing into your bottom line?
Timothy D. Cook:
Right now, we're just estimating the cost of it, and it's up quarter-over-quarter, because our volume is up quarter-over-quarter. And there was some build ahead in the previous quarter. And so that's the primary reason that it's up. In terms of what we do to mitigate, we obviously try to optimize our supply chain and ultimately, we're -- we will do more in the United States. We've committed $500 billion investment in the U.S. over the next 4 years. And we're already building chips in Arizona. And in fact, we're building semiconductors across 12 states in 24 factories, and have a lot of other things in the work. You probably saw the investment in MP Materials last week.
And so we continue to explore these things and look for more that we can do, which I think ultimately is the objective.
Amit Jawaharlaz Daryanani:
Got it. Super helpful. And then your Services growth, I think, was extremely impressive at 13%, especially given all the fears folks had. Can you just touch on, did you see any impact that was notable from the Epic case and the steering dynamics that came after that? And maybe just touch on what does that appeal process looks like for you as you go forward? .
Kevan Parekh:
Yes, this is Kevan. Let me take that one. In general, I think just reminding, I think you just said, we had a very strong Services quarter, we had an all-time record at the $27.4 billion, up 13%. The one thing I would also say is our services performance was broad- based. So we also saw strength in developed and emerging markets, both parts of the world had double-digit growth. We also saw a sequential acceleration across the majority of our categories, including cloud services, where I mentioned in the prepared remarks that we had an all-time revenue record.
As it relates to the EPIC decision, we -- keep in mind, we only just introduced the change required by the court in the June quarter. And as you know, we don't provide the level of detail. But in general, I would say it was a very, very -- in the U.S., we had a double- digit growth for the U.S. App Store, and we set an all-time record. And so we'll continue to monitor the effects on our business, but we'll continue to innovate and ensure that the App Store delivers the best experience for users and remains a great business opportunity for developers.
Operator:
Our next question is from David Vogt with UBS.
David Vogt:
And I have two questions as well. Maybe Tim, just on the supply chain strategy. I know last quarter, you talked about focusing production or assembly to India. And I just want to get an update on how you're thinking about the strategy holistically, given sort of the tariff rates, I think, in India potentially are higher than I think anyone had expected. So I know you mentioned some U.S. investments, would love to kind of get your thoughts on how you're thinking about China versus the rest of Southeast Asia and India going forward? And then I'll give you my second question also.
So Kevan, I'm just trying to understand a little bit more about the demand drivers of iPhone in the quarter because obviously, the 16 has been in the market for some time. I know there was some promotional activity. But seasonally, you generally don't see this kind of strength in the June quarter. Maybe you can help us understand outside of maybe the promotional activity, what else were some of the drivers that led to what was -- looks like a pretty significant above seasonal strength in the June quarter stats?
Timothy D. Cook:
Yes. In terms of the tariff situation and country of origin and so forth. One thing I would say, just to remind everyone is keep in mind that the vast majority of our products are covered under the Section 232 investigation. And so the -- today or I should say, last quarter, the bulk of the tariffs that we paid were the IEEPA tariffs that hit early in the year related to China. And so that's just a reminder of where things are and what we assumed as we calculated the projection of $1.1 billion that's in our outlook color. In terms of the country of origin, it's the same as I referenced last quarter.
There hasn't been a change to that, which is the vast majority of the iPhone sold in the U.S. or the majority, I should say, have a country of origin of India and the vast majority of the products, other products, the Mac and the iPad and the Watch have a country of origin of Vietnam that are sold in the United States. Still, the products for other international countries, the vast majority of them are coming from China. And so that hopefully gives you a flavor of the of where things are. But I would stress again that we do a lot in this country in the United States.
And we've committed $500 billion, and we're always looking to do more. And you could kind of see that in the most recent announcements, whether it's MP Materials or our manufacturing academy that we're standing up in Detroit in a couple of weeks or so. And so we're going to be doing -- we're doing more in this country, and that's on top of having roughly 19 billion chips coming out of the U.S. now, and we will do more, and of course, glass from iPhone and the Face ID module. And so there's loads of different things that are done in the United States.
Kevan Parekh:
And then, David, as...
David Vogt:
And then on the iPhone activity?
Kevan Parekh:
Yes. So I was going to mention the iPhone activity. You asked if there's any kind of unique characteristics this quarter? I would just say, as Tim outlined, we really believe that the strong upgrade performance, which was a June quarter record was really driven by the strength of the product lineup. The iPhone 16 family has done incredibly well compared to the iPhone 15 family. And we also, as you recall, recently introduced the 16e as well, which also continued to impact the success of the overall iPhone 16 lineup.
Operator:
Our next question is from Krish Sankar with TD Cowen.
Krish Sankar:
I have two of them. The first one is for Kevan, this was a previous question, do you think there was any pull-in of iPhones in the June quarter that led to some of the upside? And how to think about channel inventory in June quarter? And how it looks in September relative to seasonal trends? And then I had a longer-term follow-up for Tim.
Timothy D. Cook:
Let me see if I can answer the channel inventory question or what I think is the channel inventory question. If you look at iPhone channel inventory from the beginning of the quarter to the end of the quarter, we reduced it, and it ended toward the low end of our targeted range. And so that's the answer on the inventory piece of it.
Kevan Parekh:
And then I think you also asked about the pull-ahead impact. I think we referenced that earlier. Just to be clear on what we believe we saw in the June quarter, we did see some obvious signs of pull-ahead really in the April time frame around the tariff-related discussions that were out in the marketplace. And so we felt that, that was from what we saw about a 1 point impact of the 10 points at a total company level of growth. And so that was the limited impact that we believe we saw for the quarter.
Krish Sankar:
Got it. Very helpful. And then I just have like a long-term follow-up for Tim. Tim, I'm kind of curious about your thoughts on AI for edge devices. There's like some people who think that LLM could be a commodity in the future. Do you think -- do you see a scenario where the LLMs become a core part of your iOS or is the SLM the way to go and how to think about evolution of edge devices in a futuristic AI world and if smartphone going to be the choice of device. Just curious your thoughts on it, broadly speaking.
Timothy D. Cook:
The way that we look at AI is that it's one of the most profound technologies of our lifetime. And I think it will affect all devices in a significant way. What pieces of the chain are commoditized and not commoditized, I wouldn't want to really talk about today because that gives away some things on our strategy. But I think it's a good question.
Operator:
Our next question is from Samik Chatterjee with JPMorgan.
Samik Chatterjee:
Tim, maybe if I can start with your remarks about the pull-ahead being about a 1 percentage point benefit here. Anything to share in terms of how -- what's underlying that estimate in terms of what you're seeing for -- is it a pull-ahead largely on iPhones? Or is it across the board? And is it primarily in the U.S. or again, sort of across multiple regions? Any color there would be helpful in terms of how you're sort of getting to that assumption there. And I have a follow-up.
Timothy D. Cook:
It was principally on iPhone and Mac. And it was pretty -- it was obvious evidence of it. It was an unusual buying pattern there and that largely occurred in April towards the beginning of the quarter. And it was really -- we believe it was largely the United States.
Samik Chatterjee:
Okay. Okay. Got it. And maybe on the tariff front, when you gave the estimate of $900 million last quarter, which came in at $800 million, you did highlight it was -- there were some unique factors in the quarter. When I take the $1.1 billion that you're now sort of expecting for the September quarter and as we start to think about December, would -- is there anything unique in the December quarter in terms of sourcing from regions, et cetera, that would uniquely impact December, just given sort of that you had highlighted that quarter-to-quarter, so there would be unique things. Just curious if December looks very different from September because of any unique factors.
Timothy D. Cook:
I would be careful about projecting based on the numbers from Q2 and Q3 because, one, we're uncertain of what the rates will be. And so the rates may change. Two, in -- particularly in last quarter, we had some build ahead inventory that we were -- that we had within the company and within our supplier -- within our supply chain. And so those two are a little unique. Also, as you know, from following us for so long, Q1 is generally a higher volume quarter. And the tariffs are currently are pretty linear with volume.
Operator:
Our next question is from Aaron Rakers from Wells Fargo.
Aaron Christopher Rakers:
I've got two as well, and I'll just ask them together. I guess the first one is just more housekeeping. Kevan, when we think about currency impact, how much of a benefit was currency this quarter, and I guess across the business and in particular, maybe on the Services segment, and on a year-on-year basis, how much currency benefit should we be thinking about embedded in the guidance into the September quarter? And then the second quick question is CapEx is clearly moving higher. I know you guys don't guide specifically to that number.
But just kind of qualitatively, should we -- as you lean in more on AI, should we really start to see that CapEx, which is running close to about $4 billion annualized today, really start to move appreciably higher? Any color on that would be helpful.
Kevan Parekh:
Great, Aaron. Thanks for the questions. Let me answer the first one, first around foreign exchange. For Q3, we really had no impact from a foreign exchange standpoint on the year-on-year results. And so -- when we look at both the revenue growth as well as the gross margin, there was virtually no impact from foreign exchange. As we look at going from Q3 to June quarter to the September quarter, again, very, very, as I mentioned earlier, a very small tailwind going from Q3 to Q4 from a foreign exchange standpoint on both revenue as well as gross margin.
And then on the second question, sure, on the CapEx side, I think we talked about the fact that we are, and Tim mentioned the fact that we are increasing our investment significantly in AI. You are going to continue to see our CapEx grow. It's not going to be exponential growth, but it is going to grow substantially. And a lot of that's a function of the investments we're making in AI. As we mentioned, we also have other items that fall under that category, facilities and some of our retail store investments. But I would say a lot of the growth is really being driven by AI.
I would remind you that we do have a hybrid model though, where we also leverage third-party infrastructure in addition to investing in our own first-party infrastructure.
Operator:
Our next question is from Atif Malik with Citi.
Atif Malik:
Tim, at the WWDC earlier in the quarter, you showed impressive updates on Vision Pro with the use of widget, spatial scenes, persona and new ways to create content. Appears like Meta and Xiaomi are seeing strong momentum on their AI glasses. So is the focus still around enterprises on Vision Pro? Or are you thinking of broadening the use cases and maybe tying it to more of your devices? Any thoughts on Vision Pro as they did not get enough airtime in the prepared remarks.
Timothy D. Cook:
Yes. Thanks for bringing it up. I was thrilled with the release from the team on visionOS 26. It includes many things in it like spatial widgets to enable users to customize their digital space. The personas took a huge increase. They're much more lifelike. And of course, there's new enterprise APIs for companies as well. And we're seeing, as Kevan talked about in his opening remarks, we're seeing those things resonate out with CAE and other customers. And so we continue to be very focused on it. And I don't want to get into the road map on it, but this is an area that we really believe in.
Atif Malik:
Great. And Kevan, historically, you guys have not done much big M&A. Do you feel like you need to accelerate your AI road map or just keep the organic focus?
Timothy D. Cook:
Let me take that one as well. We've acquired around seven companies this year. And that's companies from all walks of life, not all AI oriented. And so we're doing one, think of it as one every several weeks. We're very open to M&A that accelerates our road map. We are not stuck on a certain size company, although the ones that we have acquired thus far this year are small in nature. But we basically ask ourselves whether a company can help us accelerate a road map. If they do, then we're interested, but we don't have anything to share specifically today.
Suhasini Chandramouli:
All right. Thank you, Atif. A replay of today's call will be available for 2 weeks on Apple Podcasts, as a webcast on apple.com/ investor and via telephone. The number for the telephone replay is (866) 583-1035. Please enter confirmation code 6287473 followed by the pound sign. These replays will be available by approximately 5 p.m. Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at (408) 862-1142. And financial analysts can contact me, Suhasini Chandramouli with additional questions at (408) 974-3123. Thanks again for joining us today.
Operator:
Once again, this does conclude today's conference. We do appreciate your participation."
Microsoft Corporation (MSFT),Q1,2025,Microsoft (MSFT) Q1 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2024/10/30/microsoft-msft-q1-2025-earnings-call-transcript/,"Microsoft
(
MSFT
+1.52%
)
Q1 2025 Earnings Call
Oct 30, 2024
,
5:30 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Operator
Greetings, and welcome to the Microsoft Fiscal Year 2025 first-quarter earnings conference call. [Operator instructions] As a reminder, this conference is being recorded. It is now my pleasure to introduce your host, Brett Iversen, vice president of investor relations. Please go ahead.
Brett Iversen
--
Vice President, Investor Relations
Good afternoon, and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer; Amy Hood, chief financial officer; Alice Jolla, chief accounting officer; and Keith Dolliver, corporate secretary and deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. We have recast certain prior period amounts to reflect the FY '25 changes to the composition of our segments announced in August 2024.
Additional details, including FY '23 and FY '24 recast segment revenue, operating income, and product and service level revenue can be found in the financial statements filed on the Investor Relations website. More detailed outlook slides will also be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.
They are included as additional clarifying items to aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only.
We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website.
During this call, we'll be making forward-looking statements, which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the Risk Factors section of our Form 10-K, Forms 10-Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement.
And with that, I'll turn the call over to Satya.
Satya Nadella
--
Chair and Chief Executive Officer
Thank you, Brett. We are off to a solid start to our fiscal year, driven by continued strength of Microsoft Cloud, which surpassed $38.9 billion in revenue, up 22%. AI-driven transformation is changing work, work artifacts and workflow across every role, function, and business process, helping customers drive new growth and operating leverage. All up, our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, which will make it the fastest business in our history to reach this milestone.
Now I'll highlight examples of our progress starting with infrastructure. Azure took share this quarter. We are seeing continued growth in cloud migration. Azure Arc now has over 39,000 customers across every industry, including American Tower, CTT, L'Oréal, up more than 80% year-over-year.
We now have data centers in over 60 regions around the world. And this quarter, we announced new cloud and AI infrastructure investments in Brazil, Italy, Mexico, and Sweden as we expand our capacity in line with our long-term demand signals. At the silicon layer, our new Cobalt 100 VMs are being used by companies like Databricks, Elastic, Siemens, Snowflake and Synopsys to power their general-purpose workloads at up to 50% better price performance than previous generations. On top of this, we are building out our next-generation AI infrastructure, innovating across the full stack to optimize our fleet for AI workloads.
We offer the broadest selection of AI accelerators, including our first-party accelerator, Maia 100 as well as the latest GPUs from AMD and NVIDIA. In fact, we are the first cloud to bring up NVIDIA's Blackwell system with GB200-powered AI servers. Our partnership with OpenAI also continues to deliver results. We have an economic interest in a company that has grown significantly in value, and we have built differentiated IP and are driving revenue momentum.
More broadly with Azure AI, we are building an end-to-end app platform to help customers build their own copilots and agents. Azure OpenAI usage more than doubled over the past 6 months as both digital natives like Grammarly and Harvey as well as established enterprises like Bajaj Finance, Hitachi, KT, and LG move apps from test to production. GE Aerospace, for example, used Azure OpenAI to build a new digital assistant for all 52,000 of its employees. In just 3 months, it has been used to conduct over 500,000 internal queries and process more than 200,000 documents.
And this quarter, we added support for OpenAI's newest model family, o1. We're also bringing industry-specific models through Azure AI, including a collection of best-in-class multimodal models for medical imaging. And with the GitHub models, we now provide access to our full model catalog directly within the GitHub developer workflow. Azure AI is also increasingly an on-ramp to our data and analytics services.
As developers build new AI apps on Azure, we have seen an acceleration of Azure Cosmos DB and Azure SQL DB hyperscale usage as customers like Air India, Novo Nordisk, Telefonica, Toyota Motor North America and Uniper take advantage of capabilities purpose built for AI applications. And with Microsoft Fabric, we provide a single AI-powered platform to help customers like Chanel, EY, KPMG, Swissair and Syndigo unify their data across clouds. We now have over 16,000 paid Fabric customers, over 70% of the Fortune 500. Now on to developers.
GitHub Copilot is changing the way the world builds software. Copilot enterprise customers increased 55% quarter-over-quarter as companies like AMD and Flutter Entertainment tailor Copilot to their own code base. And we are introducing the next phase of AI code generation, making GitHub Copilot agentic across the developer workflow. GitHub Copilot Workspace is a developer environment, which leverages agents from start to finish so developers can go from spec to plan to code all in natural language.
Copilot Autofix is an AI agent that helps developers at companies like Asurion and Auto Group fix vulnerabilities in their code over three times faster than it would take them on their own. We're also continuing to build on GitHub's open platform ethos by making more models available via GitHub Copilot. And we are expanding the reach of GitHub to a new segment of developers introducing GitHub Spark, which enables anyone to build apps in natural language. Already, we have brought generative AI to Power Platform to help customers use low-code, no-code tools to cut costs and development time.
To date, nearly 600,000 organizations have used AI-powered capabilities in Power Platform, up four times year-over-year. Citizen developers at ZF, for example, built apps simply by describing what they need using natural language. And this quarter, we introduced new ways for customers to apply AI to streamline complex workflows with Power Automate. Now on to work.
We launched the next wave of Microsoft 365 Copilot innovation last month, bringing together web, work, and Pages as the new design system for knowledge work. Pages is the first new digital artifact for the AI age, and it's designed to help you ideate with AI and collaborate with other people. We've also made Microsoft 365 Copilot responses two times faster and improved response quality by nearly 3x. This innovation is driving accelerated usage, and the number of people using Microsoft 365 daily more than doubled quarter-over-quarter.
We are also seeing increased adoption from customers in every industry as they use Microsoft 365 Copilot to drive real business value. Vodafone, for example, will roll out Microsoft 365 Copilot to 68,000 employees after a trial showed that, on average, they save 3 hours per person per week. And UBS will deploy 50,000 seats in our largest finserve deal to date. And we continue to see enterprise customers coming back to buy more seats.
All up, nearly 70% of the Fortune 500 now use Microsoft 365 Copilot, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite. Copilot is the UI for AI, and with Microsoft 365 Copilot, Copilot Studio and agents and now autonomous agents, we have built an end-to-end system for AI business transformation. With Copilot Studio, organizations can build and connect Microsoft 365 Copilot to autonomous agents, which then delegate to Copilot when there is an exception. More than 100,000 organizations from Nsure, Standard Bank and Thomson Reuters to Virgin Money and Zurich Insurance have used Copilot Studio to date, up over two times quarter-over-quarter.
More broadly, we are seeing AI drive a fundamental change in the business applications market as customers shift from legacy apps to AI-first business processes. Dynamics 365 continues to take share as organizations like Evron, Heineken and Lexmark chose our apps over other providers. And monthly active users of Copilot across our CRM and ERP portfolio increased over 60% quarter-over-quarter. Our Dynamics 365 contact center is also winning customers like Currys, Le Creuset and RXO as it brings generative AI to every customer engagement channel.
And just last week, we added 10 out-of-the-box autonomous agents to Dynamics 365 that helps customers automatically qualify sales leads, track suppliers and work hand in hand with service reps to resolve issues. We're also bringing AI to industry-specific workflows. One year in, DAX Copilot is now documenting over 1.3 million physician-patient encounters each month at over 500 healthcare organizations like Baptist Medical Group, Baylor Scott & White, Greater Baltimore Medical Center, Novant Health and Overlake Medical Center. It is showing faster revenue growth than GitHub Copilot did in this first year.
And new features extend DAX beyond notes, helping physicians automatically draft referrals, after-visit instructions, and diagnostic evidence. On top of all this AI innovation, Microsoft Teams usage remains at all-time highs as people use it to streamline all their communications. Nearly 75% of our Teams Enterprise customers now buy Premium, Phone or Rooms. When it comes to Windows, our new class of Copilot+ PCs is winning new customers.
They offer best-in-class AI capability, performance, and value. AMD, Intel, and Qualcomm now all support Copilot+ PCs. This quarter, we also introduced new AI experience only available on Copilot+ PCs like Click to Do, which places an interactive overlay over your desktop to suggest next best actions. And as we approach the end of support for Windows 10 a year from now, we are well positioned to transition our customers to Windows 11, ensuring they benefit from enhanced features and security improvements we've introduced over the past few years.
Now on to security. We continue to prioritize security above all else. With our Secure Future Initiative, we have dedicated the equivalent of 34,000 full-time engineers to address the highest-priority security tasks. We have made significant progress to better protect tenants' identities, networks, and engineering systems, and we have created new processes to ensure security is prioritized at every level of the company.
And we continue to take what we learn and turn it into innovations across our products. Security Copilot, for example, is being used by companies in every industry, including Clifford Chance, Intesa Sanpaolo, and Shell to perform SecOps tasks faster and more accurately. And we are now helping customers protect their AI deployments, too. Customers have used Defender to discover and secure more than 750,000 GenAI app instances and used Purview to audit over 1 billion Copilot interactions to meet their compliance obligations.
And all up, we continue to take share across all major categories we serve and are consistently recognized by top analysts as a leader in 20 categories more than any other vendor. Now let me turn to our consumer businesses, starting with LinkedIn. Member growth continues to accelerate with markets in India and Brazil both growing at double digits. We are also seeing record engagement as we introduce new ways for our more than 1 billion members to connect, sell services, get hired and share knowledge.
Our investments in rich formats like video strengthen our leadership in B2B advertising and amplify the value we deliver to our customers. Weekly immersive video views increased six times quarter-over-quarter, and total video viewership on LinkedIn is up 36% year-over-year. Our AI-powered tools also continue to transform how people sell, learn and hire. In Sales, new AI features help every team member perform at the level of top sellers and drive more profitable growth.
In Learning, just yesterday, we announced updates to our coaching experience, including personalized career development plans. LinkedIn's first agent hiring assistant will help hirers find qualified candidates faster by tackling the most time-consuming task. Already hirers who use AI assistant messages see a 44% higher acceptance rate compared to those who don't. And our hiring business continues to take share.
Now on to Search, Advertising and News. With Copilot, we are seeing the first step toward creating a new AI companion for everyone with new Copilot experience we introduced earlier this month, includes a refreshed design and tone along with improved speed and fluency across the web and mobile. And it includes advanced capabilities like voice and vision that make it more delightful and useful and feel more natural. You can both browse and converse with Copilot simultaneously because Copilot sees what you see.
More broadly, AI is also transforming search, browsers, and digital advertising, and we continue to take share across Bing and Edge. Bing ex TAC revenue growth outpaced the search market. Now on to Gaming. One year since we closed our acquisition of Activision Blizzard King, we are focused on building a business positioned for long-term growth, driven by higher-margin content and services.
You already see this transformation in our results as we diversify the ways that gamers access our content. We set new records for monthly active users in the quarter as more players than ever play our games across devices and on the Xbox platform. Game Pass also set a new Q1 record for total revenue and average revenue per subscriber. And as we look ahead, our IP across our studios has never been stronger.
Last week's launch of Black Ops 6 was the biggest Call of Duty release ever, setting a record for day 1 players as well as Game Pass subscriber adds on launch day. And unit sales on PlayStation and Steam were also up over 60% year-over-year. This speaks to our strategy of meeting gamers where they are by enabling them to play more games across the screens they spend their time on. In closing, we are rapidly innovating to expand our opportunity across our commercial and consumer businesses.
In 3 weeks' time, we will hold our Ignite Conference, and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era. With that, let me turn it over to Amy.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thank you, Satya. And good afternoon, everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%. With strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom line growth.
We also saw continued share gains across many of our businesses. In our commercial business, increased demand, and growth in long-term commitments to our Microsoft Cloud platform drove our results. Commercial bookings were ahead of expectations and increased 30% and 23% in constant currency. Results were driven by strong execution across our core annuity sales motions and growth in the number of $10 million-plus contracts for both Azure and Microsoft 365.
Additionally, we also saw an increase in the number of $100-million-plus contracts for Azure. Commercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion. Roughly 40% will be recognized in revenue in the next 12 months, up 17% year-over-year. The remaining portion, recognized beyond the next 12 months, increased 27%.
And this quarter, our annuity mix increased to 98%. In addition to commercial results that were in line with expectations, we also saw some benefit from in-period revenue recognition across Microsoft 365 commercial, Azure, and our on-premises server business. At a company level, Activision contributed a net impact of approximately 3 points to revenue growth with a 2 point drag on operating income growth and had a negative $0.05 impact to earnings per share. A reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third-party partner to first-party and includes $911 million from purchase accounting adjustments, integration, and transaction-related cost.
FX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, segment-level revenue, COGS, and operating expense growth. Microsoft Cloud revenue was $38.9 billion and grew 22%, roughly in line with expectations. Microsoft Cloud gross margin percentage decreased 2 points year-over-year to 71%. This was slightly better than expected due to improvement in Azure, although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure.
Company gross margin dollars increased 13% and 14% in constant currency, and gross margin percentage was 69%, down 2 points year-over-year, driven by the lower Microsoft Cloud gross margin noted earlier as well as the impact from purchase accounting adjustments, integration, and transaction-related costs from the Activision acquisition. Operating expenses increased 12%, lower than expected due to our focus on cost efficiencies and ongoing prioritization work. Operating expense growth included 9 points from the Activision acquisition. At a total company level, headcount at the end of September was 8% higher than a year ago.
Excluding the growth from the Activision acquisition, headcount was 2% higher. Operating income increased 14% and operating margins were 47%, down 1 point year-over-year. Excluding the net impact from the Activision acquisition, operating margins were up 1 point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities. Now to our segment results.
Revenue from Productivity and Business Processes was $28.3 billion and grew 12% and 13% in constant currency, ahead of expectations, driven by better-than-expected results across all businesses. M365 commercial cloud revenue increased 15% and 16% in constant currency with business trends that were as expected. The better-than-expected result was due to a small benefit from the in-period revenue recognition noted earlier. ARPU growth was primarily driven by E5 as well as M365 Copilot.
Paid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments. Seat growth was driven by our small and medium business and frontline worker offerings. M365 commercial cloud revenue represents nearly 90% of total M365 commercial products and cloud services. M365 commercial products revenue increased 2% and 3% in constant currency, ahead of expectations, primarily due to the benefit from in-period revenue recognition noted earlier.
M365 consumer products and cloud services revenue increased 5% and 6% in constant currency. M365 consumer cloud revenue increased 6% and 7% in constant currency, with continued momentum in M365 consumer subscriptions, which grew 10% to 84.4 million. M365 consumer cloud revenue represents 85% of total M365 consumer products and cloud services. LinkedIn revenue increased 10% and 9% in constant currency, slightly ahead of expectations with growth across all lines of business.
Dynamics revenue grew 14%, driven by Dynamics 365, which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains. As a reminder, Dynamics 365 represents about 90% of total Dynamics revenue. Segment gross margin dollars increased 11% and 12% in constant currency, and gross margin percentage decreased slightly year-over-year, driven by scaling our AI infrastructure. Operating expenses increased 2%, and operating income increased 16%.
Next, the Intelligent Cloud segment. Revenue was $24.1 billion, increasing 20% and 21% in constant currency, in line with expectations. Azure and other cloud services revenue grew 33% and 34% in constant currency, with healthy consumption trends that were in line with expectations. The better-than-expected result was due to the small benefit from in-period revenue recognition noted earlier.
Azure growth included roughly 12 points from AI services similar to last quarter. Demand continues to be higher than our available capacity. Non-AI growth trends were also in line with expectations in total and across regions as customers continued to migrate and modernize on the Azure platform. The non-AI point contribution to Azure growth was sequentially lower by approximately 1 point.
In our on-premises server business, revenue decreased 1%. Lower-than-expected transactional purchasing ahead of the Windows Server 2025 launch as well as lower purchasing of licenses running in multi-cloud environments was mostly offset by the benefit from in-period revenue recognition noted earlier. Enterprise and partner services revenue decreased 1% and was relatively unchanged in constant currency. Segment gross margin dollars increased 15%, and gross margin percentage decreased 3 points year-over-year, driven by scaling our AI infrastructure.
Operating expenses increased 8% and operating income grew 18%. Now to More Personal Computing. Revenue was $13.2 billion, increasing 17% with 15 points of net impact from the Activision acquisition. Results were above expectations, driven by Gaming and Search.
Windows OEM and Devices revenue increased 2% year-over-year as better-than-expected results in Windows OEM due to mix shift to higher monetizing markets was partially offset by the lower-than-expected results in devices due to execution challenges in the commercial segment. Search and news advertising revenue ex TAC increased 18% and 19% in constant currency ahead of expectations, primarily due to continued execution improvement. We saw rate expansion in addition to healthy volume growth in both Edge and Bing. And in Gaming, revenue increased 43% and 44% in constant currency with 43 points of net impact from the Activision acquisition.
Results were ahead of expectations, driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition. Segment gross margin dollars increased 16% and 17% in constant currency with 12 points of net impact from the Activision acquisition. Gross margin percentage was relatively unchanged year-over-year.
Our strong execution on margin improvement in gaming and search was offset by sales mix shift to those businesses. Operating expenses increased 49% with 51 points from the Activision acquisition. Operating income decreased 4%. Now back to total company results.
Capital expenditures including finance leases were $20 billion, in line with expectations, and cash paid for PP&E was $14.9 billion. Roughly half of our cloud and AI-related spend continues to be for long-lived assets that will support monetization over the next 15 years and beyond. The remaining cloud and AI spend is primarily for servers, both CPUs and GPUs, to serve customers based on demand signals. Cash flow from operations was $34.2 billion, up 12%, driven by strong cloud billings and collections, partially offset by higher supplier employee and tax payments.
Free cash flow was $19.3 billion, down 7% year-over-year, reflecting higher capital expenditures to support our cloud and AI offerings. This quarter, other income expense was negative $283 million, significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments. Our losses on investments accounted for under the equity method were as expected. Our effective tax rate was approximately 19%.
And finally, we returned $9 billion to shareholders through dividends and share repurchases. Now moving to our Q2 outlook, which, unless specifically noted otherwise, is on a U.S. dollar basis. First, FX.
With the weaker U.S. dollar and assuming current rates remain stable, we expect FX to increase total revenue and segment level revenue growth by less than 1 point. We expect FX to have no meaningful impact to COGS or operating expense growth. Our outlook has many of the trends we saw in Q1 continue through Q2.
Customer demand for our differentiated solutions should drive another quarter of strong growth. In commercial bookings, we expect strong growth on a growing expiry base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 70%, down year-over-year, driven by the impact of scaling our AI infrastructure.
We expect capital expenditures to increase on a sequential basis given our cloud and AI demand signals. As I said last quarter, we will stay aligned and if needed, adjust to the demand signals we see. As a reminder, there can be quarterly spend variability from cloud infrastructure build-outs and the timing of delivery of finance leases. Next, segment guidance, starting with Productivity and Business Processes.
We are the market leader when it comes to knowledge-based copilots and agents in the enterprise space, and we are focused on continuing to gain share across our productivity solutions. Therefore, we expect revenue in Productivity and Business Processes to grow between 10% and 11% in constant currency or USD 28.7 billion to USD 29 billion. M365 commercial cloud revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and ARPU growth through E5 and M365 Copilot. For H2, we expect revenue growth to remain relatively stable compared to Q2.
We continue to see growth in M365 Copilot seats, and we expect the related revenue to continue to grow gradually over time. For M365 commercial products, we expect revenue to decline in the low single digits. As a reminder, M365 commercial products include on-premises components of M365 suites, so our quarterly revenue growth can have variability primarily from in-period revenue recognition depending on the mix of contracts. M365 consumer cloud revenue growth should be in the mid-single digits driven by M365 subscriptions.
For LinkedIn, we expect revenue growth of approximately 10%, driven by continued growth across all businesses. And in Dynamics 365, we expect revenue growth to be in the mid- to high teens, driven by continued growth across all workloads. Next, Intelligent Cloud. Helping our customers transform and grow with innovative cloud and AI solutions is driving continued growth in Azure.
Therefore, we expect revenue in Intelligent Cloud to grow between 18% and 20% in constant currency or USD 25.55 billion to USD 25.85 billion. Revenue will continue to be driven by Azure, which, as a reminder, can have quarterly variability primarily from in-period revenue recognition depending on the mix of contracts. In Azure, we expect Q2 revenue growth to be 31% to 32% in constant currency, driven by strong demand for our portfolio of services. We expect consumption growth to be stable compared to Q1, and we expect to add more sequential dollars to Azure than any other quarter in history.
We expect the contribution from AI services to be similar to last quarter, given the continued capacity constraints as well as some capacity that shifted out of Q2. And in H2, we still expect Azure growth to accelerate from H1 as our capital investments create an increase in available AI capacity to serve more of the growing demand. And in our on-premises server business, we expect revenue to decline in the low to mid-single digits on a prior year comparable that benefited from purchasing ahead of Windows Server 2012 end of support. And in Enterprise and partner services, we expect revenue growth to be in the low single digits.
Now to More Personal Computing. We continue to make decisions to prioritize strategic higher-margin opportunities within each of our consumer businesses. Our outlook reflects the improvement in gross and operating margins from this prioritization work across gaming, search, and devices. We expect revenue in More Personal Computing to be USD 13.85 billion to USD 14.25 billion.
Windows OEM and devices revenue should decline in the low to mid-single digits. We expect Windows OEM revenue growth in line with the PC market to be more than offset by a decline in devices as the trends from Q1 continue. Search and news advertising ex TAC revenue growth should be in the high teens, with continued growth in both volume and revenue per search. This will be higher than overall search and news advertising revenue growth, which we expect to be in the high single digits.
And in Gaming, we expect revenue to decline in the high single digits due to hardware. We expect Xbox content and services revenue growth to be relatively flat. We're excited about last week's launch of Call of Duty, where we saw the most Game Pass subscriber adds we've ever seen on a launch day. There are two things about the launch that are different than the Call of Duty launch a year ago, where revenue was mostly recognized in the quarter of purchase.
First, the game is available on Game Pass, so for players who play through Game Pass, the subscription revenue is recognized over time. Second, the game requires an online connection to play, so even for players who purchased the stand-alone game, revenue recognition will also occur ratably over time. Now back to company guidance. We expect COGS to grow between 11% and 13% in constant currency or to be between USD 21.9 billion to USD 22.1 billion, and operating expense to grow approximately 7% in constant currency or to be between USD 16.4 billion and USD 16.5 billion.
This should result in another quarter of operating margin expansion. Other income and expense is expected to be roughly negative $1.5 billion, primarily driven by our share of the expected loss from OpenAI, which is accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. As you heard from Satya, our strategic partnership and investment in OpenAI has been pivotal in building and scaling our AI business and positioning us as the leader in the AI platform wave.
And lastly, we expect our Q2 effective tax rate to be approximately 19%. In closing, we remain focused on strategically investing in the long-term opportunities that we believe drive shareholder value. Monetization from these investments continues to grow, and we're excited that only 2.5 years in, our AI business is on track to surpass $10 billion of annual revenue run rate in Q2. This will be the fastest business in our history to reach this milestone.
We are committed to growing this leadership position across our entire Microsoft Cloud while maintaining our disciplined focus on cost management and prioritization across every team. With that, let's go to Q&A, Brett.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Amy. We'll now move over to Q&A. [Operator instructions] Operator, can you please repeat your instructions?
Questions & Answers:
Operator
[Operator instructions] Our first question comes from the line of Keith Weiss with Morgan Stanley. Please go ahead.
Keith Weiss
--
Analyst
Excellent. Thank you, guys, for taking the questions. Congratulations on a really solid quarter. So Satya, the expansion of capabilities, the speed of innovation, the magnitude of the opportunities ahead for generative AI makes this the most exciting period for software I've seen in my 25 years of covering this space.
And based upon this call, it seems like you share that excitement. But in my investor conversation, that excitement also feeds two related questions, and they both have to do with constraints. And the first is like what are the internal constraints or guardrails that Microsoft has when it comes to investing behind these innovations, particularly in relation to the funding of future generations of foundational models, where people are talking about price tags using the tens of billions or even $100 billion plus. And then on the other side of the spectrum, what are the external constraints that Microsoft sees in building out this capacity to meet the demand and capture the opportunity, particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion? I'd love to get the Microsoft perspective on both those questions.
Satya Nadella
--
Chair and Chief Executive Officer
Thank you, Keith, for those questions. I think on the first point, ultimately, when you think about, let's say, capital outlay for training because that's essentially what you're asking, it is going to be rate limited by your monetization of inference in a given generation, right? So just like in the past, we would allocate capital to build out cloud based on the demand signal we were seeing and then we would then project the demand, and that's what we would build it for. So you can think of training essentially as that, right, which is you're building the next-generation model so that then you have a more capable model that then drives more inference demand, right? So ultimately -- even with all the scaling laws and what have you, I think you ultimately will normalize to having a pace. In fact, I think the best way to think about even is given that Moore's Law effectively is working on the sort of silicon and system side, so it's just not compute, right? It's efficiencies in compute.
It's data as well as algorithms. You will want to sort of keep on that curve, which is you really want to refresh your fleet with the Moore's Law every year and then effectively depreciate it over the period of the life cycle of it. And then the inference demand ultimately will govern how much we invest in training because that's, I think, at the end of the day, you're all subject to ultimately demand. The second piece of the external constraints, we have run into obviously lots of external constraints because this demand all showed up pretty fast, right? I mean if you think about even the most hit product of this generation, all are in our cloud, right, whether it's ChatGPT, whether it's Copilot, whether it's GitHub Copilot or even DAX Copilot.
I mean pick the top 4 or 5 products of this generation. They're all sort of in and around our ecosystem. And so therefore, we ran into a set of constraints, which are everything because DCs don't get built overnight. So there is DCs.
There is power. And so that's sort of been the short-term constraint. Even in Q2, for example, some of the demand issues we have -- or our ability to fulfill demand is because of, in fact, external third-party stuff that we leased moving out. So that's the constraints we have.
But in the long run, we do need effectively power and we need DCs. And some of these things are more long lead. But I feel pretty good that going into the second half of even this fiscal year, that some of that supply/demand will match up.
Keith Weiss
--
Analyst
Excellent. Thank you, guys.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Keith. Operator, next question please.
Operator
The next question comes from the line of Brent Thill with Jefferies.
Brent Thill
--
Analyst
Thanks, Amy. Good to hear the reacceleration in the back half for Azure. I guess many are asking, 34% growth in Q1 falling to low 30s. I know the comp is a couple of points harder.
But is there anything else you're contemplating in that guide for Q2 to see that deceleration other than a tougher comp? Thank you.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thanks, Brent. Maybe this is a great question because I can sort of reiterate some of the points I made and tie them together a little bit. In Q1, the 34% in CC, we talked about that upside versus the 33% that we had guided to was primarily due to some revenue recognition benefits. And so I think about that on a sort of a pure consumption basis and AI as being 33%.
And you think about 1 point or 2 of decel that we've guided to, and the majority of that is due to, unfortunately, some supply pushouts that I mentioned and then Satya reiterated in terms of AI supply coming online that we counted on. The underlying consumption growth is stable Q1 to Q2. And so to your question on some ins and outs, it is certainly some ins and outs. I do, as you heard, have confidence, as we get a good influx of supply across the second half of the year particularly on the AI side, that we'll be better able to do some supply demand matching and hence, while we're talking about acceleration in the back half.
I'll also take the opportunity to say, when you see usage in AI workloads, we always intend to think about that as just a GPU exercise. The importance of having GPUs and CPUs be able to run these workloads is also important. So that's a piece of the acceleration in H2 as well.
Brent Thill
--
Analyst
Thanks.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Brant. Operator, next question please.
Operator
The next question comes from the line of Mark Moerdler with Bernstein. Please proceed.
Mark Moerdler
--
Analyst
Thank you very much for taking my question. Congratulations on the quarter. The question every investor obviously asks is a question on the capex growth and the capex spend. Obviously, half of that facility is an equivalent that have a longer life, but the other half is the rest of the components.
Can you give any color on how you think of that growth? Does it return to the traditional approach, where basically capex is going to grow in line or slightly slower than cloud revenue? And if so, any sense of the timing? Do we have enough facilities online by sometime next year, et cetera? Any color would be appreciated.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thanks, Mark. I think in some ways, it's helpful to go back to the cloud transition that we worked on over a decade ago, I think, in the early stages. And what you did see, and you'll see us do in the same time is you have to build to meet demand. Unlike the cloud transition, we're doing it on a global basis in parallel as opposed to sequential given the nature of the demand.
And then as long as we continue to see that demand grow, you're right, the growth in capex will slow and the revenue growth will increase. And those 2 things, to your point, get closer and closer together over time. The pace of that entirely depends really on the pace of adoption. And to Satya's point, some of that spend goes toward building the next training infrastructure so you won't see all of it in COGS.
Some of it goes to opex when you're spending it on training. But in general, that's a healthy way to think about the balance as that over time does do and should, like the last cycle, get closer together.
Mark Moerdler
--
Analyst
Thank you very much. That's very helpful.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Mark. Operator, next question please.
Operator
The next question comes from the line of Karl Keirstead with UBS. Please proceed.
Karl Keirstead
--
Analyst
OK. Great. Thank you. I'm actually not going to ask a question about the numbers, but Satya and Amy, I'd love to ask a question about OpenAI.
Since the print 3 months ago, we, investors have been hit with a torrent of media stories about OpenAI and Microsoft. And I'd love to give Microsoft an opportunity to frame the relationship. It seems to me it's critically important. But we have been, I think, everyone on the line, picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and offer customers choice.
So Satya, I'd love to get your framing of the relationship. And then in terms of the numbers, maybe this is a little bit more for you, Amy. But how does Microsoft manage the demands on capex from helping OpenAI with its scaling ambitions? And how do you manage the impact on other income that you just gave us some color on?
Satya Nadella
--
Chair and Chief Executive Officer
Sure. Thanks, Karl. So I'd say, first, the partnership for both sides, that's OpenAI and Microsoft, has been super beneficial. After all, we were the -- we effectively sponsored what is one of the most highest-valued private companies today when we invested in them and really took a bet on them and their innovation 4, 5 years ago.
And that has led to great success for Microsoft. That's led to great success for OpenAI. And we continue to build on it, right? So we serve them with world-class infrastructure on which they do their innovation in terms of models, on top of which we innovate on both the model layer with some of the post-training stuff we do as well as some of the small models we build and then, of course, all of the product innovation, right? One of the things that my own sort of conviction of OpenAI and what they were doing came about when I started seeing something like GitHub Copilot as a product get built or DAX Copilot get built or M365 Copilot get built. So we have a fantastic portfolio of innovation that we build on top of that.
And the same also, I would say, we are investors. We feel very, very good about sort of our investment stake in OpenAI. And so our focus -- and we're always in constant dialogue with them in a partnership like this where both sides have achieved mutual success at the pace at which we've achieved it. That means we need to kind of push each other to do more, to capture the moment, and that's what we plan to do, and we intend to keep building on it.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
And maybe to your other two questions, Karl, listen, I'm thrilled with their success and need for supply from Azure and infrastructure and really what it's meant in terms of being able to also serve other customers for us. It's important that we continue to invest capital to meet not only their demand signal and needs for compute but also from our broader customers. That's partially why you've seen us committing the amount of capital we've seen over the past few quarters, is our commitment to both grow together and for us to continue to grow the Azure platform for customers beyond them. And so I don't really think of it as how do you balance it.
It's just we have customers who have needs and real use cases and delivering value today. And if we can't meet that, we need to work to meet it. And that means working harder and faster to make sure we do that, which is what the team is committed to do. Second piece of your question, I think, was on the impact to other income.
And not to get too accounting heavy on the earnings phone call, but I would say, just a reminder, this is under the equity method, which means we just take our percentage of losses every quarter. And those losses, of course, are capped by the amount of investment we make in total, which we did talk about in the Q this quarter as being $13 billion. And so over time, that's just the constraint, and it's a bit of a mechanical entry. And so I don't really think about managing that.
That's the investment and acceleration that OpenAI is making in themselves, and we take a percentage of that.
Karl Keirstead
--
Analyst
Got it. OK. Very helpful. Thank you both.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Karl. Operator, next question please.
Operator
The next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.
Kash Rangan
--
Analyst
Hi. Thank you very much. Satya, when you talked about the investment cycle, these models are getting bigger, more expensive, but you also pointed out to how in the inference phase, we're likely to get paid. How does that cycle look like in inference for Microsoft? Where are the products and the applications that will show up on the Microsoft P&L as a result of the inference phase of AI kicking in?
Satya Nadella
--
Chair and Chief Executive Officer
Thanks, Kash. I mean the good news for us is that we're not waiting for that inference to show up, right? If you sort of think about the point we even made that this is going to be the fastest growth to $10 billion of any business in our history, it's all inference, right? One of the things that may not be as evident is that we're not actually selling raw GPUs for other people to train. In fact, that's sort of a business we turn away because we have so much demand on inference that we are not taking what I would -- in fact, there's a huge adverse selection problem today where people -- it's just a bunch of tech companies still using VC money to buy a bunch of GPUs. We kind of really are not even participating in most of that because we are literally going to the real demand, which is in the enterprise space or our own products like GitHub Copilot or M365 Copilot.
So I feel the quality of our revenue is also pretty superior in that context. And that's what gives us even the conviction, to even Amy's answers previously, about our capital spend, is if this was just all about sort of a bunch of people training large models and that was all we got, then that would be ultimately still waiting, to your point, for someone to actually have demand, which is real. And in our case, the good news here is we have a diversified portfolio. We're seeing real demand across all of that portfolio.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
And Kash, maybe just to add a little bit to what Satya is saying. I think a part of his 2 answers is that what you're seeing is this number we're talking about, the $10 billion, across inference and our apps is already what that momentum and that investment and that progress and that revenue is what builds the next cycle of training, right? And so it's that circle as opposed to, oh, we're doing training now and then inference. Much of the training investments that are -- that fuel this revenue growth came before, and we already funded that work. And so that's an important part.
Kash Rangan
--
Analyst
That's, to your point, that you invest now, and you can get the growth later even if you slow down the capex, right? That's what you're trying to tell us.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
That's the cycle that is important to understand.
Kash Rangan
--
Analyst
Got it. Thank you so much.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Kash. Operator, next question please.
Operator
The next question comes from the line of Mark Murphy with J.P. Morgan. Please proceed.
Mark Murphy
--
Analyst
Thank you very much. I'm wondering if you can shed any more light just on the nature of the supply limitations that you're mentioning that are impacting Azure in Q2, where that impact might be incrementally just a touch more than we expected. Is it more the GPU supply? Is there some element of power cooling or the ability to wire up the networks? And Amy, should we infer that the supply is constraining Azure growth by roughly a couple of few points in Q2? Or am I overestimating that?
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Maybe to answer both those questions, Mark, very directly, I wouldn't think about it component logic in my Q2 answer. The supply pushout, as Satya said, was third parties that are delivering later than we had expected, that get pushed mainly into the second half of the year and in general, Q3. So that's third parties where we have tended to buy supply inclusive of kits, so it's complete end-to-end third-party delivery. In terms of the impact, as I was saying, when you think about having flat consumption Q1 to Q2, there really are only 2 things that impact that difference, and 1 was the help we got in Q1 from the revenue and accounting help.
And then Q2 has been the supply pushout.
Mark Murphy
--
Analyst
Thank you.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Mark. Operator, next question please.
Operator
The next question comes from the line of Raimo Lenschow with Barclays. Please proceed.
Raimo Lenschow
--
Analyst
Thank you. If you talk about the market at the moment -- because you were first with Copilot, you had identified a lot with copilots and now we're talking agents. Can you kind of -- Satya, how do you think about that? And to me, it looks like an evolution that we're discovering how to kind of productize AI better, et cetera. So how do you think about that journey between copilots, agents and maybe what's coming next?
Satya Nadella
--
Chair and Chief Executive Officer
Sure. The system we have built is Copilot, Copilot Studio, agents, and autonomous agents. You should think of that as the spectrum of things, right? So ultimately, the way we think about how this all comes together is you need humans to be able to interface with AI. So the UI layer for AI is Copilot.
You can then use Copilot Studio to extend Copilot. For example, you want to connect it to your CRM system, to your office system, to your HR system. You do that through Copilot Studio by building agents effectively. You also build autonomous agents.
So you can use even -- that's the announcement we made a couple of weeks ago, is you can even use Copilot Studio to build autonomous agents. Now these autonomous agents are working independently, but from time to time, they need to raise an exception, right? So autonomous agents are not fully autonomous because, at some point, they need to either notify someone or have someone input something. And when they need to do that, they need a UI layer, and that's where, again, it's Copilot. So Copilot, Copilot agents built-in Copilot Studio, autonomous agents built in Copilot Studio, that's the full system, we think, that comes together, and we feel very, very good about the position.
And then, of course, we are taking the underlying system services across that entire stack that I just talked about, making it available in Azure, right? So you have the raw infrastructure if you wanted. You have the model layer independent of it. You have the AI app server in Azure AI, right? So everything is also a building block service in Azure for you to be able to build. In fact, if you want to build everything that we have built in the Copilot stack, you can build it yourself using the AI platform.
So that's sort of, in simple terms, our strategy, and that's kind of how it all comes together.
Raimo Lenschow
--
Analyst
OK. Perfect. Very clear.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Raimo. Operator, we have time for one last question.
Operator
And the last question will come from the line of Rishi Jaluria with RBC. Please proceed.
Rishi Jaluria
--
Analyst
Wonderful. Thanks. Hi, Satya. Hi, Amy.
Appreciate the question. I want to go and think a little bit about Copilot, how we should be thinking about kind of numbers here with the recategorization. It seems like that was maybe softer in the past than expected or maybe with the numbers this quarter starting to pick up. Can you maybe walk us through what you're seeing on that and maybe more importantly, how we should be thinking about your overall AI strategy on consumer versus enterprise, especially now with Moustafa on the fold?
Satya Nadella
--
Chair and Chief Executive Officer
Yes. On the first part, Rishi, to your question, I think we feel very, very good about the momentum we have in the commercial Copilot, right? As I said in my remarks and Amy talked about, this is the fastest growth of a new suite in M365. If I compare it to what we saw even back -- way back in E3 or E5 or the transition from O to M, this is really much faster, right? It's the numbers of penetration of the Fortune 500 and then the fact that they're coming back for more seats and what have you. So it's very strong in that context.
The other thing I'd also mention is that we want this to be something that is systemic, right, because people need to be able to put the security controls. Then they need to deploy. Then there's skilling, and then there's change management. So this is not like you just -- it's not a tool.
Like when I talk about Copilot, Copilot Studio, agents, it's really as much about a new way to work. And sometimes I describe it as what happened throughout the '90s with PC penetration. After all, if you take a business process like forecasting, what was it like pre email and Excel and post email and Excel? That's the type of change that you see with Copilot. But overall, we feel great about the rate of progress and the penetration.
And then on the consumer side, look, for us, the exciting part here is to be able to use the same investment we are making in the commercial where we have structural strength and then beyond the offense. One of the things that, I think, I hope you all catch in our earnings is ex TAC. Our revenue, when it comes to what we describe as search, news, and ads, is growing faster than market. So that's -- it's fantastic to see that.
And so that's kind of our consumer business, which in Microsoft's large scope, it's sort -- even a $10-plus billion business sort of sometimes go missing. But in our case, it is actually a fantastic growth business that's growing faster than market. We feel good about how we will use AI in LinkedIn. In fact, LinkedIn is a consumer business as you know.
You saw even this week, they announced some new capabilities for both consumers and in their case, even recruiting. So we think that AI, the same investment gets monetized even through LinkedIn's innovation. And gaming, of course, is another place where you'll see some of these things apply and Windows, right? So the place where I think I'm excited about is Copilot+ PCs. For us, it's not about having a disconnected edge.
It's about having hybrid AI where the rebirth of sort of the PC as the edge of AI is going to be one of the most exciting things for developers. So we feel well positioned, quite frankly, with the same investment. So this is -- that's the thing. We're not a conglomerate here.
We are sort of one company. That means we invest once, and then we have all these categories that benefit from that. And that's the theory of the firm for us. And so we feel good about all of that coming together.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
And maybe just to add one piece because I think, Rishi, now that I'm listening and thinking through the question, it feels like you're wondering, like why am I not seeing the Copilot, if you've made all this progress and the results, and the answer is you already are. In that M365 commercial number, we've seen that seat growth, but those seats that we're adding, the majority of them are driven by frontline worker and small businesses. Those have a lower ARPU point. And so it masks some of the ARPU that we're already seeing not just from E5, which continues to contribute, but also this quarter, additional impact from Copilot.
So as we go forward, being able -- that is where you're going to see the impact will be in ARPU in M365 commercial, and as Satya said, I think you'll see the impact of Copilot engagement, frankly, across the same ex TAC number.
Rishi Jaluria
--
Analyst
OK. Wonderful. Thank you.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Rishi. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with all of you again soon.
Operator
[Operator signoff]
Duration: 0 minutes
Call participants:
Brett Iversen
--
Vice President, Investor Relations
Satya Nadella
--
Chair and Chief Executive Officer
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Keith Weiss
--
Analyst
Brent Thill
--
Analyst
Amy Hood
--
Executive Vice President, Chief Financial Officer
Mark Moerdler
--
Analyst
Karl Keirstead
--
Analyst
Kash Rangan
--
Analyst
Mark Murphy
--
Analyst
Raimo Lenschow
--
Analyst
Rishi Jaluria
--
Analyst
More MSFT analysis
All earnings call transcripts"
Microsoft Corporation (MSFT),Q2,2025,Microsoft (MSFT) Q2 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/01/29/microsoft-msft-q2-2025-earnings-call-transcript/,"Microsoft
(
MSFT
+1.52%
)
Q2 2025 Earnings Call
Jan 29, 2025
,
5:30 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Operator
Greetings, and welcome to the Microsoft fiscal year 2025 second-quarter earnings conference call. At this time, all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. [Operator instructions] As a reminder, this conference is being recorded.
It is now my pleasure to introduce your host, Brett Iversen, vice president of investor relations. Please go ahead.
Brett Iversen
--
Vice President, Investor Relations
Good afternoon, and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer; Amy Hood, chief financial officer; Alice Jolla, chief accounting officer; and Keith Dolliver, corporate secretary and deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call.
In this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company's second-quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted.
We will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only. We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded.
If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward-looking statements, which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties.
Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the Risk Factors section of our Form 10-K, Form 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement. And with that, I'll turn the call over to Satya.
Satya Nadella
--
Chair and Chief Executive Officer
Thank you, Brett. This quarter, we saw continued strength in Microsoft Cloud, which surpassed $40 billion in revenue for the first time, up 21% year over year. Enterprises are beginning to move from proof of concepts to enterprisewide deployments to unlock the full ROI of AI. And our AI business has now surpassed an annual revenue run rate of $13 billion, up 175% year over year.
Before I get into the details of the quarter, I want to comment on the core thesis behind our approach to how we manage our fleet and how we allocate our capital to compute. AI scaling laws continue to compound across both pre-training and inference time compute. We ourselves have been seeing significant efficiency gains in both training and inference for years now. On inference, we have typically seen more than 2x price performance gain for every hardware generation and more than 10x for every model generation due to software optimizations.
And as AI becomes more efficient and accessible, we will see exponentially more demand. Therefore, much as we have done with the commercial cloud, we are focused on continuously scaling our fleet globally and maintaining the right balance across training and inference as well as geo-distribution. From now on, it's a more continuous cycle governed by both revenue growth and capability growth thanks to the compounding effects of software-driven AI scaling laws and Moore's Law. With that, I will walk through the progress we are making across every layer of the tech stack.
Azure is the infrastructure layer for AI. We continue to expand our data center capacity in line with both near-term and long-term demand signals. We have more than doubled our overall data center capacity in the last three years, and we have added more capacity last year than any other year in our history. Our data centers, networks, racks, and silicon are all coming together as a complete system to drive new efficiencies to power both the cloud workloads of today and the next-generation AI workloads.
We continue to take advantage of Moore's Law and refresh our fleet as evidenced by our support of the latest from AMD, Intel, NVIDIA, as well as our first-party silicon innovation from Maia, Cobalt, Boost, and HSM. When it comes to cloud migrations, we continue to see customers like UBS move workloads to Azure. UBS alone migrated mainframe workloads encompassing nearly 400 billion records and two petabytes of data. And we remain the cloud of choice for customers' mission-critical Oracle, SAP, and VMware apps.
At the data layer, we are seeing Microsoft Fabric break out. We now have over 19,000 paid customers from Hitachi to Johnson Controls to Schaeffler. Fabric is now the fastest-growing analytics product in our history. Power BI is also deeply integrated with Fabric with over 30 million monthly active users, up 40% since last year.
Beyond Fabric, we are seeing new AI-driven data patterns emerge. If you look underneath ChatGPT or Copilot or enterprise AI apps, you see the growth of raw storage, database services, and app platform services as these workloads scale. The number of Azure OpenAI apps running on Azure databases and Azure App Services more than doubled year over year, driving significant growth in adoption across SQL, hyperscale, and Cosmos DB. Now, on to AI platform and tools.
As we shared last week, we are thrilled OpenAI has made a new large Azure commitment. Through our strategic partnership, we continue to benefit mutually from each other's growth. And with OpenAI's APIs exclusively running on Azure, customers can count on us to get access to the world's leading models. And OpenAI has a lot more coming soon, so stay tuned.
Azure AI Foundry features best-in-class tooling run times to build agents, multi-agent apps, AIOps, API access to thousands of models. Two months in, we already have more than 200,000 monthly active users, and we are well positioned with our support of both OpenAI's leading models and the best selection of open-source models and SLMs. DeepSeek's R1 launched today via the model catalog on Foundry and GitHub with automated red teaming, content safety integration, and security scanning. Our Phi family of SLMs has now been downloaded over 20 million times.
And we also have more than 30 models from partners like Bayer, PAYG AI, Rockwell Automation, Siemens to address industry-specific use cases. With AI, how we build, deploy, and maintain code is fundamentally changing, and GitHub Copilot is increasingly the tool of choice for both digital natives like ASOS and Spotify as well as world's largest enterprises like HP, HSBC, and KPMG. We have been delighted by the early response to GitHub Copilot and VS Code with more than 1 million sign-ups in just the first week post launch. All up, GitHub now is home to 150 million developers, up 50% over the past two years.
Now, on to the future of work. Microsoft 365 Copilot is the UI for AI. It helps supercharge employee productivity and provides access to a swarm of intelligent agents to streamline employee workflow. We are seeing accelerated customer adoption across all deal sizes as we win new Microsoft 365 Copilot customers and see the majority of existing enterprise customers come back to purchase more seats.
When you look at customers who purchased Copilot during the first quarter of availability, they have expanded their seat collectively by more than 10x over the past 18 months. To share just one example, Novartis has added thousands of seats each quarter over the past year and now have 40,000 seats. Barclays, Carrier Group, Pearson, and University of Miami all purchased 10,000 or more seats this quarter. And overall, the number of people who use Copilot daily, again, more than doubled quarter over quarter.
Employees are also engaging with Copilot more than ever. Usage intensity increased more than 60% quarter over quarter, and we are expanding our TAM with Copilot Chat, which was announced earlier this month. Copilot Chat, along with Copilot Studio, is now available to every employee to start using agents right in the flow of work. With Copilot Studio, we are making it as simple to build an agent as it is to create an Excel spreadsheet.
More than 160,000 organizations have already used for Copilot Studio, and they collectively created more than 400,000 custom agents in the last three months alone, up over 2x quarter over quarter. We've also introduced our own first-party agents to facilitate meetings, manage projects, resolve common HR and IT queries, and access SharePoint data. And we also continue to see partners like Adobe, SAP, ServiceNow, and Workday build their third-party agents and integrate with Copilot. What is driving Copilot as the UI for AI as well as our momentum with agents is our rich data cloud, which is the world's largest source of organizational knowledge.
Billions of emails, documents, and chats, hundreds of millions of Teams meetings, and millions of SharePoint sites are added each day. This is the enterprise knowledge cloud. It is growing fast, up over 25% year over year. More broadly, what we are seeing is Copilot plus agents disrupting business applications, and we are leaning into this.
With Dynamics 365, we took share as organizations like Ecolab, Lenovo, RTX, TotalEnergies, and Vizient switched to our AI-powered apps from legacy providers. In healthcare, DAX Copilot surpassed 2 million monthly physician-patient encounters, up 54% quarter over quarter. It is being used by top providers like Mass General Brigham, Michigan Medicine, Vanderbilt University Medical Center to increase productivity of their physicians. When it comes to Windows, we are seeing momentum build as we approach end of support for Windows 10.
Customers are choosing the latest Windows 11 devices for their enhanced security and advanced AI capabilities. 15% premium-priced laptops in the U.S. this holiday were Copilot+ PCs, and we expect the majority of the PCs sold in the next several years to be Copilots+ PCs. We also see more and more developers from Adobe and CapCut to WhatsApp build apps that leverage built-in NPUs.
And they will soon be able to run DeepSeek's R1 distal models locally on Copilot+ PCs as well as the vast ecosystem of GPUs available on Windows. And beyond Copilot+ PCs, the most powerful AI workstation for local development is a Windows PC running WSL2 powered by NVIDIA RTX GPUs. Now, on to security. We continue to make progress with our Secure Future initiative, and we are applying what we have learned, introducing over 80 new product capabilities over the past year.
With Security Copilot organizations across private and public sector like City of Johannesburg, Eastman, Intesa, National Australia Bank, NTT can resolve incidents 30% faster. Data governance is increasingly critical, and customers now use Microsoft purview to audit over 2 billion Copilot interactions for safe and compliant use. Now, on to our consumer businesses, starting with LinkedIn. More professionals than ever are engaging in high-value conversations on LinkedIn with comments up 37% year over year.
Short-form video continues to grow on the platform, with video creation all up growing at twice the rate of other post formats. We're also innovating with agents to help recruiters and small businesses find qualified candidates faster, and our hiring business again took share. In subscriptions, LinkedIn premiums surpassed $2 billion in annual revenue for the first time this quarter. Subscriber growth has increased nearly 50% over the past two years, and nearly 40% of subscribers have used our AI features to improve their profiles.
And LinkedIn Marketing Solution remains the leader in B2B advertising. Now, on to search, advertising, and news. We once again took share across Bing and Edge. Edge surpassed 30% market share in the U.S.
on Windows and has taken share for 15 consecutive quarters. The investments we have made in improving our ad rates are paying off and advertisers increasingly see our network as an essential platform to optimize ROI. And our Copilot consumer app is seeing increased engagement and retention with its improved speed, unique personality, first-of-its-kind features like Copilot Vision. Just today, we made Think Deeper, powered by o1, free for all Copilot users globally.
Now, on to gaming. We are focused on improving the profitability of the business in order to position it for long-term growth driven by higher-margin content and platform services, and we are delivering on this plan. Black Ops 6 was top-selling game on Xbox and PlayStation this quarter and saw more players in its launch quarter than any other paid release in the franchise history. And we saw rave reviews of Indiana Jones and the Great Circle, which has already been played by more than 4 million people.
We also continue to see strong momentum for Xbox Cloud Gaming with a record 140 million hours streamed this quarter. All up, Game Pass set a new quarterly record for revenue and grew its PC subscriber base by over 30% as we focus on driving fully paid subscribers across endpoints. In closing, we continue to innovate across our tech stack to help our customers in this AI era, and I'm energized by the many opportunities ahead. With that, let me turn it over to Amy.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thank you, Satya, and good afternoon, everyone. This quarter, revenue was $69.6 billion, up 12%. Gross margin dollars increased 13% and 12% in constant currency, while operating income increased 17% and 16% in constant currency. Earnings per share was $3.23, an increase of 10%.
We delivered another quarter of double-digit top- and bottom-line growth. Results were driven by strong demand for our cloud and AI offerings, while we also improved our operating leverage with higher-than-expected operating income growth. As you heard from Satya, our AI business annual revenue run rate surpassed $13 billion and was above expectations. Commercial bookings increased 67% and 75% in constant currency and were significantly ahead of expectations driven by Azure commitments from OpenAI.
Execution was strong across our core annuity sales motions with growth in the number of $100 million-plus contracts for both Azure and Microsoft 365. Commercial remaining performance obligation increased to $298 billion, up 34% and 36% in constant currency. Roughly 40% will be recognized in revenue in the next 12 months, up 21% year over year. The remaining portion recognized beyond the next 12 months increased 45%.
And this quarter, our annuity mix was 97%. FX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, more personal computing revenue, total company COGS, and operating expense. FX decreased revenue more than expected in our commercial segments. Microsoft Cloud revenue was $40.9 billion and grew 21%.
Microsoft Cloud gross margin percentage was 70%, in line with expectations, and decreased two points year over year, driven by scaling our AI infrastructure. Company gross margin percentage increased slightly year over year to 69%, primarily driven by sales mix shift to higher-margin businesses as well as improvement in gaming and search, partially offset by the impact of scaling our AI infrastructure. Operating expenses increased 5%, lower than expected, and operating margins increased two points year over year to 45%. The better-than-expected margin expansion was driven by delivering efficiencies across our businesses as we invest to scale AI infrastructure and build AI applications.
At a total company level, head count at the end of December was 2% higher than a year ago and was relatively unchanged from last quarter. Now, to our segment results. Revenue from Productivity and Business Processes was $29.4 billion and grew 14% and 13% in constant currency, even with the unfavorable FX impact noted earlier. Results were ahead of expectations driven by Microsoft 365 Commercial.
Microsoft 365 Commercial Cloud revenue increased 16% and 15% in constant currency, slightly ahead of expectations due to better-than-expected performance in E5 and Microsoft 365 Copilot. With M365 Copilot, we continue to see growth in adoption, expansion, and usage. ARPU growth was again driven by E5 and M365 Copilot. Paid M365 commercial seats grew 7% year over year, with installed base expansion across all customer segments, though primarily in our small and medium business and frontline worker offerings.
M365 commercial products revenue increased 13%, significantly ahead of expectations, driven by higher-than-expected transactional purchasing with the launch of Office 2024 as well as the Windows commercial on-premises components from the better-than-expected performance of M365 suites noted earlier. M365 consumer cloud revenue increased 8%, slightly ahead of expectations. We saw continued momentum in M365 consumer subscriptions, which grew 10% to $86.3 million, with mix shift to M365 basic. LinkedIn revenue increased 9% with continued growth across all lines of business.
In our Talent Solutions business, results were slightly below expectations, driven by continued weakness in the hiring market in key verticals. Dynamics 365 revenue increased 19% and 18% in constant currency, slightly ahead of expectations with growth across all workloads. Segment gross margin dollars increased 13% and 12% in constant currency, and gross margin percentage decreased slightly year over year, driven by scaling our AI infrastructure. Operating expenses increased 6% and operating income increased 16% and 15% in constant currency.
Next, the Intelligent Cloud segment. Revenue was $25.5 billion and grew 19% with more unfavorable FX impact than expected. Excluding the unfavorable FX impact, results in Azure non-AI services, on-prem server, and enterprise and partner services were slightly lower than expected, partially offset by better-than-expected results in Azure AI services. Azure other cloud services revenue grew 31%.
Azure growth included 13 points from AI services, which grew 157% year over year, and was ahead of expectations even as demand continued to be higher than our available capacity. Growth in our non-AI services was slightly lower than expected due to go-to-market execution challenges, particularly with our customers that we primarily reach through our scale motions as we balance driving near-term non-AI consumption with AI growth. In our on-premises server business, revenue decreased 3%, slightly below expectations, driven by slower-than-expected purchasing around Windows Server 2025 launch. Enterprise and Partner Services revenue decreased 1%, below expectations, with lower-than-expected performance across Enterprise Support Services and Industry Solutions.
Segment gross margin dollars increased 12% and 13% in constant currency, and gross margin percentage decreased four points year over year, driven by scaling our AI infrastructure. Operating expenses increased 10% and operating income grew 14%. Now, to More Personal Computing. Revenue was $14.7 billion, relatively unchanged year over year, with better-than-expected results driven primarily by Windows OEM prebuilds, usage from a third-party partnership in search as well as Call of Duty launch performance in gaming.
Windows OEM and devices revenue increased 4% year over year, ahead of expectations, driven by commercial inventory builds in advance of Windows 10 end support as well as uncertainty around tariffs. Search and news advertising revenue ex-TAC increased 21% and 20% in constant currency, ahead of expectations, driven by usage from a third-party partnership. Growth continues to be driven by rate expansion and healthy volume growth in both Edge and Bing. And in gaming, revenue decreased 7% and 8% in constant currency as content and services growth continued to be offset by hardware declines.
Xbox content and services revenue increased 2%, ahead of expectations, driven by stronger-than-expected performance in Blizzard and Activision content, including Call of Duty. Segment gross margin dollars increased 13% and 12% in constant currency. Gross margin percentage increased six points year over year, driven by sales mix shift to higher-margin businesses as well as strong execution on margin improvement in gaming and search. Operating expenses decreased 1%.
Operating income increased 32% and 30% in constant currency, driven by continued prioritization of higher-margin opportunities. Now, back to total company results. Capital expenditures, including finance leases, were $22.6 billion, in line with expectations, and cash paid for PP&E was $15.8 billion. More than half of our cloud and AI-related spend was on long-lived assets that will support monetization over the next 15 years and beyond.
The remaining cloud and AI spend was primarily for servers, both CPUs and GPUs, to serve customers based on demand signals, including our customer-contracted backlog. Cash flow from operations was $22.3 billion, up 18%, driven by strong cloud billings and collections, partially offset by higher supplier, employee, and tax payments. Free cash flow was $6.5 billion, down 29% year over year, reflecting the capital expenditures noted earlier. This quarter, other income and expense was negative $2.3 billion, lower than our October guidance due to the impairment charge from our Cruise investment.
Our effective tax rate came in slightly lower than anticipated at 18%. And finally, we returned $9.7 billion to shareholders through dividends and share repurchases. Now, moving to our Q3 outlook, which unless specifically noted otherwise, is on a U.S. dollar basis.
First, FX. With the strengthening of the U.S. dollar since October, we now expect FX to decrease total revenue growth by two points. Within the segments, we expect FX to decrease revenue growth by two points in Productivity and Business Processes and Intelligent Cloud and roughly one point in More Personal Computing.
When compared to our October guidance assumptions on Q3 FX impact, this is a decrease to total revenue of roughly $1 billion. We expect FX to decrease COGS growth by approximately two points and operating expense growth by approximately one point. Our outlook has many of the trends we saw in Q2 continue through Q3. Demand for our differentiated cloud and AI offerings across the Microsoft Cloud should drive another quarter of strong growth.
In commercial bookings, with a relatively flat expiry base and a strong prior year comparable in terms of large Azure contracts, we expect growth to be roughly flat year over year. We expect consistent execution across our core annuity sales motions and continued long-term commitments to our platform. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 69%, down year over year, driven by the impact of scaling our AI infrastructure.
Next, to segment guidance. In Productivity and Business Processes, we expect revenue to grow between 11% and 12% in constant currency, or USD 29.4 billion to USD 29.7 billion. Microsoft 365 commercial cloud revenue growth should be between 14% and 15% in constant currency, relatively stable compared to our better-than-expected Q2 results. We expect continued ARPU growth through E5 and M365 Copilot, and we again expect some seat growth moderation given the size of the installed base.
For M365 commercial products, we expect revenue to be relatively unchanged year over year. As a reminder, M365 commercial products include Windows commercial on-premises components of M365 suites. So, our quarterly revenue growth can have variability primarily from in-period revenue recognition depending on the mix of contracts. M365 consumer cloud revenue growth should be in the mid- to high single digits, driven by M365 subscriptions.
For LinkedIn, we expect revenue growth in the low to mid-single digits. Although we expect growth across all businesses, the Q2 trends in Talent Solutions should continue in Q3 as a headwind to growth. And in Dynamics 365, we expect revenue growth to be in the mid-teens driven by continued growth across all workloads. For Intelligent Cloud, we expect revenue to grow between 19% and 20% in constant currency, or USD 25.9 billion to USD 26.2 billion.
Revenue will continue to be driven by Azure, which, as a reminder, can have quarterly variability primarily from in-period revenue recognition depending on the mix of contracts. In Azure, we expect Q3 revenue growth to be between 31% and 32% in constant currency driven by strong demand for our portfolio of services. As we shared in October, the contribution from our AI services will grow from increased AI capacity coming online. In non-AI services, healthy growth continues, although we expect ongoing impact through H2 as we work to address the execution challenges noted earlier.
And while we expect to be AI capacity-constrained in Q3, by the end of FY '25, we should be roughly in line with near-term demand given our significant capital investments. In our on-premises server business, we expect revenue to decline in the mid-single digits, driven by a decrease in transactional purchasing. And in Enterprise and Partner Services, we expect revenue growth to be in the low to mid-single digits. In More Personal Computing, we expect revenue to be USD 12.4 billion to USD 12.8 billion with continued prioritization of higher-margin opportunities.
Windows OEM and devices revenue should decline in the low to mid-single digits. We expect revenue from Windows OEM to be relatively flat year over year as our outlook assumes inventory levels will normalize. Actual results may differ based on current tariff uncertainties. Devices revenue will decline.
Search and news advertising ex-TAC revenue growth should be in the mid-teens from continued growth in both volume and revenue per search with share gains across Edge and Bing. Growth is expected to moderate from last quarter, primarily due to additional FX impact and as the third-party partnership usage noted earlier returns to more normal levels. Search ex-TAC growth will be higher than overall search and news advertising revenue growth, which we expect to be in the mid- to high single digits. And in gaming, we expect revenue growth to be in the low single digits.
We expect Xbox content and services revenue growth to be in the low to mid-single digits driven by first-party content as well as Xbox Game Pass. Hardware revenue will decline year over year. Now, back to company guidance. We expect COGS to grow between 19% and 20% in constant currency or to be between USD 21.65 billion to USD 21.85 billion and operating expense to grow between 5% and 6% in constant currency or to be between USD 16.4 billion and USD 16.5 billion.
Other income and expense is expected to be roughly negative $1 billion, primarily driven by investments accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. And lastly, we expect our Q3 effective tax rate to be approximately 18%. Now, some additional thoughts on the rest of the fiscal year and beyond.
First, FX. With the strengthening of the U.S. dollar since October, we now expect FX to decrease Q4 revenue and COGS growth by more than one point and operating expense growth by roughly one point. Next, capital expenditures.
We expect quarterly spend in Q3 and Q4 to remain at similar levels as our Q2 spend. In FY '26, we expect to continue investing against strong demand signals, including customer contracted backlog we need to deliver against across the entirety of our Microsoft Cloud. However, the growth rate will be lower than FY '25 and the mix of spend will begin to shift back to short-lived assets, which are more correlated to revenue growth. As a reminder, our long-lived infrastructure investments are fungible, enabling us to remain agile as we meet customer demand globally across our Microsoft Cloud, including AI workloads.
As always, there can be quarterly spend variability from cloud infrastructure build-outs and the timing of delivery of finance leases. For the full fiscal year, we continue to expect double-digit revenue and operating income growth as we focus on delivering efficiencies across both COGS and operating expense. And given the operating leverage that we've delivered throughout the year, inclusive of efficiency gains as we scale our AI infrastructure and utilize our own AI solutions, we now expect FY '25 operating margins to be up slightly year over year. And finally, our FY '25 full-year effective tax rate should be between 18% and 19%.
In closing, we are committed to delivering real-world AI solutions to help customers grow and improve their results. We are confident in our leadership position as we grow with our customers. Before turning to Q&A, I have one special thank you. Brett Iversen is moving to a new role here as the Head of our Americas sales finance team.
On behalf of the company, thank you for your tremendous impact leading Investor Relations for the past four years and for the partnership with both Satya and me. And I'd like to welcome Jonathan Neilson, the former head of finance for our security products, who is returning to Investor Relations to lead the team. With that, let's go to Q&A, Brett.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Amy. We'll now move over to Q&A. Out of respect for others on the call, we request that participants please only ask one question. Operator, can you please repeat your instructions?
Questions & Answers:
Operator
Thank you. [Operator instructions] And our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.
Keith Weiss
--
Analyst
Excellent. Thank you, guys, for taking the question. And echoing Amy's comments, Brett, congratulations on the new role. It's been a pleasure working with you, and best of luck in that new role.
Looking at the quarter, another really solid quarter when it comes to commercial bookings. But again, we were a little bit disappointed on Azure coming in at the bottom end of the guidance range. Amy, I was hoping you could dig into perhaps what some of those execution issues were, what the resolution to those issues were. And do we still feel comfortable in the acceleration into the back half of the year that you were talking about after the June quarter and after last quarter? Thank you very much.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thanks, Keith. Let me spend a little time on that about what we saw in Q2 and give you some additional background on the near-term execution issues that we're talking about. First, let me be very specific, they are in the non-AI ACR component. Our Azure AI results were better than we thought due to very good work by the operating teams pulling in some delivery dates even by weeks.
When you're capacity-constrained, weeks matter, and it was good execution by the team, and you see that in the revenue results. On the non-AI side, really, the challenges were in what we call the scale motions. So, think about primarily, these are customers we reach through partners and through more indirect methods of selling. And really, the art form there is as these customers, which we reach in this way, are trying to balance how do you do an AI workload with continuing some of the work they've done on migrations and other fundamentals, we then took our sales motions in the summer and really changed to try to balance those two.
As you do that, you learn with your customers and with your partners on sort of getting that balance right between where to put our investments, where to put the marketing dollars, and importantly, where to put people in terms of coverage and being able to help customers make those transitions. And I think we are going to make some adjustments to make sure we are in balance because when you make those changes in the summer, by the time it works its way through the system, you can see the impacts on whether you have that balance right. And so, the teams are working through that. They're already making adjustments.
And I expect while we will see some impact through H2 just because when you work through the scale motion, it can take some time for that to adjust. I feel good that the teams understand and are working through that. So, hopefully, that's just helpful on that. Then we talked a little bit about Q3.
And so, we've talked about 31 to 32 after publishing a 31 this quarter. Our AI results that we had felt good about and talked about our ability to land that revenue is the same. So, again, in Q3, we are working from a pretty constrained capacity place, and that's no different than it was our expectation to be in that position last October when I talked to you all. And when I talk about being capacity-constrained, it takes two things.
You have to have space, which I generally call long-lived assets, right? That's the infrastructure and the land and then you have to have kits. We're continuing, and you've seen that's why our spend has pivoted this way, to be in the long-lived investment. We have been short power and space. And so, as you see those investments land that we've made over the past three years, we get closer to that balance by the end of this year.
And so, the confidence on the AI side continues to be there in terms of being able to sell, utilize, and be, I think, encouraged by the signals. What we're seeing is waiting to see just how the non-AI ACR works through the scale motions in H2. But in general, the only thing that's changed is really that scale motion from my seat, Keith. I hope that's helpful.
Satya?
Satya Nadella
--
Chair and Chief Executive Officer
Yeah. I think, Amy, just one thing I'd add, Keith, to your question is, as Amy said, AI growth rate is actually better than what we expected, and we worked through some of the supply stuff and more importantly, some of the workloads are scaling well. And when you look underneath any of these AI workloads, the other thing that is good is the ratio of even what we would call just regular storage, data services, app services. So, underneath a ChatGPT or a Copilot or even the emerging AI workloads in the enterprise, so that's all good.
The enterprise workloads, whether it's SAP or whether it's VMware migrations, what have you, that's also in good shape. And it's just the scale place where Amy talked about this nuance, right, how do you really tweak the incentives, go-to-market? At a time of platform shifts, you kind of want to make sure you lean into even the new design wins, and you just don't keep doing the stuff that you did in the previous generation. And that's the art form Amy was referencing to, to make sure you get the right balance. But let me put it this way.
You would rather win the new than just protect the past. And that's sort of another thing that we definitely will lean into always.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Keith. Operator, next question, please.
Operator
The next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.
Mark Moerdler
--
Analyst
Thank you very much for taking my question. Can you give more color on what drove the far larger-than-expected Microsoft AI revenue? We talked a bit about the Azure AI component of it. But can you give more color on that? And our estimates are that the Copilot was much bigger than we had expected and growing much faster. Any more details on the breakdown of what that Microsoft AI beat would be great.
Thanks.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thanks, Mark, for the question. Yes, that was, as we talked about, better than expected. A couple of pieces to that, which you correctly identified, number one is the Azure component we just talked about. And the second piece, you're right, Microsoft Copilot was better.
And what was important about that, we saw strength both in seats, both new seats and expansion seats, as Satya talked about. And usage doesn't directly impact revenue, but of course, indirectly does as people get more and more value added. And also, price per seat was actually quite good. We still have a good signal for value.
So, those are the biggest pieces, Mark, of that sort of outperformance in terms of our expectations.
Brett Iversen
--
Vice President, Investor Relations
Thank you, Mark. Operator, next question, please.
Operator
The next question comes from the line of Brent Thill with Jefferies. Please proceed.
Brent Thill
--
Analyst
Thanks. Satya, you mentioned DeepSeek a couple of times in your prepared remarks. I think everyone would love your thoughts on what you're seeing there. And are we seeing AI scale now at a lower cost? Are we reaching a mark where you can see that? Or do we still have some time to go? Thanks for your thoughts on this.
Satya Nadella
--
Chair and Chief Executive Officer
Yeah. Thanks, Brent. So, yeah, in my remarks, I talked about, in some sense, what's happening with AI. It's no different than what was happening with the regular compute cycle.
It's always about bending the curve and then putting more points up the curve. So, there's Moore's Law that's working and hyperdrive. Then on top of that, there is the AI scaling laws, both the pretraining and the inference time compute that compound, and that's all software. You should think of what I said in my remarks, which we have observed for a while, which is 10x on improvements per cycle just because of all the software optimizations on inference.
And so, that's what you see. And add to that, I think DeepSeek has had some real innovations. And that is some of the things that even OpenAI found in '01. And so, we are going to -- obviously, now that all gets commoditized and it's going to get broadly used.
And the big beneficiaries of any software cycle like that is the customers, right? Because at the end of the day, if you think about it, right, what was the big lesson learned from client server to cloud? More people bought servers, except it was called cloud. And so, when token prices fall, inference computing prices fall, that means people can consume more, and there will be more apps written. And it's interesting to see that when I referenced these models that are pretty powerful, it's unimaginable to think that here we are in sort of beginning of '25, where on the PC, you can run a model that required pretty massive cloud infrastructure. So, that type of optimization means AI will be much more ubiquitous.
And so, therefore, for a hyperscaler like us, a PC platform provider like us, this is all good news as far as I'm concerned.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Brent. Operator, next question, please.
Operator
The next question comes from the line of Karl Keirstead with UBS. Please proceed.
Karl Keirstead
--
Analyst
Thank you. Maybe this one is well for Satya, and it's also away from the numbers. But Satya, I wanted to ask you about the Stargate news and the announced changes in the OpenAI relationship last week. It seems that most of your investors have interpreted this as Microsoft, for sure, remaining very committed to OpenAI's success, but electing to take more of a backseat in terms of funding OpenAI's future training capex needs.
I was hoping you might frame your strategic decision here around Stargate, and Amy, whether there's any takeaway for investors from that decision in terms of how you're thinking about capex needs over the next several years? Thank you.
Satya Nadella
--
Chair and Chief Executive Officer
Yeah. Thanks for the question. So, we remain very happy with the partnership with OpenAI. And as you saw, they have committed in a big way to Azure, and even in the bookings, what we recognized is just the first tranche of it.
And so, you'll see given the ROFR we have more benefits of that even into the future. And obviously, their success is our success because even all the other commercial arrangements that we detailed out in the blog that we put out even commensurate with that announcement. But to your overall point, the thing that I would say is we are building a pretty fungible fleet, right? We are making sure that there's the right balance between training and inference. It's geo-distributed.
We are working super hard on all the software optimizations, right? I mean, just not the software optimizations that come because of what DeepSeek has done, but all the work we have done to, for example, reduce the prices of GPT models over the years in partnership with OpenAI. In fact, we did a lot of the work on the inference optimizations on it, and that's been key to driving, right? One of the key things to note in AI is you just don't launch the frontier model -- but if it's too expensive to serve, it's no good, right? It does -- it won't generate any demand. So, you've got to have that optimization so that inferencing costs are coming down and they can be consumed broadly. And so, that's the fleet physics we are managing.
And also, remember, you don't want to buy too much of anything at one time because the Moore's Law every year is going to give you 2x, your optimization is going to give you 10x. You want to continuously upgrade the fleet, modernize the fleet, age the fleet, and at the end of the day, have the right ratio of monetization and demand-driven monetization to what you think of as the training expense. So, I feel very good about the investment we are making, and it's fungible, and it just allows us to scale more long-term business.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
And maybe, Karl, just to reiterate a little of the comments that I made on capex because I think it's helpful to ground a bit more in what Satya is saying, a fungible fleet means. We have, and I think we talked about it, close to $300 billion of RPO. That is committed customer contracts that need to be delivered on. And the faster we can do that and the more efficiently we can do that, the better off we are, not just the OpenAI partnership, which is a piece of that, but with the entire platform that we need to deliver for our customers.
And I think the other thing that's sometimes missing is when we say fungible, we mean not just the primary use, which we've always talked about, which is inference. But there is some training post training, which is a key component. And then they're just running the commercial cloud, which at every layer under every modern AI app that's going to be built will be required. It will be required to be distributed, and it will be required to be global.
And all of those things are really important because it then means you're the most efficient. And so, the investment you see us make in capex, you're right, the front end has been this sort of infrastructure build that lets us really catch up not just on the AI infrastructure we needed, but think about that as the building itself, data centers, but also some of the catch-up we need to do on the commercial cloud side. And then you'll see the pivot to more CPU and GPU. And that pivot will more directly correlate to revenue, and it will be contracted either with the partnership that you asked about with OpenAI or with others.
And so, I do think the way I want everyone to internalize it is that the capex growth is going through that cycle pivot, which is far more correlated to customer contract delivery, no matter who the end customer is.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Karl. Operator, next question, please.
Operator
And our next question comes from the line of Brad Zelnick with Deutsche Bank. Please proceed.
Brad Zelnick
--
Analyst
Thank you very much for taking my question. And I'll echo my congrats and gratitude to Brett as well. Satya, as we think about Microsoft's very rich Copilot portfolio, now having been in market for over a year with the products and precision only getting better and the cost of inference coming down, how do you think about the journey from here and perhaps the ability to package and evolve the go-to-market to address the broadest range of customers and customer requirements out there? Thanks.
Satya Nadella
--
Chair and Chief Executive Officer
Well, thanks, Brad, for the question. In fact, you saw us make two announcements recently. One is on the M365 Copilot side, we now have the Copilot chat. So, this is now going to be broadly deployed across the entire installed base effectively because you can go have this now turned on by IT and everybody can start using web-grounded chat with all the enterprise controls right away, and it has Copilot Studio built in.
And so, that means they can start building agents. So, we think of that plus the full Copilot as a good combination that I think will accelerate, quite frankly, in terms of just seat usage and agent building and what have you. So, that's sort of one. And the other thing is you also see, even on the consumer side, we just, yesterday, launched one -- or the ThinkHarder feature on Copilot now that's powered by o1.
It's available globally, right? So, you can see the benefits of inference optimization and the cost coming down means you can drive more ubiquity of what were features that ones were sort of premium tier, and that's all definitely something that we will do across, right? The same thing is happening in GitHub Copilot, same thing in security Copilot. So, across the length and breadth of our portfolio, you'll see that.
Brad Zelnick
--
Analyst
Thank you.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Brad. Operator, next question, please.
Operator
The next question comes from the line of Brad Reback with Stifel. Please proceed.
Brad Reback
--
Analyst
That's great. Thank you very much. Satya, if you look out several years, any sense of what percent of inference done on Azure will be done on proprietary models versus open models? And with that said, does it matter to Microsoft at the end of the day? Thanks.
Satya Nadella
--
Chair and Chief Executive Officer
Yeah. It's a good question because at some level, what you're seeing is effectively lots of models that get used in any application, right? When you look underneath even a Copilot or a GitHub Copilot or what have you, you already see lots of many different models. You build models, you fine-tune models, you distill models. Some of them are models that you distill into an open-source model.
So, there's going to be a combination. So, we've always maintained that it's always good to have frontier models. You want to always build your application with high ambition using the best. model that is available and then optimize from there on.
So, that's also another side. Like there's a temporality to it, right? What you start with as a given COGS profile doesn't need to be the end because you continuously optimize for latency and COGS and putting in different models. And in fact, all that complexity, by the way, has to be managed by a new app server. So, one of the things that we are investing heavily on is foundry because from an app developer perspective, you kind of want to keep pace with this flurry of models that are coming in, and you want to have an evergreen way for your application to benefit from all that innovation, but not have all the dev cost or the DevOps cost or what people talk about AIOps cost.
So, we are also investing significantly in all the app server for any workload to be able to benefit from all these different models, open source, close source, different weight classes, and at the same time, from an operations perspective, it's faster, easier for you.
Brad Reback
--
Analyst
Great. Thank you.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Brad. Operator, next question, please.
Operator
And the next question comes from the line of Brad Sills with Bank of America. Please proceed.
Brad Sills
--
Analyst
Wonderful. Thank you so much. Great to hear about the strength you're seeing in Copilot. Would love to get some color as to where you're seeing that strength.
Is it departmental deals, customers moving from proof of concept to departmental deals, maybe multiple departmental deals in the enterprise? And you mentioned some uptick in usage trends. Would love to get some color on just the common use cases that you're seeing that give you that confidence that that will ramp into monetization later. Thank you.
Satya Nadella
--
Chair and Chief Executive Officer
Yeah. I mean, I think the initial sort of set of seats were for places where there's more belief in immediate productivity, a sales team, in finance, or in supply chain where there is a lot of, like, for example, SharePoint grounded data that you want to be able to use in conjunction with web data and have it produce results that are beneficial. But then what's happening very much like what we have seen in these previous generation productivity things is that people collaborate across functions, across roles, right? For example, even in my own daily habit, I go to chat. I use work tab and get results, and then I immediately share using pages with colleagues.
I sort of call it think with AI and work with people. And that pattern then requires you to make it more of a standard issue across the enterprise. And so, that's what we're seeing. It starts maybe at a departmental level.
Quickly, the collaboration network effects will effectively demand that you spread it across. You can do it by cohort and what have you. And so, what we've made it easier even is to start with Copilot Chat plus this. And so, that gives the enterprise customers even more flexibility to have something that's more ubiquitous.
Brad Sills
--
Analyst
Wonderful. Thank you so much.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Brad. Operator, we have time for one last question.
Operator
And the last question will come from the line of Brent Bracelin with Piper Sandler. Please proceed.
Brent Bracelin
--
Analyst
Thank you for taking the question here. Good afternoon. I wanted to go back to commercial bookings. Commercial RPO, I think, increased $39 billion sequentially.
That's the most we've ever seen on a sequential basis, commercial bookings growth, 75% constant currency. That's 2x higher than we've seen in the last decade. I appreciate there's some volatility with this metric, but it does feel like this quarter, there was a bit of a sea change relative to momentum on backlog and bookings. Can you just talk about maybe the breadth of where that strength came from? Was it broad-based? Was there a couple of large deals? Any color there would be helpful.
Thanks.
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Thanks, Brent. It's a great question. We talked a little bit about one of the main drivers, which was one of the Azure commitments that OpenAI has made. And I do want to say, while that is obviously a big component, you'll continue to see OpenAI make commitments.
So, I don't -- I want to separate the concept that it's one-time versus an ongoing relationship that will grow as they grow, which it absolutely will. And to your question on what else is participating in that number. First, we did have very good core motions. Our core motions are things like, to your point, renewals of our existing contracts, add-ons to those contracts, upsells, like, for example, Copilot or GitHub Copilot or other processes.
And I think that's important. We also had a good E5 quarter, which when we talk a lot about M365 Copilot, I sometimes forget to also talk about Suite momentum, and we saw that as well this quarter, which we felt very good about. And then the final component is large Azure commitments. And those really did look as we expected, which is good.
To your point, and that you're seeing a really broad-based growth. Those Azure commitments take two forms. One, it's existing customers who've worked through their commitments and are making larger commitments, which is a good commitment signed for the platform. And then you have new customers making commitments, and we also saw that this quarter.
And so, to your point, sometimes I think a big number that looks like this can make you think it's just one thing. I think you're right. Some of it was one thing, but a lot of it was good execution consistently across the workloads.
Brent Bracelin
--
Analyst
Thank you.
Brett Iversen
--
Vice President, Investor Relations
Thanks, Brent. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with all of you soon.
Operator
[Operator signoff]
Duration: 0 minutes
Call participants:
Brett Iversen
--
Vice President, Investor Relations
Satya Nadella
--
Chair and Chief Executive Officer
Amy E. Hood
--
Executive Vice President, Chief Financial Officer
Keith Weiss
--
Analyst
Amy Hood
--
Executive Vice President, Chief Financial Officer
Mark Moerdler
--
Analyst
Brent Thill
--
Analyst
Karl Keirstead
--
Analyst
Brad Zelnick
--
Analyst
Brad Reback
--
Analyst
Brad Sills
--
Analyst
Brent Bracelin
--
Analyst
More MSFT analysis
All earnings call transcripts"
Microsoft Corporation (MSFT),Q4,2025,Microsoft (MSFT) Q4 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/08/05/microsoft-msft-q4-2025-earnings-call-transcript/,"Date
Wednesday, July 30, 2025, at 9:30 p.m. ET
Call participants
Chairman and Chief Executive Officer — Satya Nadella
Chief Financial Officer — Amy Hood
Chief Accounting Officer — Alex Jolla
Corporate Secretary and Deputy General Counsel — Keith Dolliver
General Manager, Investor Relations — Jonathan Neilson
Need a quote from a Motley Fool analyst? Email pr@fool.com
Takeaways
Total revenue
-- $76.4 billion in revenue for fiscal Q4 2025, up 18% in constant currency, exceeding internal expectations.
Operating income
-- Operating income was over $128 billion for fiscal 2025, up 17% year over year, with a company-wide operating margin of 45% for fiscal Q4 2025. Operating margin increased two points year over year, reaching 45%.
Earnings per share
-- $3.65 for fiscal Q4 2025. Earnings per share increased 22% in constant currency.
Microsoft Cloud revenue
-- $46.7 billion in Microsoft Cloud revenue for fiscal Q4 2025, up 25% in constant currency and ahead of guidance.
Azure revenue
-- Azure surpassed $75 billion in annual revenue for fiscal 2025, up 34% year over year, with Azure and other cloud services revenue up 39% in fiscal Q4 2025.
Commercial bookings
-- Commercial bookings surpassed $100 billion for the first time in fiscal 2025, increasing 30% in constant currency. Contracted remaining performance obligation was $368 billion as of fiscal Q4 2025, up 35% in constant currency.
Productivity and Business Processes revenue
-- $33.1 billion in revenue from Productivity and Business Processes for fiscal Q4 2025, up 14% in constant currency, led by Microsoft 365, Dynamics 365, and LinkedIn contributions.
Microsoft 365 commercial cloud revenue
-- Increased 16% in constant currency for fiscal Q4 2025, with seat growth of 6% year over year and installed base expansion across customer segments.
Dynamics 365 revenue
-- Increased 21% in constant currency for fiscal Q4 2025, delivering growth across all workloads.
LinkedIn revenue
-- Rose 8% in constant currency for fiscal Q4 2025, with growth across all businesses in fiscal 2025, but noting hiring market weakness in Talent Solutions.
More Personal Computing revenue
-- $13.5 billion for fiscal Q4 2025, up 9%, driven by Windows OEM and Xbox content and services.
Gaming revenue
-- Gaming revenue increased 10%, with Xbox content and services revenue up 12% in constant currency for fiscal Q4 2025. Game Pass annual revenue was nearly $5 billion for fiscal 2025.
Gross margin (company)
-- 69%, down one point year over year in fiscal Q4 2025, reflecting a sales mix shift to Azure and lower cloud gross margin from AI infrastructure investment.
Gross margin (Microsoft Cloud)
-- 68%, down two points year over year in fiscal Q4 2025, offset partially by efficiency gains in Azure and Microsoft 365.
Paid Microsoft 365 consumer subscribers
-- Paid Microsoft 365 consumer subscribers grew 8% for fiscal 2025.
Operating expenses
-- Operating expenses increased 5% in constant currency.
Headcount
-- Remained relatively unchanged year over year as of fiscal Q4 2025.
Capital expenditures
-- Capital expenditures were $24.2 billion for fiscal 2025, including $5 billion of finance leases in fiscal Q4 2025. Over half was allocated to long-lived assets supporting future monetization, as stated by management on the fiscal Q4 2025 earnings call.
Free cash flow
-- Free cash flow was $25.6 billion for fiscal 2025, supported by strong cloud billing and collections in fiscal Q4 2025.
AI product adoption
-- Microsoft 365 Copilot achieved the largest quarter of seat adds since launch in fiscal Q4 2025. GitHub Copilot Enterprise customers grew 75% quarter over quarter.
Data center capacity
-- Over two gigawatts of new capacity stood up in the past twelve months, with total exceeding 400 data centers across 70 regions as of fiscal Q4 2025.
Azure AI Foundry adoption
-- Over 14,000 customers are using the Foundry agent service as of fiscal Q4 2025. 80% of the Fortune 500 already use Foundry.
Outlook for fiscal 2026
-- Expectation for double-digit revenue and operating income growth for fiscal 2026, operating margins to remain relatively unchanged, and an effective tax rate of 19%-20% for fiscal 2026.
Q1 guidance
-- Anticipate over $30 billion in capital expenditures for fiscal Q1 2026 and Microsoft Cloud gross margin percentage of approximately 67%, driven by continued AI infrastructure scaling.
Summary
Microsoft
(
MSFT
+1.53%
)
reported broad segment outperformance, highlighted by a 23% increase in Microsoft Cloud annual revenue for fiscal 2025 and sustained expansion in Azure, Copilot adoption, and data center capacity. Management stated, ""We saw accelerating growth from migrations again this quarter,"" referencing high-profile migration wins such as Nestle during the quarter and indicating migration activity as a key Azure tailwind. Fiscal year-end commercial bookings exceeded $100 billion for the first time in fiscal 2025, supported by a 35% rise in total remaining performance obligations in fiscal Q4 2025 and increasing contract value, while capital investments scaled to address ongoing capacity constraints despite significant capacity coming online. Guidance for fiscal 2026 projects double-digit revenue and operating income growth, moderated capital expenditure growth compared to fiscal 2025, but management cautions Microsoft Cloud gross margin percentage will decline as AI infrastructure scaling persists, with guidance indicating this trend for fiscal Q1 2026.
Hood projected, ""expect our fiscal 2026 effective tax rate to be between 19%-20%,"" guiding toward a higher effective tax rate versus fiscal 2025.
Management expects fiscal Q1 2026 capital expenditures to exceed $30 billion. Commercial remaining performance obligation increased to $368 billion as of fiscal Q4 2025.
Nadella underscored, ""Every Azure region is now AI-first,"" emphasizing the company's full-stack AI infrastructure as a continued point of competitive differentiation and strategic investment.
Customers created three million agents using SharePoint and Copilot Studio during fiscal 2025, illustrating rapid diffusion of agent-based productivity applications.
Industry glossary
Commercial bookings
: The total value of all contracts signed during the quarter, including renewals and new business, that have a cash or billings impact in future periods.
Commercial remaining performance obligation (CRPO)
: The aggregate contracted revenue that is yet to be recognized over the remaining contract term.
ARPU
: Average revenue per user, a metric measuring the average revenue generated per user or seat.
Ex-TAC
: Revenue measured excluding traffic acquisition costs that are paid to partners such as search or ad providers.
Copilot
: Microsoft's generative AI-powered productivity application suite offered across 365, GitHub, and other surface areas.
Agent
: An autonomous or semi-autonomous AI application configured to complete complex tasks across Microsoft's software and cloud ecosystem.
Fabric
: Microsoft’s integrated data and analytics platform supporting AI-driven workloads across cloud and hybrid environments.
Full Conference Call Transcript
Jonathan Neilson:
On the call with me are Satya Nadella, Chairman and Chief Executive Officer; Amy Hood, Chief Financial Officer; Alex Jolla, Chief Accounting Officer; and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Corporation Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides a reconciliation of differences between GAAP and non-GAAP financial measures. More detailed outlook slides will be available on the Microsoft Corporation Investor Relations website. We provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items.
The non-GAAP financial measures provided should not be considered as a substitute for, or superior to, the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid in further understanding the company's fourth quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted. We will also provide growth rates in constant currency, when available, as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations.
Where growth rates are the same in constant currency, we will refer to the growth rate only. We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Corporation Investor Relations website. During this call, we will be making forward-looking statements, predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties.
Actual results could materially differ because of factors discussed in today's earnings press release, and the comments made during this conference call and in the Risk Factors section of our Form 10-Ks, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement. And with that, I'll turn the call over to Satya.
Satya Nadella:
Thank you, Jonathan. It was a very strong close to what was a record fiscal year for us. All up, Microsoft Cloud surpassed $168 billion in annual revenue, up 23%. The rate of innovation and the speed of diffusion is unlike anything we have seen. To that end, we are building the most comprehensive suite of AI products and tech stack at massive scale. And to provide more context, I want to walk up the stack starting with Azure. Azure surpassed $75 billion in annual revenue, up 34% driven by growth across all workloads. We continue to lead the AI infrastructure wave and took share every quarter this year.
We opened new data centers across six continents and now have over 400 data centers across 70 regions, more than any other cloud provider. There is a lot of talk in the industry about building the first gigawatt and multi-gigawatt data centers. We stood up more than two gigawatts of new capacity over the past twelve months alone, and we continue to scale our own data center capacity faster than any other competitor. Every Azure region is now AI-first. All of our regions can now support liquid cooling, increasing the fungibility and the flexibility of our fleet.
And we are driving and riding a set of compounding S-curves across silicon systems and models to continuously improve efficiency and performance for our customers. Take, for example, the GBD 4.0 family of models, which have the highest volume of inference tokens. Through software optimization alone, we are delivering 90% more tokens for the same GPU compared to a year ago. Beyond the AI fleet, we continue to build our commercial cloud to address customers' unique data residency and sovereignty requirements. This quarter, we introduced the Microsoft Sovereign Cloud, the industry's most comprehensive solution spanning both public and private cloud deployments. All of this innovation is driving our strong results. We saw accelerating growth from migrations again this quarter.
Nestle, for example, migrated more than 200 SAP instances, 10,000 plus servers, and 1.2 petabytes of data to Azure with near-zero business disruption. That makes it one of the largest and most successful migrations in business history. The next big accelerator in the cloud will be quantum, and I'm excited about progress. In fact, earlier this month, we announced the world's first operational deployment of a level two quantum computer in partnership with Atom Computing. This is how we will continue to think and make investments with decade-long arcs while making progress every quarter. The next layer is data, which is foundational to every AI application.
Microsoft Fabric is becoming the complete data and analytics platform for the AI era, spanning everything from SQL to NoSQL to analytics workloads. It continues to gain momentum with revenue up 55% year over year, and over 25,000 customers. It's the fastest-growing database product in our history. FabricOne expands all databases and clouds, including semantic models from Power BI, and, therefore, it is the best source of knowledge and grounding for AI applications and context engineering. Azure Databricks and Snowflake on Azure both accelerated as well. Cosmos DB and Azure PostgreSQL are both powering mission-critical workloads at scale. OpenAI, for example, uses Cosmos DB in the hot path of every chat GPT, storing chat history, user profiles, and conversational state.
And Azure PostgreSQL stores metadata critical to the operation of chat GPT as well as OpenAI's developer APIs. This year, we launched Azure AI Foundry to help customers design, customize, and manage AI applications and agents at scale. Foundry features best-in-class tooling, management, observability, and built-in controls for trustworthy AI. Customers increasingly want to use multiple AI models to meet their specific performance, cost, and use case requirements. And with Foundry, they can provision inferencing throughput once and apply it across more models than any other hyperscaler, including models from OpenAI, DeepSea, Meta, x AI's Grok, and very soon, Black Forest Labs and Mistral AI.
We sim-shipped 15 models from OpenAI alone on Foundry this year, providing same-day access to state-of-the-art models deeply integrated with our infrastructure and tools. And we are seeing accelerated adoption of our new Foundry agent service, which is now being used by 14,000 customers to build agents that automate complex tasks. For example, Nasdaq is using Foundry to build agents that help customers prepare for board meetings, cutting prep time by up to 25%. All up, 80% of Fortune 500 already use Foundry, and when we look narrowly at just the number of tokens served by Foundry API, we processed over 500 trillion this year, up over seven times.
This is a good indicator of true platform diffusion beyond a few head apps and services. Talking about the app layer, these applications are becoming embedded in our daily work and life. Our family of Copilot apps has surpassed 100 million monthly active users across commercial and consumer. And when you take a broader look at the engagement of AI features across our products, we have over 800 million monthly active users. Microsoft 365 Copilot is becoming the new way to organize, work, and workflow and work artifacts. We rolled out our biggest update to Microsoft 365 Copilot to date this quarter, bringing together chat, search, create notebooks, as well as agents into one intuitive scaffolding.
With this innovation and continued product improvements, we are seeing real momentum. Customers continue to adopt Copilot at a faster rate than any other new Microsoft 365 suite with strong usage intensity as shown by our week-over-week retention. And we saw the largest quarter of seat ads since launch with a record number of customers returning to buy more seats. Barclays, for example, will roll out Microsoft 365 Copilot to 100,000 employees globally following a successful initial deployment to 15,000. UBS is expanding its deployment to all of its employees after initially rolling it out to 55,000 of them. And Adobe, KPMG, Pfizer, Wells Fargo, all purchased over 25,000 seats this quarter.
Tens of thousands of organizations have already used our researcher and analyst deep reasoning agents in the first weeks of availability, and we have introduced group-level agents in teams like facilitator and interpreter, which generate real-time translation and notes in meetings. Hundreds of partners like Adobe, SAP, ServiceNow, and Workday have built their own third-party agents that integrate with Copilot and Teams. We are also seeing more customers use Copilot Studio to Microsoft 365 Copilot and build their own agents. This year, customers created 3 million agents using SharePoint and Copilot Studio. And with Copilot tuning, they can easily create agents fine-tuned on their company's data workflow and style that reflect their unique tone, language, and expertise.
We're also seeing great traction among specific roles and functions starting with developers. GitHub Copilot continues to have great momentum in IDE with agent mode and new form factors like coding agent, which is capable of asynchronously executing developer tasks. We have 20 million GitHub Copilot users. GitHub Copilot Enterprise customers increased 75% quarter over quarter. As companies tailor Copilot to their own code bases. And 90% of the Fortune 100 now use GitHub Copilot. More broadly, GitHub usage and repos are seeing explosive growth because of AI. AI projects on GitHub more than doubled over the last year.
The surge in wide coding projects and AI coding agents, whether it is ClaudeCode, Codex, Cursor, or GitHub Copilot, are generating more pull requests and more repos on GitHub. And our code review agent is being used heavily across the platform performing millions of code reviews each month. In health care, we had a breakout year for Dragon Copilot. Customers used our ambient AI solutions to document over 13 million physician-patient encounters this quarter, up nearly seven times year over year. For example, at Mercy Health System, more than a thousand physicians are already using Copilot to reduce administrative burden so that they can focus on providing better care.
They have saved more than 100,000 hours to date and plan to expand to all 5,000 providers. As one physician put it, the best thing to happen to my practice in ten years. And in security, we were the first in the industry to introduce agents to help defenders autonomously handle high-volume security and IT tasks. More broadly, AI is driving a fundamental change in the biz app market as customers shift from legacy systems to agentic business applications. Dynamics 365 took share this year. And we are winning customers in every industry, like Verizon with sales, Domino's Pizza Group with ERP, 1-800-Flowers with contact center. When it comes to consumer apps, we are innovating across all surfaces.
In fact, on Monday, we introduced Copilot mode in Edge. It's especially exciting to see the innovation coming back to browsers. Copilot mode brings together Copilot composer, chat, discover, search, and actions to build the next generation of browser for the AI age. Copilot consumer app also continues to see strong growth in engagement and successful sessions. And we are bringing Copilot to every Windows 11 PC. With Copilot Vision, you can share your screen with Copilot and get real-time insights and assistance on anything. And we are well-positioned as we approach Windows 10 end of support in October, thanks to Windows 11 and Copilot plus PCs, which offer customers compelling security as well as AI value.
Talking about security, it underlies our cloud and AI infrastructure as well as our Copilot and agents. We have launched over 100 new capabilities over the past year. Just last week, we added a modern data lake to our SIM, Microsoft Sentinel, bringing together customer data across our first-party tools, as well as third-party ecosystem over 350 connectors. We're also extending the system's customers already use for governance, identity, security, and management to protect every AI agent. Entra now extends identity permissions policies and controls to agents, Defender secures nearly 2 million general AI apps. Purview is used by three-quarters of the Microsoft 365 Copilot customers to protect their data.
And all up, we now have nearly 1.5 million security customers and continue to take share across all major categories we serve. Before I wrap, I want to talk about two consumer businesses of ours with massive end-user reach, LinkedIn and Xbox. LinkedIn is home to 1.2 billion members with four consecutive years of double-digit member growth. All up, comments on LinkedIn rose over 30%, and video uploads increased over 20% this year. We continue to bring AI to every part of LinkedIn experience, introducing agents across hiring as well as 500 million monthly active users across platforms and devices.
We are now the top publisher on both Xbox and PlayStation this quarter with successful launches of Forza Horizon 5 and Oblivion Remastered. The Call of Duty franchise has never been stronger. 50 million people have played Black Ops 6. Total hours surpassed 2 billion. Minecraft saw record monthly active usage and revenue this quarter thanks in large part to the success of the Minecraft movie. And we have nearly 40 games in development. So much, much more to come. We surpassed over 500 million hours of gameplay streamed via the cloud this year and Game Pass annual revenue was nearly $5 billion for the first time.
In closing, we are going through a generational tech shift with AI, and I have never been more confident in my opportunity to drive long-term growth and define what the future looks like. With that, let me turn it over to Amy to walk through our financial results as well as the outlook.
Amy Hood:
Thank you, Satya, and good afternoon, everyone. This year, we delivered over $281 billion in revenue, up 15% year over year, which reflects the broad strength of our products and services. Operating income was over $128 billion, up 17% year over year as we invested against the expansive opportunity ahead. And in our largest quarter of the year, we significantly exceeded expectations with strong execution by our sales and partner teams. As Satya shared, innovating faster than ever to deliver new value to our customers. This quarter, revenue was $76.4 billion, up 18% in constant currency.
Gross margin dollars increased 15% in constant currency, while operating income increased 22% in constant currency, and earnings per share was $3.65, an increase of 22% in constant currency. For the first time, commercial bookings were over $100 billion, increasing 30% in constant currency, on a strong prior year comparable. Strong execution across our core annuity sales motions including healthy renewals, as well as an increase in the number of $10 million and $100 million plus contracts for both Azure and Microsoft 365 helped drive these results. Commercial remaining performance obligation increased to $368 billion, up 35% in constant currency. Roughly 35% will be recognized in revenue in the next twelve months, up 21% year over year.
The remaining portion, recognized beyond the next twelve months, increased 49%. And this quarter, our annuity mix was again 98%. FX was roughly in line with expectations on total company revenue. Segment level revenue, COGS, and operating expense growth. Microsoft Cloud revenue was $46.7 billion, ahead of expectations and grew 25% in constant currency. Microsoft Cloud gross margin percentage was slightly better than expected at 68%, down two points year over year from the impact of scaling our AI infrastructure, partially offset by continued efficiency gains in Azure and Microsoft 365 commercial cloud.
Company gross margin percentage was 69%, down one point year over year, driven by sales mix shift to Azure, and the lower Microsoft Cloud gross margin noted earlier. Operating expenses increased 5% in constant currency, and operating margins increased two points year over year, to 45%. Better than expected revenue growth, coupled with a focus on operating efficiently, drove the margin expansion. At a total company level, headcount at the June was relatively unchanged, year over year. Now to our segment results. Revenue from Productivity and Business Processes was $33.1 billion and grew 14% in constant currency, better than expected, driven by Microsoft 365 products and cloud services and Microsoft 365 consumer products and cloud services.
Microsoft 365 commercial cloud revenue was ahead of expectations, and increased 16% in constant currency with two points of benefit from in-period revenue recognition. Business trends remained relatively stable to the prior quarter when excluding the in-period revenue recognition. With ARPU growth again driven by E5 and Microsoft 365 Copilot. Paid Microsoft 365 commercial seats grew 6% year over year, with installed base expansion across all customer segments. Though primarily in our small and medium business, and frontline worker offerings. Microsoft 365 commercial products revenue increased 7% in constant currency, ahead of expectations to higher than expected Office 2024 transactional purchasing.
Microsoft 365 consumer cloud revenue was better than expected, increasing 20% driven by ARPU growth following the January price increase and subscriber growth of 8%. LinkedIn revenue increased 8% in constant currency, with growth across all businesses. Though Talent Solutions continues to be impacted, by weakness in the hiring market. Dynamics 365 revenue increased 21% in constant currency with strong execution in our core annuity sales motions, leading to growth across all workloads. Segment gross margin dollars increased 15% in constant currency, and gross margin percentage increased slightly. Driven by the efficiency gains noted earlier, even as we deliver more AI features across our products and scale our AI infrastructure.
Operating expenses increased 6% in constant currency, and operating income increased 19% in constant currency. Next, the intelligent cloud segment. Revenue was $29.9 billion and grew 25% in constant currency, ahead of expectations driven by Azure, and our on-premises server business. In Azure and other cloud services, revenue grew 39%. Significantly ahead of expectations driven by accelerated growth in our core infrastructure business, primarily from our largest customers. As a reminder, new cloud and AI workloads are built and scaled. Using the breadth of our services. Revenue from Azure AI services was generally in line with expectations. And while we brought additional data center capacity online this quarter, demand remains higher than supply.
In our on-premises server business, revenue decreased 3% in constant currency, ahead of expectations, primarily driven by transactional purchasing which also has higher in-period revenue recognition. Enterprise and partner services revenue increased 6% in constant currency, with growth in enterprise support services, partially offset a decline in industry solutions. Segment gross margin dollars increased 16% in constant currency, and gross margin percentage decreased four points year over year, driven by scaling our AI infrastructure, partially offset by Azure efficiency gains noted earlier. Operating expenses increased 4% in constant currency, and operating income grew 23%. Now to more personal computing. Revenue was $13.5 billion and grew 9%. Exceeding expectations primarily due to Windows OEM as well as Xbox content and services.
Windows OEM and devices revenue increased 3% year over year, ahead of expectations as inventory levels remained elevated. Search and news advertising revenue ex-TAC increased 20% in constant currency, driven by continued growth both volume and revenue per search. As well as roughly eight points of favorable impact from third-party partnerships including the benefit of a low prior year comparable. And in gaming, revenue increased 10%. Xbox content and services revenue increased 12% in constant currency, driven by better than expected performance from first-party content and Xbox Game Pass. Segment gross margin dollars increased 15%. Gross margin percentage increased three points year over year with improvement across all businesses. Operating expenses increased 3% in constant currency.
Operating income increased 33% in constant currency, driven by continued prioritization, of higher margin opportunities. Now back to total company results. Capital expenditures were $24.2 billion including $5 billion of finance leases, where we recognize the full value at the time of lease commencement. Cash paid for PP&E was $17.1 billion. The difference is primarily due to finance leases. More than half our spend was on long-lived assets, will support monetization over the next fifteen years and beyond. The remaining spend was primarily for servers, both CPUs and GPUs, and driven by strong demand signals. Cash flow from operations was $42.6 billion up 15%, driven by strong cloud billings and collections, partially offset by higher supplier payments.
And this quarter, free cash flow was $25.6 billion. Other income and expense was negative $1.7 billion primarily due to losses on investments accounted for under the equity method. Our effective tax rate, approximately 17%. And finally, we returned $9.4 billion to shareholders through dividends and share repurchases, bringing our total cash return to shareholders to over $37 billion for the full fiscal year. Now moving to our outlook. My commentary for both the full year and next quarter is on a US dollar basis unless specifically noted otherwise. Let me start with some full year commentary for FY '26. First, FX.
Assuming current rates remain stable, we expect FX to increase full year revenue growth and COGS growth by approximately two points and to increase operating expense growth by one point. Next, building on the strong momentum we saw this past year, we expect to deliver another year of double-digit revenue and operating income growth in FY '26. We will continue to invest against the expansive opportunity ahead across both capital expenditures and operating expenses, given our leadership position in commercial cloud, strong demand signals for our cloud and AI offerings, and significant contracted backlog. Capital expenditure growth, as we shared last quarter, will moderate compared to FY '25 with a greater mix of short-lived assets.
Due to the timing of delivery of additional capacity in H1, including large finance lease sites, we expect growth rates in H1 will be higher than in H2. We remain focused on delivering revenue growth increasing our operational agility. And as a result, we expect operating margins to be relatively unchanged year over year. And finally, expect our FY '26 effective tax rate to be between 19-20%. Now to our outlook for the first quarter. Based on current rates, we expect FX to increase total revenue growth by two points. Within the segments, we expect FX to increase revenue growth by roughly three points in productivity and business processes and roughly one point in intelligence cloud and more personal computing.
We expect FX to increase COGS and operating expense growth, by roughly one point. In commercial bookings, we expect healthy growth on a growing X3 base. Bookings growth will again be driven by strong execution across our core annuity sales motions and long-term commitments to our platform. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 67%, down year over year driven by the impact of continuing to scale our AI infrastructure. We expect Q1 capital expenditures to be over $30 billion driven by the continued strong demand signals we see.
As a reminder, there can be quarterly spend variability from cloud infrastructure build-outs, and the timing of delivery of finance leases. Next, to segment guidance. In productivity and business processes, we expect revenue of $32.2 to $32.5 billion or growth of 14% to 15% with roughly three points of benefit from FX as noted earlier. In Microsoft 365 Commercial Cloud, we expect revenue growth to be between 13% and 14% in constant currency, with business trends that remain relatively stable compared to the prior quarter. ARPU growth will again be driven by E5 and Microsoft 365 Copilot. Microsoft 365 commercial products revenue growth should be in the mid to high single digits.
As a reminder, Microsoft 365 commercial products includes both the Windows commercial on-premises components of Microsoft 365 suites, and office transactional purchasing, both of which can be variable due to in-period revenue recognition dynamics. Microsoft 365 consumer cloud revenue growth should be in the low twenties driven by the January price increase. For LinkedIn, we expect revenue growth in the high single digits. And in Dynamics 365, we expect revenue growth to be in the high teens with continued growth across all workloads. For intelligent cloud, we expect revenue of $30.1 to $30.4 billion or growth of 25% to 26%, with roughly one point of benefit from FX as noted earlier.
Revenue will continue to be driven by Azure, which can have quarterly variability in year-on-year growth rates depending on the timing of capacity delivery, and when it comes online, as well as from in-period revenue recognition, depending on the mix of contracts. In Azure, we expect Q1 revenue growth of approximately 37% in constant currency, driven by strong demand for our portfolio of services on a significant base. Even as we continue bringing more data center capacity online, we currently expect to remain capacity constrained, through the first half of our fiscal year. In our on-premises server business, we expect revenue to decline in the low to mid single digits, with the ongoing customer shift to cloud offerings.
In more personal computing, we expect revenue to be $12.4 to $12.9 billion. Windows OEM and devices revenue should decline in the mid- to high single digits. We expect the elevated inventory levels at the end of Q4 to come down through the quarter in Windows OEM, although the range of potential outcomes remains wider than normal. Devices revenue should decline. Search and news advertising ex-TAC revenue growth should be in the low to mid teens, down sequentially as growth rates normalize, following the benefit from third-party partnerships noted earlier. Growth will continue to be driven by volume, and revenue per search across Edge and Bing. Overall search and news advertising revenue growth should be in the low double digits.
And in gaming, we expect revenue to decline in the mid to high single digits against a strong prior year comparable. We expect Xbox content and services revenue to decline in the mid single digits. Now back to company guidance. We expect COGS of $24.3 to $24.5 billion or growth of 21% to 22%. And operating expense of $15.7 to $15.8 billion or growth of 5% to 6%. Other income and expense is estimated to be negative $1.3 billion primarily due to investments accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. And lastly, we expect our Q1 effective tax rate to be between 19-20%.
In closing, we finished the year with double-digit revenue and operating income growth. And exceeded the FY '25 operating margin commitment we shared a year ago. Our focus remains on investing in security, quality, an AI platform and product innovation that delivers value and opportunity to our customers. We are excited for FY '26. With that, let's go to Q and A, Jonathan.
Jonathan Neilson:
Thanks, Amy. We'll now move over to Q and A. Out of respect for those on the call, we request that participants please only ask one question. Operator, can you please repeat your instructions?
Operator:
Thank you. Ladies and gentlemen, if you would like to ask a question, please press 1 on your telephone keypad. And the confirmation tone will indicate your line is in the question queue. You may press 2 if you would like to remove your question from the queue. For participants using speaker equipment, it may be necessary to pick up your handset before pressing the star keys. And our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.
Keith Weiss:
Thank you guys for taking the question and congratulations on a fantastic end to FY 2025. I've been covering Microsoft Corporation for a while. I don't think I've ever seen a quarter where, like, everything came together this well. So congratulations on that.
Satya Nadella:
Thank you for calling Income Conferencing. The next available operator will be with you momentarily. On. So these are workload results that are invaluable for us to learn to build both the products as well as the platform. And then broadly they or rather over time, they will be brought to few. In fact, one of the things that Amy and I track is not just the head app usage, but also what's the sort of all the tier two applications that are being built. That's sort of that's speaks a little bit, Keith, to, I think, your question.
Is as long as we have head apps shaping the platform, and then after that, we have the broad diffusion happen, which in some sense with both of those is what we're seeing. So I feel very good about being in decent standing going forward.
Jonathan Neilson:
Thanks, Keith. Operator, next question, please.
Operator:
The next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.
Mark Moerdler:
Thank you. I also give you my congratulations. Amazing I didn't know how you were gonna beat last quarter. And you did it. So congratulations. And thank you for taking my question. Satya and Amy, we're now two plus years since the Jaina revolution. Adoption is still early and ramping. What do you think is the best way that software companies are gonna be able to monetize AI for SaaS? Do you believe there are differences in monetization for horizontal, more general apps like Microsoft 365 Copilot or dynamic CRM Copilot versus very targeted capacities on the AgenTex side? And, also, how should you think about the trajectory of SaaS AI margins over the long term? Thank you.
Satya Nadella:
Yeah. Start, and Amy, you should feel free to add. I mean, if I just broaden out beyond just SaaS as a category, I think just like, you know, the server to cloud transition, was an expansion of essentially usage of servers. That is essentially what happened with the cloud, right, which is we did a bunch of servers except that the expertise required, the capital required, the time required to bring up servers, build it out, scale it, was just all hard. And so therefore, the market was a certain size, whereas with the cloud, you could sort of buy it with flexibility, you could burst, and you could spin up and spin down. The expertise required came down.
So it was just orders of magnitude. That's what happening. So if you sort of even subscribe to this point of view that intelligence is basically log of compute, that means compute's going to grow and you've got to use it as efficiently as possible to just keep creating, intelligence. Now how does it manifest beyond just the infrastructure? I kind of to Keith's earlier question, talked a little bit about how infrastructure is getting shaped, data layer is getting shaped, the app server is getting built. These are all classic categories of infrastructure. That'll continue, but they will be an order or two of magnitude more.
So literally, like, there in fact, one of the other things we track is every GPU requires storage and compute, that ratio. Is another thing that is really exponential for AI infrastructure. Growth. So when you go to the app layer, the SaaS apps themselves are now building in if effectively agentic and chat interfaces with intelligence. And they're also building autonomous agents. Agents are kind of like applications, like a database application. Perhaps, but they are being used increasingly in app you know, inside of a user interaction. I think a good example is GitHub Copilot. It got started as an you know, code completions on an IDE. Then we added the chat interface to it.
Then we added the agent mode to it. And now we have an autonomous agent, which in fact works completely asynchronous. Right? So all those four things are now part of essentially GitHub. And by the way, it also turns out that every other tool that is also doing any form of coding is adding more and more GitHub reports. If I had to think about GitHub monetization, we have an opportunity around just monetizing GitHub Enterprise. And then we have the ability to think about GitHub Copilot. And GitHub Copilot, as with all these form factors. And so that's exactly the same thing that's with Microsoft 365. That's the same thing that's happening with Dynamics 365.
So you have to be very open to taking your data tier, your business logic tier, and your UI tier and sort of being more expansive in it. As long as you do that, it's just that usage goes up. And that's what I think shows up in the results.
Amy Hood:
And I think, Mark, if you wanted to think about all the things in the layers that you talked about is really we're seeing very similar monetization tools exist in this transition too. Right? There's a per user logic. There's tiers of per user. Sometimes those tiers relate to consumption. Sometimes there's pure consumption models. Think you'll continue to see a blending of these, especially as the AI model capability grows. You'll end up with ways that teams are gonna wanna throttle that usage, use the best models for the best job, and I think the blending of these models will continue to be something we see on the go forward basis.
Mark Moerdler:
Thank you. I appreciate it.
Jonathan Neilson:
Thanks, Mark. Operator, next question, please.
Operator:
The next question comes from the line of Karl Keirstead with UBS. Please proceed.
Karl Keirstead:
Okay. Satya, Amy, this is the second quarter in a row of pretty material Azure upside from what sounds like an acceleration in, on-prem to Azure migration activity. I'm just wondering if you can comment on the plethora of customer conversations you've had, whether there are a couple of two or three specific catalysts that are driving that migration? And how durable a trend do you think that is? Thank you.
Satya Nadella:
Yeah. I'm just the three things are really one is the migrations. A good example would be what I referenced in my remarks with Nestle, with the SAP instances, they moved along with a lot of the data that's associated with it and a bunch of servers. So that's kind of a classic example. Think whether it's VMware migrations or migrations of SAP or even just our own server migrations, they're pretty healthy. And as it turns out that we're still not anywhere close to the finish line, if at best, maybe in the middle innings of that. The second thing that's also happening is cloud-native applications that are scaling. This is even excluding all of the AI stuff.
Just the classic cloud-native e-commerce company, let's say, these are scaling in a big way. And some of those customers were not on Azure previously, but now they're increasingly there. If they have come for AI perhaps, but they now stay for more than AI. And so to me, that's another thing you see in overall what's happening across the Azure number. And then, of course, there are the new AI workflows. So those are three things that are all, in some sense, building on each other, but that's kinda what's driving our growth.
Karl Keirstead:
Got it. Thank you.
Jonathan Neilson:
Thanks, Karl. Operator, next question, please.
Operator:
The next question comes from the line of Brent Thill with Jefferies. Please proceed.
Brent Thill:
Satya, back to the strength across the board in the quarter. Was there anything that jumped out at you or surprised you that you didn't think you were going to see but you did see in the quarter? It just the magnitude of upside, I think, had shocked many here.
Satya Nadella:
Yeah. I don't know, Brent, if anything really surprised us. But I think what we are noticing in our own build-out of these AI and in general is the platform is becoming more than here's a model, and here's an API, make some calls. I mean, that's in some sense was a bit of the state of the art maybe even a year ago. Whereas now you have essentially these very stateful app patterns that are emerging that require quite a bit of rethinking of even the app stack. I mean, take even the storage tier stuff. Right?
The degree of sophistication you have and hey, how much of an index do you really want to build by pre-processing so that your prompt engineering or context engineering, as I called, can be better and higher quality. So I think all of that is emerging. So when I look at a product like Azure Search, Fabric, and Cosmos DB, all of the things, the framework around it are just becoming robust to build serious applications. And so that's what I feel great about is the learning curve inside the company, outside the company, the diffusion of the stack. The speed with which that's emerging that you can build applications is much faster.
I always go back and say, hey, when a I don't know. A relational database came out, it took a while for people to build an ERP system, let's say. And this thing we're kind of building pretty sophisticated applications at a very, very fast clip based on, I think, the degree of maturity that's emerging.
Brent Thill:
Thanks, Brent. Operator, next question please.
Operator:
The next question comes from the line of Raimo Lenschow with Barclays. Please proceed.
Raimo Lenschow:
Perfect. Thank you. Congrats from me as well. I had one question around Copilot, and I'm obviously a happy user here at Barclays. If you think about it the one thing that we're all realizing is that Copilot is the AI part, but data is becoming more and more important. And then from there on, we can start thinking about agents. Where is the where what are you seeing in your customer conversations, Satya, about, like, that understanding that Copilot is actually just the starting point, and then from there on, you know, it's really becoming, like, much, much broader. Thank you.
Satya Nadella:
Yeah. I think that's right. Even inside of Copilot, I'm sure you're seeing it. Right? You now have analyst and researcher to just talk about two examples. And, of course, people, all the third-party agents. So, yeah, there is a lot more of just not request response. It's about spawning essentially applications that then go to work and come back. But the UI still remains very important, right, even for asynchronous work, to instruct the asynchronous work, you need UI. And to monitor asynchronous work, you need UI. It may be it may not be a chat interface. And of course, you need a way to then inspect what the asynchronous work is.
So even take the example I was giving on GitHub, even if you're not using GitHub Copilot to create the code check-in or the pull request, interestingly enough, we're seeing massive to get a Copilot code review agent even if you used maybe CloudClub, you know, CloudClub or whatever else to write the code. So that's I think what's happening across all of these. So you're absolutely right that you need it starts with some kind of a UI that's more chat-focused, but it quickly goes beyond it. And you see it in Microsoft 365, you see it in Dynamics 365, and you see it in GitHub.
Raimo Lenschow:
Thank you.
Jonathan Neilson:
Thanks, Raimo. Operator, next question, please.
Operator:
The next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.
Kash Rangan:
Hi. Thank you very much, Amy. I wanna acknowledge that, I think a few quarters ago, you said that you reached a point in time where you can accelerate Azure while slowing down CapEx. So you did it. But what is the outlook? When I look at the CapEx guidance for the upcoming quarter, certainly, I would view that as a positive indicator of the book of business you have for your cloud services. But how should we think about the shape of the curve of, CapEx vis a vis Azure growth rate in the years ahead, particularly as I listen to Satya's comments, on, the AI stack consuming more and more infrastructure.
Are we at a point where we're gonna have to continue to do this and we magically wait for inference and applications to kick in and they've therefore create a richer gross margin mix. Thank you so much for your comments, and congrats on the quarter.
Amy Hood:
Thanks, Kash. Let me back up and first say when you think about the full year comments I've made on CapEx, as well as the Q1 guidance of over $30 billion you first have to ground yourself in the fact that we have $368 billion of contracted backlog we need to deliver, not just across Azure, but, of across the breadth of the Microsoft Cloud. So in terms of feeling good, about the ROI and the growth rates and the correlation I feel very good that the spend that we're making is correlated to basically contracted on the books business.
That we need to deliver and we need the teams to execute at their very best to get the capacity in place. As quickly and effectively as they can. And so when you look we've talked about the growth rate will decline year over year. But at its core, our investments, particularly in short-lived assets, like servers, GPUs, CPUs, networking storage, is just really correlated to the backlog we see and the curve of demand. And I talked about my gosh, in January and said, I thought we'd be in better supply demand shape by June. And now I'm saying, hope I'm in better shape by December. And that's not because we slowed CapEx.
Even with accelerating the spend and trying to pull leases in and get CPUs and GPUs in the system as quickly as we can we are still seeing demand improve. And so I am not as focused, Cash, on trying to pick a date at which revenue growth and CapEx growth will meet and cross. I'm focused on building backlog, building business, and delivering capacity. Which we are seeing has a good ROI today. In terms of our ability to get that done. So I don't want people to get overly focused on a pivot point because when you're in sort of these expansive moments, picking a data point usually means you're gonna pick to be too conservative.
In terms of market share gain and in terms of winning. And so I tend to put my energy more there.
Satya Nadella:
Yeah. I think one of the other things Kash is that I think I said this in the previous earnings as well, which is the difference between a holster and a high scaler is software. And the same is going to be true here. That GPD 4.0 example I gave, is all software, right? The optimization even in the last year. So we know how to use the software skills to take any piece of hardware and make it, you know, multiple x better. And so that's kind of where the yield will come. But as Amy said, while you're really going and building out the plant, you don't wanna sort of serialize it.
You just want to go in parallel on all of these fronts. And that's sort of what will compound over time. And I do think it's important when Platts talks about the software layer, he's talking about in his comments to connect this back to the compounding S-curves. And so I would remind people that is something that we saw through the prior cloud transition. It's how we operated through that one and the same sort of skills and logic done at an even faster pace. Is what will apply the same transition.
Kash Rangan:
Sounds very encouraging. Thank you so much.
Jonathan Neilson:
Thanks, Kash. Operator, next question, please.
Operator:
The next question comes from the line of Michael Turrin with Wells Fargo. Please proceed.
Michael Turrin:
Hey, great. Thanks very much for taking the questions and congrats for me as well on the metrics working in concert here. Amy, maybe on margin, impressive to hear expectations for flat operating margin in the upcoming year as you absorb some of the mix shift towards Azure and some of the more AI-focused offerings? Can you speak in more detail just around your ability to manage those trade-offs and offset some of the mix shift? And I'm wondering, specifically just on any productivity gains you're seeing from leveraging AI internally that you'd highlight or anything else you just mentioned in underpinning the full year expectation there? Thank you.
Amy Hood:
Thanks, Michael. I think really the area to focus on is when you think about margin, I think sometimes people get a lot of energy around cost control as a driver of margin. The other driver is to focus on making sure you deliver great product that's competitive and innovative and can take share. Because that drives revenue. And revenue itself and revenue growth, as you all know better, even perhaps than I do, is a durable way to see margin improvement. It builds on itself.
That being said, the second thing I would point to is really what I talked to Cash a little bit about before, Satya and I both mentioned it, is applying all of our skill set here to deliver efficiencies. Whether that's at whatever layer of the stack that exists. The S-curves compound, and we are doing that work and we're focused on it at the same time we're doing the build-out. So you'll see improvements there even as we continue, to invest. And then, of course, it's about continuing to have great talent here, focus on products and opportunities where we have the biggest markets. And the most likelihood of success.
And so when we have those three things happen, and the energy is right, and the focus is there, gives me confidence in terms of margin delivery. But make no mistake, starts and ends really with product. Which is what we're really focused on here and delivering that to customers.
Michael Turrin:
That all sounds pretty good. Thanks very much.
Jonathan Neilson:
Thanks, Michael. That wraps up the Q and A portion of today's earnings call. Thank you for joining us today. We look forward to speaking with you all soon.
Satya Nadella:
Thank you. Thank you.
Operator:
This concludes today's conference. You may disconnect your lines at this time. Thank you for your participation."
Nvidia Corporation (NVDA),Q1,2025,Nvidia (NVDA) Q1 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2024/05/29/nvidia-nvda-q1-2025-earnings-call-transcript/,"Nvidia
(
NVDA
+0.74%
)
Q1 2025 Earnings Call
May 22, 2024
,
5:00 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Operator
Good afternoon. My name is Regina, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's first-quarter earnings call. All lines have been placed on mute to prevent any background noise.
After the speakers' remarks, there will be a question-and-answer session. [Operator instructions] Thank you. Simona Jankowski, you may begin your conference.
Simona Jankowski
--
Vice President, Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the first quarter of fiscal 2025. With me today from NVIDIA are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the second quarter of fiscal 2025. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, May 22, 2024, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. Let me highlight some upcoming events. On Sunday, June 2, ahead of the Computex Technology trade show in Taiwan, Jensen will deliver a keynote which will be held in person in Taipei as well as streamed live.
And on June 5, we will present at the Bank of America Technology Conference in San Francisco. With that, let me turn the call over to Colette.
Colette Kress
--
Executive Vice President, Chief Financial Officer
Thanks, Simona. Q1 was another record quarter. Revenue of $26 billion was up 18% sequentially and up 262% year on year and well above our outlook of $24 billion. Starting with Data Center.
Data Center revenue of $22.6 billion was a record, up 23% sequentially and up 427% year on year, driven by continued strong demand for the NVIDIA Hopper GPU computing platform. Compute revenue grew more than 5x and networking revenue more than 3x from last year. Strong sequential Data Center growth was driven by all customer types, led by enterprise and consumer Internet companies. Large cloud providers continue to drive strong growth as they deploy and ramp NVIDIA AI infrastructure at scale and represented the mid-40s as a percentage of our Data Center revenue.
Training and inferencing AI on NVIDIA CUDA is driving meaningful acceleration in cloud rental revenue growth, delivering an immediate and strong return on cloud providers' investment. For every $1 spent on NVIDIA AI infrastructure, cloud providers have an opportunity to earn $5 in GPU instant hosting revenue over four years. NVIDIA's rich software stack and ecosystem and tight integration with cloud providers makes it easy for end customers up and running on NVIDIA GPU instances in the public cloud. For cloud rental customers, NVIDIA GPUs offer the best time-to-train models, the lowest cost to train models, and the lowest cost to inference large language models.
For public cloud providers, NVIDIA brings customers to their cloud, driving revenue growth and returns on their infrastructure investments. Leading LLM companies such as OpenAI, Adept, Anthropic, Character.ai, Cohere, Databricks, DeepMind, Meta, Mistral, XAi, and many others are building on NVIDIA AI in the cloud. Enterprises drove strong sequential growth in Data Center this quarter. We supported Tesla's expansion of their training AI cluster to 35,000 H100 GPUs.
Their use of NVIDIA AI infrastructure paved the way for the breakthrough performance of FSD version 12, their latest autonomous driving software based on Vision. NVIDIA Transformers, while consuming significantly more computing, are enabling dramatically better autonomous driving capabilities and propelling significant growth for NVIDIA AI infrastructure across the automotive industry. We expect automotive to be our largest enterprise vertical within Data Center this year, driving a multibillion revenue opportunity across on-prem and cloud consumption. Consumer Internet companies are also a strong growth vertical.
A big highlight this quarter was Meta's announcement of Llama 3, their latest large language model, which was trained on a cluster of 24,000 H100 GPUs. Llama 3 powers Meta AI, a new AI assistant available on Facebook, Instagram, WhatsApp, and Messenger. Llama 3 is openly available and has kick-started a wave of AI development across industries. As generative AI makes its way into more consumer Internet applications, we expect to see continued growth opportunities as inference scales both with model complexity as well as with the number of users and number of queries per user, driving much more demand for AI compute.
In our trailing four quarters, we estimate that inference drove about 40% of our Data Center revenue. Both training and inference are growing significantly. Large clusters like the ones built by Meta and Tesla are examples of the essential infrastructure for AI production, what we refer to as AI factories. These next-generation data centers host advanced full-stack accelerated computing platforms where the data comes in and intelligence comes out.
In Q1, we worked with over 100 customers building AI factories ranging in size from hundreds to tens of thousands of GPUs, with some reaching 100,000 GPUs. From a geographic perspective, Data Center revenue continues to diversify as countries around the world invest in sovereign AI. Sovereign AI refers to a nation's capabilities to produce artificial intelligence using its own infrastructure, data, workforce, and business networks. Nations are building up domestic computing capacity through various models.
Some are procuring and operating sovereign AI clouds in collaboration with state-owned telecommunication providers or utilities. Others are sponsoring local cloud partners to provide a shared AI computing platform for public and private sector use. For example, Japan plans to invest more than $740 million in key digital infrastructure providers, including KDDI, Sakura Internet, and SoftBank to build out the nation's sovereign AI infrastructure. France-based Scaleway, a subsidiary of the Iliad Group, is building Europe's most powerful cloud-native AI supercomputer.
In Italy, Swisscom Group will build the nation's first and most powerful NVIDIA DGX-powered supercomputer to develop the first LLM natively trained in the Italian language. And in Singapore, the National Supercomputer Centre is getting upgraded with NVIDIA Hopper GPUs, while Singtel is building NVIDIA's accelerated AI factories across Southeast Asia. NVIDIA's ability to offer end-to-end compute to networking technologies, full-stack software, AI expertise, and rich ecosystem of partners and customers allows sovereign AI and regional cloud providers to jump-start their country's AI ambitions. From nothing the previous year, we believe sovereign AI revenue can approach the high single-digit billions this year.
The importance of AI has caught the attention of every nation. We ramped new products designed specifically for China that don't require export control license. Our Data Center revenue in China is down significantly from the level prior to the imposition of the new export control restrictions in October. We expect the market in China to remain very competitive going forward.
From a product perspective, the vast majority of compute revenue was driven by our Hopper GPU architecture. Demand for Hopper during the quarter continues to increase. Thanks to CUDA algorithm innovations, we've been able to accelerate LLM inference on H100 by up to 3x, which can translate to a 3x cost reduction for serving popular models like Llama 3. We started sampling the H200 in Q1 and are currently in production with shipments on track for Q2.
The first H200 system was delivered by Jensen to Sam Altman and the team at OpenAI and powered their amazing GPT-4o demos last week. H200 nearly doubles the inference performance of H100, delivering significant value for production deployments. For example, using Llama 3 with 700 billion parameters, a single NVIDIA HGX H200 server can deliver 24,000 tokens per second, supporting more than 2,400 users at the same time. That means for every $1 spent on NVIDIA HGX H200 servers at current prices per token, an API provider serving Llama 3 tokens can generate $7 in revenue over four years.
With ongoing software optimizations, we continue to improve the performance of NVIDIA AI infrastructure for serving AI models. While supply for H100 grew, we are still constrained on H200. At the same time, Blackwell is in full production. We are working to bring up our system and cloud partners for global availability later this year.
Demand for H200 and Blackwell is well ahead of supply, and we expect demand may exceed supply well into next year. Grace Hopper Superchip is shipping in volume. Last week at the International Supercomputing Conference, we announced that nine new supercomputers worldwide are using Grace Hopper for a combined 200 exaflops of energy-efficient AI processing power delivered this year. These include the Alps Supercomputer at the Swiss National Supercomputing Centre, the fastest AI supercomputer in Europe; Isambard-AI at the University of Bristol in the U.K.; and JUPITER in the Julich Supercomputing Centre in Germany.
We are seeing an 80% attach rate of Grace Hopper in supercomputing due to its high energy efficiency and performance. We are also proud to see supercomputers powered with Grace Hopper take the No. 1, the No. 2, and the No.
3 spots of the most energy-efficient supercomputers in the world. Strong networking year-on-year growth was driven by InfiniBand. We experienced a modest sequential decline, which was largely due to the timing of supply, with demand well ahead of what we were able to ship. We expect networking to return to sequential growth in Q2.
In the first quarter, we started shipping our new Spectrum-X Ethernet networking solution optimized for AI from the ground up. It includes our Spectrum-4 switch, BlueField-3 DPU, and new software technologies to overcome the challenges of AI on Ethernet to deliver 1.6x higher networking performance for AI processing compared with traditional Ethernet. Spectrum-X is ramping in volume with multiple customers, including a massive 100,000 GPU cluster. Spectrum-X opens a brand-new market to NVIDIA networking and enables Ethernet-only data centers to accommodate large-scale AI.
We expect Spectrum-X to jump to a multibillion-dollar product line within a year. At GTC in March, we launched our next-generation AI factory platform, Blackwell. The Blackwell GPU architecture delivers up to 4x faster training and 30x faster inference than the H100 and enables real-time generative AI on trillion-parameter large language models. Blackwell is a giant leap with up to 25x lower TCO and energy consumption than Hopper.
The Blackwell platform includes the fifth-generation NVLink with a multi-GPU spine and new InfiniBand and Ethernet switches, the X800 series designed for a trillion-parameter scale AI. Blackwell is designed to support data centers universally, from hyperscale to enterprise, training to inference, x86 to Grace CPUs, Ethernet to InfiniBand networking, and air cooling to liquid cooling. Blackwell will be available in over 100 OEM and ODM systems at launch, more than double the number of Hoppers launched and representing every major computer maker in the world. This will support fast and broad adoption across the customer types, workloads, and data center environments in the first-year shipments.
Blackwell time-to-market customers include Amazon, Google, Meta, Microsoft, OpenAI, Oracle, Tesla, and XAi. We announced a new software product with the introduction of NVIDIA Inference Microservices, or NIM. NIM provides secure and performance-optimized containers powered by NVIDIA CUDA acceleration in network computing and inference software, including Triton and PrintServer, and TensorRT-LLM with industry-standard APIs for a broad range of use cases, including large language models for text, speech, imaging, vision, robotics, genomics, and digital biology. They enable developers to quickly build and deploy generative AI applications using leading models from NVIDIA, AI21, Adept, Cohere, Getty Images, and Shutterstock, and open models from Google, Hugging Face, Meta, Microsoft, Mistral AI, Snowflake, and Stability AI.
NIMs will be offered as part of our NVIDIA AI enterprise software platform for production deployment in the cloud or on-prem. Moving to gaming and AI PCs. Gaming revenue of $2.65 billion was down 8% sequentially and up 18% year on year, consistent with our outlook for a seasonal decline. The GeForce RTX SUPER GPUs market reception is strong and end demand and channel inventory remained healthy across the product range.
From the very start of our AI journey, we equipped GeForce RTX GPUs with CUDA Tensor cores. Now, with over 100 million of an installed base, GeForce RTX GPUs are perfect for gamers, creators, AI enthusiasts, and offer unmatched performance for running generative AI applications on PCs. NVIDIA has full technology stack for deploying and running fast and efficient generative AI inference on GeForce RTX PCs. TensorRT-LLM now accelerates Microsoft's Phi-3 Mini model and Google's Gemma 2B and 7B models as well as popular AI frameworks, including LangChain and LlamaIndex.
Yesterday, NVIDIA and Microsoft announced AI performance optimizations for Windows to help run LLMs up to 3x faster on NVIDIA GeForce RTX AI PCs. And top game developers, including NetEase Games, Tencent, and Ubisoft are embracing NVIDIA Avatar Character Engine to create lifelike avatars to transform interactions between gamers and non-playable characters. Moving to ProViz, revenue of $427 million was down 8% sequentially and up 45% year on year. We believe generative AI and Omniverse industrial digitalization will drive the next wave of professional visualization growth.
At GTC, we announced new Omniverse Cloud APIs to enable developers to integrate Omniverse industrial digital twin and simulation technologies into their applications. Some of the world's largest industrial software makers are adopting these APIs, including ANSYS, Cadence, 3DXCITE, Dassault Systems brand, and Siemens. And developers can use them to stream industrial digital twins with spatial computing devices such as Apple Vision Pro. Omniverse Cloud APIs will be available on Microsoft Azure later this year.
Companies are using Omniverse to digitalize their workflows. Omniverse power digital twins enable Wistron, one of our manufacturing partners, to reduce end-to-end production cycle times by 50% and defect rates by 40%. And BYD, the world's largest electric vehicle maker, is adopting Omniverse for virtual factory planning and retail configurations. Moving to automotive.
Revenue was $329 million, up 17% sequentially and up 11% year on year. Sequential growth was driven by the ramp of AI Cockpit solutions with global OEM customers and strength in our self-driving platforms. Year-on-year growth was driven primarily by self-driving. We supported Xiaomi in the successful launch of its first electric vehicle, the SU7 sedan built on the NVIDIA DRIVE Orin, our AI car computer for software-defined AV fleets.
We also announced a number of new design wins on NVIDIA DRIVE Thor, the successor to Orin, powered by the new NVIDIA Blackwell architecture with several leading EV makers, including BYD, XPeng, GAC's Aion Hyper, and Nuro. DRIVE Thor is slated for production vehicles starting next year. OK, moving to the rest of the P&L. GAAP gross margin expanded sequentially to 78.4% and non-GAAP gross margins to 78.9% on lower inventory targets.
As noted last quarter, both Q4 and Q1 benefited from favorable component costs. Sequentially, GAAP operating expenses were up 10% and non-GAAP operating expenses were up 13%, primarily reflecting higher compensation-related costs and increased compute and infrastructure investments. In Q1, we returned $7.8 billion to shareholders in the form of share repurchases and cash dividends. Today, we announced a 10-for-1 split of our shares with June 10 as the first day of trading on a split-adjusted basis.
We are also increasing our dividend by 150%. Let me turn to the outlook for the second quarter. Total revenue is expected to be $28 billion, plus or minus 2%. We expect sequential growth in all market platforms.
GAAP and non-GAAP gross margins are expected to be 74.8% and 75.5%, respectively, plus or minus 50 basis points, consistent with our discussion last quarter. For the full year, we expect gross margins to be in the mid-70s percent range. GAAP and non-GAAP operating expenses are expected to be approximately $4 billion and $2.8 billion, respectively. Full-year opex is expected to grow in the low 40% range.
GAAP and non-GAAP other income and expenses are expected to be an income of approximately $300 million, excluding gains and losses from nonaffiliated investments.GAAP and non-GAAP tax rates are expected to be 17%, plus or minus 1%, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website. I would like to now turn it over to Jensen as he would like to make a few comments.
Jensen Huang
--
President and Chief Operating Officer
Thanks, Colette. The industry is going through a major change. Before we start Q&A, let me give you some perspective on the importance of the transformation. The next industrial revolution has begun.
Companies and countries are partnering with NVIDIA to shift the trillion-dollar installed base of traditional data centers to accelerated computing and build a new type of data center, AI factories, to produce a new commodity, artificial intelligence. AI will bring significant productivity gains to nearly every industry and help companies be more cost- and energy-efficient while expanding revenue opportunities. CSPs were the first generative AI movers. With NVIDIA, CSPs accelerated workloads to save money and power.
The tokens generated by NVIDIA Hopper drive revenues for their AI services. And NVIDIA cloud instances attract rental customers from our rich ecosystem of developers. Strong and accelerating demand for generative AI training and inference on the Hopper platform propels our Data Center growth. Training continues to scale as models learn to be multimodal, understanding text, speech, images, video, and 3D and learn to reason and plan.
Our inference workloads are growing incredibly. With generative AI, inference, which is now about fast token generation at massive scale, has become incredibly complex. Generative AI is driving a from-foundation-up full-stack computing platform shift that will transform every computer interaction. From today's information retrieval model, we are shifting to an answers and skills generation model of computing.
AI will understand context and our intentions, be knowledgeable, reason, plan, and perform tasks. We are fundamentally changing how computing works and what computers can do, from general-purpose CPU to GPU accelerated computing, from instruction-driven software to intention-understanding models, from retrieving information to performing skills and, at the industrial level, from producing software to generating tokens, manufacturing digital intelligence. Token generation will drive a multiyear build-out of AI factories. Beyond cloud service providers, generative AI has expanded to consumer Internet companies and enterprise, sovereign AI, automotive, and healthcare customers, creating multiple multibillion-dollar vertical markets.
The Blackwell platform is in full production and forms the foundation for trillion-parameter scale generative AI. The combination of Grace CPU, Blackwell GPUs, NVLink, Quantum, Spectrum, mix and switches, high-speed interconnects, and a rich ecosystem of software and partners let us expand and offer a richer and more complete solution for AI factories than previous generations. Spectrum-X opens a brand-new market for us to bring large-scale AI to Ethernet-only data centers. And NVIDIA NIMs is our new software offering that delivers enterprise-grade optimized generative AI to run on CUDA everywhere from the cloud to on-prem data centers, to RTX AI PCs through our expansive network of ecosystem partners.
From Blackwell to Spectrum-X to NIMs, we are poised for the next wave of growth. Thank you.
Simona Jankowski
--
Vice President, Investor Relations
Thank you, Jensen. We will now open the call for questions. Operator, could you please poll for questions?
Questions & Answers:
Operator
[Operator instructions] We'll pause for just a moment to compile the Q&A roster. As a reminder, please limit yourself to one question. Your first question comes from the line of Stacy Rasgon with Bernstein. Please go ahead.
Stacy Rasgon
--
AllianceBernstein -- Analyst
Hi, guys. Thanks for taking my questions. My first one, I wanted to drill a little bit into the Blackwell comment that it's in full production now. What does that suggest with regard to shipments and delivery timing if that product is -- it doesn't sound like it's sampling anymore.
What does that mean when that's actually in customers' hands if it's in production now?
Jensen Huang
--
President and Chief Operating Officer
We will be shipping -- well, we've been in production for a little bit of time. But our production shipments will start in Q2 and ramp in Q3, and customers should have data centers stood up in Q4.
Stacy Rasgon
--
AllianceBernstein -- Analyst
Got it. So, this year, we will see Blackwell revenue, it sounds like.
Jensen Huang
--
President and Chief Operating Officer
We will see a lot of Blackwell revenue this year.
Operator
Our next question will come from the line of Timothy Arcuri with UBS. Please go ahead.
Tim Arcuri
--
UBS -- Analyst
Thanks a lot. I wanted to ask, Jensen, about the deployment of Blackwell versus Hopper just given the system's nature and all the demand for GB that you have. How does the deployment of this stuff differ from Hopper? I guess I ask because liquid cooling at scale hasn't been done before, and there's some engineering challenges both at the node level and within the data center. So, do these complexities sort of elongate the transition? And how do you sort of think about how that's all going? Thanks.
Jensen Huang
--
President and Chief Operating Officer
Yep. Blackwell comes in many configurations. Blackwell is a platform, not a GPU. And the platform includes support for air-cooled, liquid-cooled, x86 and Grace, InfiniBand, now Spectrum-X, and very large NVLink domain that I demonstrated at GTC -- that I showed at GTC.
And so, for some customers, they will ramp into their existing installed base of data centers that are already shipping Hoppers. They will easily transition from H100 to H200 to B100. And so, Blackwell systems have been designed to be backwards compatible, if you will, electrically, mechanically. And of course, the software stack that runs on Hopper will run fantastically on Blackwell.
We also have been priming the pump, if you will, with the entire ecosystem, getting them ready for liquid cooling. We've been talking to the ecosystem about Blackwell for quite some time. And the CSPs, the data centers, the ODMs, the system makers, our supply chain; beyond them, the cooling supply chain base, liquid cooling supply chain base, data center supply chain base, no one is going to be surprised with Blackwell coming and the capabilities that we would like to deliver with Grace Blackwell 200. GB200 is going to be exceptional.
Operator
Our next question will come from the line of Vivek Arya with Bank of America Securities. Please go ahead.
Vivek Arya
--
Bank of America Merrill Lynch -- Analyst
Thanks for taking my question. Jensen, how are you ensuring that there is enough utilization of your products and that there isn't a pull ahead or a holding behavior because of tight supply, competition, or other factors? Basically, what checks have you built in the system to give us confidence that monetization is keeping pace with your really very strong shipment growth?
Jensen Huang
--
President and Chief Operating Officer
Well, I guess there's the big picture view that I'll come to, but I'll answer your question directly. The demand for GPUs in all the data centers is incredible. We're racing every single day. And the reason for that is because applications like ChatGPT and GPT-4o, and now, it's going to be multi-modality, Gemini and its ramp and Anthropic, and all of the work that's being done at all the CSPs are consuming every GPU that's out there.
There's also a long line of generative AI start-ups, some 15,000, 20,000 start-ups that are in all different fields, from multimedia to digital characters, of course, all kinds of design tool application, productivity applications, digital biology, the moving of the AV industry to video so that they can train end-to-end models to expand the operating domain of self-driving cars, the list is just quite extraordinary. We're racing actually. Customers are putting a lot of pressure on us to deliver the systems and stand those up as quickly as possible. And of course, I haven't even mentioned all of the sovereign AIs who would like to train all of their regional natural resource of their country, which is their data, to train their regional models.
And there's a lot of pressure to stand those systems up. So, anyhow, the demand, I think, is really, really high and it outstrips our supply. That's the reason why I jumped in to make a few comments. Longer term, we're completely redesigning how computers work.
And this is a platform shift. Of course, it's been compared to other platform shifts in the past. But time will clearly tell that this is much, much more profound than previous platform shifts. And the reason for that is because the computer is no longer an instruction-driven-only computer.
It's an intention-understanding computer. And it understands, of course, the way we interact with it, but it also understands our meaning, what we intend that we asked it to do. And it has the ability to reason, inference iteratively to process a plan, and come back with a solution. And so, every aspect of the computer is changing in such a way that instead of retrieving prerecorded files, it is now generating contextually relevant intelligent answers.
And so, that's going to change computing stacks all over the world. And you saw a build that, in fact, even the PC computing stack is going to get revolutionized. And this is just the beginning of all the things that -- what people see today are the beginning of the things that we're working in our labs and the things that we're doing with all the start-ups and large companies and developers all over the world. It's going to be quite extraordinary.
Operator
Our next question will come from the line of Joe Moore with Morgan Stanley. Please go ahead.
Joe Moore
--
Morgan Stanley -- Analyst
Great. Thank you. Understanding what you just said about how strong demand is, you have a lot of demand for H200 and for Blackwell products. Do you anticipate any kind of pause with Hopper and H100 as you sort of migrate to those products? Will people wait for those new products, which would be a good product to have? Or do you think there's enough demand for H100 to sustain growth?
Jensen Huang
--
President and Chief Operating Officer
We see increasing demand of Hopper through this quarter. And we expect demand to outstrip supply for some time as we now transition to H200, as we transition to Blackwell. Everybody is anxious to get their infrastructure online. And the reason for that is because they're saving money and making money, and they would like to do that as soon as possible.
Operator
Our next question will come from the line of Toshiya Hari with Goldman Sachs. Please go ahead.
Toshiya Hari
--
Goldman Sachs -- Analyst
Hi. Thank you so much for taking the question. Jensen, I wanted to ask about competition. I think many of your cloud customers have announced new or updates to their existing internal programs, right, in parallel to what they're working on with you guys.
To what extent did you consider them as competitors, medium to long term? And in your view, do you think they're limited to addressing mostly internal workloads, or could they be broader in what they address going forward? Thank you.
Jensen Huang
--
President and Chief Operating Officer
Yeah. We're different in several ways. First, NVIDIA's accelerated computing architecture allows customers to process every aspect of their pipeline from unstructured data processing to prepare it for training, to structured data processing, data frame processing like SQL to prepare for training, to training to inference. And as I was mentioning in my remarks, that inference has really fundamentally changed, it's now generation.
It's not trying to just detect the cat, which was plenty hard in itself, but it has to generate every pixel of a cat. And so, the generation process is a fundamentally different processing architecture. And it's one of the reasons why TensorRT-LLM was so well received. We improved the performance in using the same chips on our architecture by a factor of three.
That kind of tells you something about the richness of our architecture and the richness of our software. So, one, you could use NVIDIA for everything, from computer vision to image processing, to computer graphics, to all modalities of computing. And as the world is now suffering from computing cost and computing energy inflation because general-purpose computing has run its course, accelerated computing is really the sustainable way of going forward. So, accelerated computing is how you're going to save money in computing, is how you're going to save energy in computing.
And so, the versatility of our platform results in the lowest TCO for their data centers. Second, we're in every cloud. And so, for developers that are looking for a platform to develop on, starting with NVIDIA is always a great choice. And we're on-prem.
We're in the cloud. We're in computers of any size and shape. We're practically everywhere. And so, that's the second reason.
The third reason has to do with the fact that we build AI factories. And this is becoming more apparent to people that AI is not a chip problem only. It starts, of course, with very good chips and we build a whole bunch of chips for our AI factories, but it's a systems problem. In fact, even AI is now a systems problem.
It's not just one large language model. It's a complex system of a whole bunch of large language models that are working together. And so, the fact that NVIDIA builds this system causes us to optimize all of our chips to work together as a system, to be able to have software that operates as a system, and to be able to optimize across the system. And just to put it in perspective, in simple numbers, if you had a $5 billion infrastructure and you improved the performance by a factor of two, which we routinely do, when you improve the infrastructure by a factor of two, the value to you is $5 billion.
All the chips in that data center doesn't pay for it. And so, the value of it is really quite extraordinary. And this is the reason why today, performance matters in everything. This is at a time when the highest performance is also the lowest cost because the infrastructure cost of carrying all of these chips cost a lot of money.
And it takes a lot of money to fund the data center, to operate the data center, the people that goes along with it, the power that goes along with it, the real estate that goes along with it, and all of it adds up. And so, the highest performance is also the lowest TCO.
Operator
Our next question will come from the line of Matt Ramsay with TD Cowen. Please go ahead.
Matt Ramsay
--
TD Cowen -- Analyst
Thank you very much. Good afternoon, everyone. Jensen, I've been in the data center industry my whole career. I've never seen the velocity that you guys are introducing new platforms at the same combination of the performance jumps that you're getting, I mean, 5x in training, some of the stuff you talked about at GTC up to 30x in inference.
And it's an amazing thing to watch but it also creates an interesting juxtaposition where the current generation of product that your customers are spending billions of dollars on is going to be not as competitive with your new stuff very, very much more quickly than the depreciation cycle of that product. So, I'd like you to, if you wouldn't mind, speak a little bit about how you're seeing that situation evolve itself with customers. As you move to Blackwell, they're going to have very large installed bases, obviously software compatible, but large installed bases of product that's not nearly as performant as your new generation stuff. And it'd be interesting to hear what you see happening with customers along that path.
Thank you.
Jensen Huang
--
President and Chief Operating Officer
Yeah, really appreciate it. Three points that I'd like to make. If you're 5% into the build-out versus if you're 95% into the build-out, you're going to feel very differently. And because you're only 5% into the build-out anyhow, you build as fast as you can.
And when Blackwell comes, it's going to be terrific. And then after Blackwell, as you mentioned, we have other Blackwells coming. And then there's a short -- we're in a one-year rhythm as we've explained to the world. And we want our customers to see our road map for as far as they like, but they're early in their build-out anyways and so they had to just keep on building, OK? And so, there's going to be a whole bunch of chips coming at them, and they just got to keep on building and just, if you will, performance-average your way into it.
So, that's the smart thing to do. They need to make money today. They want to save money today. And time is really, really valuable to them.
Let me give you an example of time being really valuable, why this idea of standing up a data center instantaneously is so valuable, and getting this thing called time-to-train is so valuable. The reason for that is because the next company who reaches the next major plateau gets to announce a groundbreaking AI. And the second one after that gets to announce something that's 0.3% better. And so, the question is, do you want to be repeatedly the company delivering groundbreaking AI or the company delivering 0.3% better? And that's the reason why this race, as in all technology races, the race is so important.
And you're seeing this race across multiple companies because this is so vital to have technology leadership, for companies to trust the leadership that want to build on your platform and know that the platform that they're building on is going to get better and better. And so, leadership matters a great deal. Time-to-train matters a great deal. The difference between time-to-train that is three months earlier just to get it done, in order to get time-to-train on three months' project, getting started three months earlier is everything.
And so, it's the reason why we're standing up Hopper systems like mad right now because the next plateau is just around the corner. And so, that's the second reason. The first comment that you made is really a great comment, which is how is it that we're moving so fast and advancing them quickly, because we have all the stacks here. We literally build the entire data center, and we can monitor everything, measure everything, optimize across everything.
We know where all the bottlenecks are. We're not guessing about it. We're not putting up PowerPoint slides that look good. We're actually -- we also like our PowerPoint slides to look good, but we're delivering systems that perform at scale.
And the reason why we know they perform at scale is because we built it all here. Now, one of the things that we do that's a bit of a miracle is that we build entire AI infrastructure here but then we disaggregate it and integrate it into our customers' data centers however they liked. But we know how it's going to perform, and we know where the bottlenecks are. We know where we need to optimize with them, and we know where we have to help them improve their infrastructure to achieve the most performance.
This deep intimate knowledge at the entire data center scale is fundamentally what sets us apart today. We build every single chip from the ground up. We know exactly how processing is done across the entire system. And so, we understand exactly how it's going to perform and how to get the most out of it with every single generation.
So, I appreciate it. Those are the three points.
Operator
Your next question will come from the line of Mark Lipacis with Evercore ISI. Please go ahead.
Mark Lipacis
--
Evercore ISI -- Analyst
Hi. Thanks for taking my question. Jensen, in the past, you've made the observation that general-purpose computing ecosystems typically dominated each computing era. And I believe the argument was that they could adapt to different workloads, get higher utilization, drive cost of compute cycle down.
And this is a motivation for why you were driving to a general-purpose GPU CUDA ecosystem for accelerated computing. And if I mischaracterized that observation, please do let me know. So, the question is, given that the workloads that are driving demand for your solutions are being driven by neural network training and inferencing, which on the surface seem like a limited number of workloads, then it might also seem to lend themselves to custom solutions. And so, then the question is, does the general-purpose computing framework become more at risk or is there enough variability or a rapid enough evolution on these workloads that support that historical general-purpose framework? Thank you.
Jensen Huang
--
President and Chief Operating Officer
Yeah. NVIDIA's accelerated computing is versatile, but I wouldn't call it general purpose. Like, for example, we wouldn't be very good at running the spreadsheet. That was really designed for general-purpose computing.
And so, the control loop of an operating system code probably isn't fantastic for general-purpose computing, not for accelerated computing. And so, I would say that we're versatile, and that's usually the way I describe it. There's a rich domain of applications that we're able to accelerate over the years, but they all have a lot of commonalities, maybe some deep differences, but commonalities. They're all things that I can run in parallel, they're all heavily threaded.
5% of the code represents 99% of the run time, for example. Those are all properties of accelerated computing. The versatility of our platform and the fact that we design entire systems is the reason why over the course of the last 10 years or so, the number of start-ups that you guys have asked me about in these conference calls is fairly large. And every single one of them, because of the brittleness of their architecture, the moment generative AI came along or the moment the fusion models came along, the moment the next models are coming along now, and now all of a sudden, look at this, large language models with memory because the large language model needs to have memory so they can carry on a conversation with you, understand the context.
All of a sudden, the versatility of the Grace memory became super important. And so, each one of these advances in generative AI and the advancement of AI really begs for not having a widget that's designed for one model but to have something that is really good for this entire domain, properties of this entire domain, but obeys the first principles of software: that software is going to continue to evolve, that software is going to keep getting better and bigger. We believe in the scaling of these models. There's a lot of reasons why we're going to scale by easily 1 million times in the coming few years for good reasons, and we're looking forward to it, and we're ready for it.
And so, the versatility of our platform is really quite key. And if you're too brittle and too specific, you might as well just build an FPGA or you build an ASIC or something like that, but that's hardly a computer.
Operator
Our next question will come from the line of Blayne Curtis with Jefferies. Please go ahead.
Blayne Curtis
--
Jefferies -- Analyst
Thanks for taking my question. I'm actually kind of curious, I mean, being supply constrained, how do you think about -- I mean, you came out with a product for China, H20. I'm assuming there'd be a ton of demand for it, but obviously, you're trying to serve your customers with the other Hopper products. Just kind of curious how you're thinking about that in the second half, if you could elaborate, any impact, what you're thinking for sales as well as gross margin.
Jensen Huang
--
President and Chief Operating Officer
I didn't hear your questions. Something bleeped out.
Simona Jankowski
--
Vice President, Investor Relations
H20 and how you're thinking about allocating supply between the different Hopper products.
Jensen Huang
--
President and Chief Operating Officer
Well, you know, we have customers that we honor and we do our best for every customer. It is the case that our business in China is substantially lower than the levels of the past. And it's a lot more competitive in China now because of the limitations on our technology. And so, those matters are true.
However, we continue to do our best to serve the customers in the markets there, and to the best of our ability, we'll do our best. But I think overall, the comments that we made about demand outstripping supply is for the entire market and particularly so for H200 and Blackwell toward the end of the year.
Operator
Our next question will come from the line of Srini Pajjuri with Raymond James. Please go ahead.
Srini Pajjuri
--
Raymond James -- Analyst
Thank you. Jensen, actually more of a clarification on what you said. GB200 systems, it looks like there is a significant demand for systems. Historically, I think you've sold a lot of HGX boards and some GPUs and the systems business was relatively small.
So, I'm just curious, why is it that now you are seeing such a strong demand for systems going forward? Is it just the TCO, or is it something else? Or is it just the architecture? Thank you.
Jensen Huang
--
President and Chief Operating Officer
Yeah. I appreciate that. In fact, the way we sell GB200 is the same. We disaggregate all of the components that make sense, and we integrate it into computer makers.
We have 100 different computer system configurations that are coming this year for Blackwell. And that is off the charts. Hopper, frankly, had only half, but that's at its peak. It started out with way less than that even.
And so, you're going to see liquid-cooled version, air-cooled version, x86 versions, Grace versions, so on and so forth. There's a whole bunch of systems that are being designed. And they're offered from all of our ecosystem of great partners. Nothing has really changed.
Now, of course, the Blackwell platform has expanded our offering tremendously, the integration of CPUs, and the much more compressed density of computing. Liquid cooling is going to save data centers a lot of money in provisioning power and not to mention to be more energy efficient. And so, it's a much better solution. It's more expansive, meaning that we offer a lot more components of a data center.
And everybody wins. The data center gets much higher performance, networking from networking switches, networking -- of course, NICs. We have Ethernet now so that we can bring AI to a large-scale NVIDIA AI to customers who only know how to operate Ethernet because of the ecosystem that they have. And so, Blackwell is much more expansive.
We have a lot more to offer our customers this generation around.
Operator
Our next question will come from the line William Stein with Truist Securities. Please go ahead.
William Stein
--
Truist Securities -- Analyst
Great. Thanks for taking my question. Jensen, at some point, NVIDIA decided that while there were reasonably good CPUs available for data center operations, your ARM-based Grace CPU provides some real advantage that made that technology worth to bring to customers, perhaps related to cost or power consumption or technical synergies between Grace and Hopper or Grace and Blackwell. Can you address whether there could be a similar dynamic that might emerge on the client side whereby, while there are very good solutions, you've highlighted that Intel and AMD are very good partners and deliver great products in x86, but there might be some, especially in emerging AI workloads, advantage that NVIDIA can deliver that others have more of a challenge?
Jensen Huang
--
President and Chief Operating Officer
Well, you mentioned some really good reasons. It is true that for many of the applications, our partnership with x86 partners are really terrific and we build excellent systems together. But Grace allows us to do something that isn't possible with the configuration, the system configuration today. The memory system between Grace and Hopper are coherent and connected.
The interconnect between the two chips -- calling it two chips is almost weird because it's like a superchip. The two of them are connected with this interface that's like at terabytes per second. It's off the charts. And the memory that's used by Grace is LPDDR.
It's the first data center-grade low-power memory. And so, we save a lot of power on every single node. And then finally, because of the architecture, because we can create our own architecture with the entire system now, we could create something that has a really large NVLink domain, which is vitally important to the next-generation large language models for inferencing. And so, you saw that GB200 has a 72-node NVLink domain.
That's like 72 Blackwells connected together into one giant GPU. And so, we needed Grace Blackwells to be able to do that. And so, there are architectural reasons, there are software programming reasons and then there are system reasons that are essential for us to build them that way. And so, if we see opportunities like that, we'll explore it.
And today, as you saw at the build yesterday, which I thought was really excellent, Satya announced the next-generation PCs, Copilot+ PC, which runs fantastically on NVIDIA's RTX GPUs that are shipping in laptops. But it also supports ARM beautifully. And so, it opens up opportunities for system innovation even for PCs.
Operator
Our last question comes from the line of C.J. Muse with Cantor Fitzgerald. Please go ahead.
C.J. Muse
--
Cantor Fitzgerald -- Analyst
Yeah, good afternoon. Thank you for taking the question. I guess, Jensen, a bit of a longer-term question. I know Blackwell hasn't even launched yet, but obviously, investors are forward-looking.
And amid rising potential competition from GPUs and custom ASICs, how are you thinking about NVIDIA's pace of innovation? And your million-fold scaling over the last decade, truly impressive, CUDA, precision, Grace, Cohere, and connectivity. When you look forward, what frictions need to be solved in the coming decade? And I guess maybe more importantly, what are you willing to share with us today?
Jensen Huang
--
President and Chief Operating Officer
Well, I can announce that after Blackwell, there's another chip. And we are on a one-year rhythm. And you can also count on us having new networking technology on a very fast rhythm. We're announcing Spectrum-X for Ethernet.
But we're all in on Ethernet, and we have a really exciting road map coming for Ethernet. We have a rich ecosystem of partners. Dell announced that they're taking Spectrum-X to market. We have a rich ecosystem of customers and partners who are going to announce taking our entire AI factory architecture to market.
And so, for companies that want the ultimate performance, we have InfiniBand computing fabric. InfiniBand is a computing fabric, Ethernet to network. And InfiniBand, over the years, started out as a computing fabric, became a better and better network. Ethernet is a network and with Spectrum-X, we're going to make it a much better computing fabric.
And we're committed, fully committed, to all three links, NVLink computing fabric for single computing domain, to InfiniBand computing fabric, to Ethernet networking computing fabric. And so, we're going to take all three of them forward at a very fast clip. And so, you're going to see new switches coming, new NICs coming, new capability, new software stacks that run on all three of them. New CPUs, new GPUs, new networking NICs, new switches, a mound of chips that are coming.
And all of it -- the beautiful thing is all of it runs CUDA. And all of it runs our entire software stack. So, if you invest today on our software stack, without doing anything at all, it's just going to get faster and faster and faster. And if you invest in our architecture today, without doing anything, it will go to more and more clouds and more and more data centers, and everything just runs.
And so, I think the pace of innovation that we're bringing will drive up the capability, on the one hand, and drive down the TCO on the other hand. And so, we should be able to scale out with the NVIDIA architecture for this new era of computing and start this new industrial revolution where we manufacture not just software anymore, but we manufacture artificial intelligence tokens, and we're going to do that at scale. Thank you.
Operator
That will conclude our question-and-answer session and our call for today. [Operator signoff]
Duration: 0 minutes
Call participants:
Simona Jankowski
--
Vice President, Investor Relations
Colette Kress
--
Executive Vice President, Chief Financial Officer
Jensen Huang
--
President and Chief Operating Officer
Stacy Rasgon
--
AllianceBernstein -- Analyst
Tim Arcuri
--
UBS -- Analyst
Vivek Arya
--
Bank of America Merrill Lynch -- Analyst
Joe Moore
--
Morgan Stanley -- Analyst
Toshiya Hari
--
Goldman Sachs -- Analyst
Matt Ramsay
--
TD Cowen -- Analyst
Mark Lipacis
--
Evercore ISI -- Analyst
Blayne Curtis
--
Jefferies -- Analyst
Srini Pajjuri
--
Raymond James -- Analyst
William Stein
--
Truist Securities -- Analyst
C.J. Muse
--
Cantor Fitzgerald -- Analyst
More NVDA analysis
All earnings call transcripts"
Nvidia Corporation (NVDA),Q2,2025,Nvidia (NVDA) Q2 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2024/08/28/nvidia-nvda-q2-2025-earnings-call-transcript/,"Nvidia
(
NVDA
+0.74%
)
Q2 2025 Earnings Call
Aug 28, 2024
,
5:00 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Operator
Good afternoon. My name is Abby, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's second-quarter earnings call. All lines have been placed on mute to prevent any background noise.
After the speakers' remarks, there will be a question-and-answer session. [Operator instructions] Thank you. And Mr. Stewart Stecker, you may begin your conference.
Stewart Stecker
--
Senior Director, Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the second quarter of fiscal 2025. With me today from NVIDIA are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I would like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the third quarter of fiscal 2025. The content of today's call is NVIDIA's property. It cannot be reproduced or transcribed without prior written consent. During this call, we may make forward-looking statements based on current expectation.
These are subject to a number of risks, significant risks, and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, August 28, 2024, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. Let me highlight an upcoming event for the financial community. We will be attending the Goldman Sachs Communacopia and Technology Conference on September 11 in San Francisco, where Jensen will participate in a keynote fireside chat.
Our earnings call to discuss the results of our third quarter of fiscal 2025 is scheduled for Wednesday, November 20, 2024. With that, let me turn the call over to Colette.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Thanks, Stewart. Q2 was another record quarter. Revenue of $30 billion was up 15% sequentially and up 122% year on year and well above our outlook of $28 billion. Starting with Data Center.
Data Center revenue of $26.3 billion was a record, up 16% sequentially and up 154% year on year, driven by strong demand for NVIDIA Hopper, GPU computing, and our networking platforms. Compute revenue grew more than 2.5x. Networking revenue grew more than 2x from the last year. Cloud service providers represented roughly 45% of our Data Center revenue, and more than 50% stemmed from the consumer Internet and enterprise companies.
Customers continue to accelerate their Hopper architecture purchases while gearing up to adopt Blackwell. Key workloads driving our Data Center growth include generative AI model training and inferencing; video, image, and text data pre and post processing with CUDA and AI workloads; synthetic data generation; AI-powered recommender systems; SQL and Vector database processing as well. Next-generation models will require 10 to 20 times more compute to train with significantly more data. The trend is expected to continue.
Over the trailing four quarters, we estimate that inference drove more than 40% of our Data Center revenue. CSPs, consumer Internet companies, and enterprises benefit from the incredible throughput and efficiency of NVIDIA's inference platform. Demand for NVIDIA is coming from frontier model makers, consumer Internet services, and tens of thousands of companies and start-ups building generative AI applications for consumers, advertising, education, enterprise and healthcare, and robotics. Developers desire NVIDIA's rich ecosystem and availability in every cloud.
CSPs appreciate the broad adoption of NVIDIA and are growing their NVIDIA capacity given the high demand. NVIDIA H200 platform began ramping in Q2, shipping to large CSPs, consumer Internet, and enterprise company. The NVIDIA H200 builds upon the strength of our Hopper architecture and offering over 40% more memory bandwidth compared to the H100. Our Data Center revenue in China grew sequentially in Q2 and a significant contributor to our Data Center revenue.
As a percentage of total Data Center revenue, it remains below levels seen prior to the imposition of export controls. We continue to expect the China market to be very competitive going forward. The latest round of MLPerf inference benchmarks highlighted NVIDIA's inference leadership with both NVIDIA Hopper and Blackwell platform combining to win gold medals on all tasks. At Computex, NVIDIA, with the top computer manufacturers, unveiled an array of Blackwell architecture-powered systems and NVIDIA networking for building AI factories and data centers.
With the NVIDIA MGX modular reference architecture, our OEMs and ODM partners are building more than 100 Blackwell-based systems designed quickly and cost-effectively. The NVIDIA Blackwell platform brings together multiple GPU, CPU, DPU, NVLink, and Link Switch and the networking chips, systems, and NVIDIA CUDA software to power the next generation of AI across the cases, industries, and countries. The NVIDIA GB200 NVL72 system with the fifth-generation NVLink enables all 72 GPUs to act as a single GPU and deliver up to 30x faster inference for LLM's workloads and unlocking the ability to run trillion-parameter models in real time. Hopper demand is strong, and Blackwell is widely sampling.
We executed a change to the Blackwell GPU mass to improve production yields. Blackwell production ramp is scheduled to begin in the fourth quarter and continue into fiscal year '26. In Q4, we expect to get several billion dollars in Blackwell revenue. Hopper shipments are expected to increase in the second half of fiscal 2025.
Hopper supply and availability have improved. Demand for Blackwell platforms is well above supply, and we expect this to continue into next year. Networking revenue increased 16% sequentially. Our Ethernet for AI revenue, which includes our Spectrum-X end-to-end Ethernet platform, doubled sequentially with hundreds of customers adopting our Ethernet offerings.
Spectrum-X has broad market support from OEM and ODM partners and is being adopted by CSPs, GPU cloud providers, and enterprises, including xAI to connect the largest GPU compute cluster in the world. Spectrum-X supercharges Ethernet for AI processing and delivers 1.6x the performance of traditional Ethernet. We plan to launch new Spectrum-X products every year to support demand for scaling compute clusters from tens of thousands of GPUs today to millions of DPUs in the near future. Spectrum-X is well on track to begin a multibillion-dollar product line within a year.
Our sovereign AI opportunities continue to expand as countries recognize AI expertise and infrastructure at national imperatives for their society and industries. Japan's National Institute of Advanced Industrial Science and Technology is building its AI Bridging Cloud Infrastructure 3.0 supercomputer with NVIDIA. We believe sovereign AI revenue will reach low double-digit billions this year. The enterprise AI wave has started.
Enterprises also drove sequential revenue growth in the quarter. We are working with most of the Fortune 100 companies on AI initiatives across industries and geographies. A range of applications are fueling our growth, including AI-powered chatbots, generative AI copilots, and agents to build new monetizable business applications and enhance employee productivity. Amdocs is using NVIDIA generative AI for their smart agent, transforming the customer experience and reducing customer service costs by 30%.
ServiceNow is using NVIDIA for its Now Assist offering, the fastest-growing new product in the company's history. SAP is using NVIDIA to build dual copilots. Cohesity is using NVIDIA to build their generative AI agent and lower generative AI development costs. Snowflake, serves over 3 billion queries a day for over 10,000 enterprise customers, is working with NVIDIA to build copilots.
And lastly, is using NVIDIA AI Omniverse to reduce end-to-end cycle times for their factories by 50%. Automotive was a key growth driver for the quarter as every automaker developing autonomous vehicle technology is using NVIDIA in their data centers. Automotive will drive multibillion dollars in revenue across on-prem and cloud consumption and will grow as next-generation AV models require significantly more compute. Health care is also on its way to being a multibillion-dollar business as AI revolutionizes medical imaging, surgical robots, patient care, electronic health record processing, and drug discovery.
During the quarter, we announced a new NVIDIA AI foundry service to supercharge generative AI for the world's enterprises with Meta's Llama 3.1 collection of models. This marks a watershed moment for enterprise AI. Companies for the first time can leverage the capabilities of an open-source frontier-level model to develop customized AI applications to encode their institutional knowledge into an AI flywheel to automate and accelerate their business. Accenture is the first to adopt the new service to build custom Llama 3.1 models for both its own use and to assist clients seeking to deploy generative AI applications.
NVIDIA NIMs accelerate and simplify model deployment. Companies across healthcare, energy, financial services, retail, transportation, and telecommunications are adopting NIMs, including Aramco, Lowes, and Uber. AT&T realized 70% cost savings and eight times latency reduction after moving into NIMs for generative AI, call transcription, and classification. Over 150 partners are embedding NIMs across every layer of the AI ecosystem.
We announced NIM Agent Blueprint, a catalog of customizable reference applications that include a full suite of software for building and deploying enterprise generative AI applications. With NIM Agent Blueprint, enterprises can refine their AI applications over time, creating a data-driven AI flywheel. The first NIM Agent Blueprints include workloads for customer service, computer-aided drug discovery, and enterprise retrieval augmented generation. Our system integrators, technology solution providers, and system builders are bringing NVIDIA NIM Agent Blueprints to enterprises.
NVIDIA NIM and NIM Agent Blueprints are available through the NVIDIA AI Enterprise software platform, which has great momentum. We expect our software, SaaS, and support revenue to approach a $2 billion annual run rate exiting this year, with NVIDIA AI Enterprise notably contributing to growth. Moving to gaming and AI PC. Gaming revenue of $2.88 billion increased 9% sequentially and 16% year on year.
We saw sequential growth in console, notebook, and desktop revenue, and demand is strong and growing and channel inventory remains healthy. Every PC with RTX is an AI PC. RTX PCs can deliver up to 1,300 AI tops and are now over 200 RTX AI laptops designed from leading PC manufacturers. With 600 AI-powered applications and games and an installed base of 100 million devices, RTX is set to revolutionize consumer experiences with generative AI.
NVIDIA ACE, a suite of generative AI technologies is available for RTX AI PCs. Megabreak is the first game to use NVIDIA ACE, including our small language model, Nemotron 4B optimized on device inference. The NVIDIA gaming ecosystem continues to grow. Recently added RTX and DLSS titles include Indiana Jones and The Great Circle, Awakening, and Dragon Age: The Vanguard.
The GeForce NOW library continues to expand with total catalog size of over 2,000 titles, the most content of any cloud gaming service. Moving to pro visualization. Revenue of $454 million was up 6% sequentially and 20% year on year. Demand is being driven by AI and graphic use cases, including model fine-tuning and Omniverse-related workloads.
Automotive and manufacturing were among the key industry verticals driving growth this quarter. Companies are racing to digitalize workflows to drive efficiency across their operations. The world's largest electronics manufacturer, Foxconn, is using NVIDIA Omniverse to power digital twins of the physical plants that produce NVIDIA Blackwell systems. And several large global enterprises, including Mercedes-Benz, signed multiyear contracts for NVIDIA Omniverse Cloud to build industrial digital twins of factories.
We announced new NVIDIA USD NIMs and connectors to open Omniverse to new industries and enable developers to incorporate generative AI copilots and agents into USD workloads, accelerating our ability to build highly accurate virtual worlds. WPP is implementing the USD NIM microservices in its generative AI-enabled content creation pipeline for customers such as The Coca-Cola Company. Moving to automotive and robotics. Revenue was $346 million, up 5% sequentially and up 37% year on year.
Year-on-year growth was driven by the new customer ramp in self-driving platforms and increased demand for AI cockpit solutions. At the consumer -- at the Computer Vision and Pattern Recognition Conference, NVIDIA won the Autonomous Brand Challenge in the end-to-end driving upscale category, outperforming more than 400 entries worldwide. Boston Dynamics, BYD Electronics, Figure, Intrinsyc, Siemens, and Teradyne Robotics are using the NVIDIA Isaac robotics platform for autonomous robot arms, humanoids, and mobile robots. Now, moving to the rest of the P&L.
GAAP gross margins were 75.1% and non-GAAP gross margins were 75.7%, down sequentially due to a higher mix of new products within Data Center and inventory provisions for low-yielding Blackwell material. Sequentially, GAAP and non-GAAP operating expenses were up 12%, primarily reflecting higher compensation-related costs. Cash flow from operations was $14.5 billion. In Q2, we utilized cash of $7.4 billion toward shareholder returns in the form of share repurchases and cash dividends, reflecting the increase in dividend per shareholder.
Our board of directors recently approved a $50 billion share repurchase authorization to add to our remaining $7.5 billion of authorization at the end of Q2. Let me turn the outlook for the third quarter. Total revenue is expected to be $32.5 billion, plus or minus 2%. Our third-quarter revenue outlook incorporates continued growth of our Hopper architecture and sampling of our Blackwell products.
We expect Blackwell production ramp in Q4. GAAP and non-GAAP gross margins are expected to be 74.4% and 75%, respectively, plus or minus 50 basis points. As our Data Center mix continues to shift to new products, we expect this trend to continue into the fourth quarter of fiscal 2025. For the full year, we expect gross margins to be in the mid-70% range.
GAAP and non-GAAP operating expenses are expected to be approximately $4.3 billion and $3.0 billion, respectively. Full-year operating expenses are expected to grow in the mid- to upper 40% range as we work on developing our next generation of products. GAAP and non-GAAP other income and expenses are expected to be about $350 million, including gains and losses from nonaffiliated investments and publicly held equity securities. GAAP and non-GAAP tax rates are expected to be 17%, plus or minus 1%, excluding any discrete items.
Further financial details are included in the CFO commentary and other information available on our IR website. We are now going to open the call for questions. Operator, would you please help us poll for questions?
Questions & Answers:
Operator
Thank you. [Operator instructions] We will pause for just a moment to compile the Q&A roster. And as a reminder, we ask that you please limit yourself to one question. And your first question comes from the line of Vivek Arya with Bank of America Securities.
Your line is open.
Vivek Arya
--
Analyst
Thanks for taking my question. Jensen, you mentioned in the prepared comments that there's a change in the Blackwell GPU mask. I'm curious, are there any other incremental changes in back-end packaging or anything else? And I think related, you suggested that you could ship several billion dollars of Blackwell in Q4 despite the change in the design. Is it because all these issues will be solved by then? Just help us size what is the overall impact of any changes in Blackwell timing, what that means to your kind of revenue profile and how are customers reacting to it.
Jensen Huang
--
President and Chief Executive Officer
Yeah. Thanks, Vivek. The change to the mask is complete. There were no functional changes necessary.
And so, we're sampling functional samples of Blackwell, Grace Blackwell, and a variety of system configurations as we speak. There are something like 100 different types of Blackwell-based systems that are built that were shown at Computex, and we're enabling our ecosystem to start sampling those. The functionality of Blackwell is as it is, and we expect to start production in Q4.
Operator
And your next question comes from the line of Toshiya Hari with Goldman Sachs. Your line is open.
Toshiya Hari
--
Analyst
Hi. Thank you so much for taking the question. Jensen, I had a relatively longer-term question. As you may know, there's a pretty heated debate in the market on your customers and customers' customers return on investment and what that means for the sustainability of capex going forward.
Internally at NVIDIA, like what are you guys watching? What's on your dashboard as you try to gauge customer return and how that impacts capex? And then a quick follow-up maybe for Colette. I think your sovereign AI number for the full year went up maybe a couple of billion. What's driving the improved outlook and how should we think about fiscal '26? Thank you.
Jensen Huang
--
President and Chief Executive Officer
Thanks, Toshiya. First of all, when I said ship production in Q4, I mean shipping out, I don't mean starting to ship, but I mean -- I don't mean starting production but shipping up. On the longer-term question, let's take a step back. And you've heard me say that we're going through two simultaneous platform transitions at the same time.
The first one is transitioning from accelerated computing to -- from general-purpose computing to accelerated computing. And the reason for that is because CPU scaling has been known to be slowing for some time and it has slowed to a crawl. And yet the amount of computing demand continues to grow quite significantly. You could maybe even estimate it to be doubling every single year.
And so, if we don't have a new approach, computing inflation would be driving up the cost for every company, and it would be driving up the energy consumption of data centers around the world. In fact, you're seeing that. And so, the answer is accelerated computing. We know that accelerated computing, of course, speeds up applications.
It also enables you to do computing at a much larger scale, for example, scientific simulations or database processing, but what that translates directly to is lower cost and lower energy consumed. And in fact, this week, there's a blog that came out that talked about a whole bunch of new libraries that we offer. And that's really the core of the first platform transition, going from general-purpose computing to accelerated computing. And it's not unusual to see someone save 90% of their computing cost.
And the reason for that is, of course, you just sped up an application 50x. You would expect the computing cost to decline quite significantly. The second was enabled by accelerated computing because we drove down the cost of training large language models or training deep learning so incredibly that it is now possible to have gigantic scale models, multitrillion-parameter models and train it on -- pretrain it on just about the world's knowledge corpus and let the model go figure out how to understand human language representation and how to codify knowledge into its neural networks and how to learn reasoning, and so which caused the generative AI revolution. Now, generative AI, taking a step back about why it is that we went so deeply into it is because it's not just a feature, it's not just the capability.
It's a fundamental new way of doing software. Instead of human-engineered algorithms, we now have data. We tell the AI, we tell the model, we tell the computer what are the expected answers. What are our previous observations? And then for it to figure out what the algorithm is, what's the function.
It learns a universal -- AI is a bit of a universal function approximator and it learns the function. And so, you could learn the function of almost anything. And anything that you have that's predictable, anything that has structure, anything that you have previous examples of. And so, now here we are with generative AI.
It's a fundamental new form of computer science. It's affecting how every layer of computing is done from CPU to GPU, from human-engineered algorithms to machine-learned algorithms, and the type of applications you could now develop and produce is fundamentally remarkable. And there are several things that are happening in generative AI. So, the first thing that's happening is the frontier models are growing in quite substantial scale.
And they're still seeing -- we're still all seeing the benefits of scaling. And whenever you double the size of a model, you also have to more than double the size of the data set to go train it. And so, the amount of flops necessary in order to create that model goes up quadratically. And so, it's not unexpected to see that the next-generation models could take 10, 20, 40 times more compute than last generation.
So, we have to continue to drive the generational performance up quite significantly so we can drive down the energy consumed and drive down the cost necessary to do it. And so, the first one is there are larger frontier models trained on more modalities. And surprisingly, there are more frontier model makers than last year. And so, you have more and more and more.
That's one of the dynamics going on in generative AI. The second is although it's below the tip of the iceberg, what we see are ChatGPT image generators. We see coding. We use generative AI for coding quite extensively here at NVIDIA now.
We, of course, have a lot of digital designers and things like that. But those are kind of the tip of the iceberg. What's below the iceberg are the largest systems, largest computing systems in the world today, which are -- and you've heard me talk about this in the past, which are recommender systems moving from CPUs. It's now moving from CPUs to generative AI.
So, recommender systems, ad generation, custom ad generation targeting ads at very large scale and quite hyper-targeting, search, and user-generated content, these are all very large-scale applications have now evolved to generative AI. Of course, the number of generative AI start-ups is generating tens of billions of dollars of cloud renting opportunities for our cloud partners. And sovereign AI, countries that are now realizing that their data is their natural and national resource and they have to use AI, build their own AI infrastructure so that they could have their own digital intelligence. Enterprise AI, as Colette mentioned earlier, is starting, and you might have seen our announcement that the world's leading IT companies are joining us to take the NVIDIA AI Enterprise platform to the world's enterprises.
The companies that we're talking to, so many of them are just so incredibly excited to drive more productivity out of the company. And then general robotics. The big transformation last year as we are able to now learn physical AI from watching video and human demonstration and synthetic data generation from reinforcement learning from systems like Omniverse, we are now able to work with just about every robotics companies now to start thinking about, start building general robotics. And so, you can see that there are just so many different directions that generative AI is going.
And so, we're actually seeing the momentum of generative AI accelerating.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
And Toshiya, to answer your question regarding sovereign AI and our goals in terms of growth, in terms of revenue, it certainly is a unique and growing opportunity, something that surfaced with generative AI and the desires of countries around the world to have their own generative AI that would be able to incorporate their own language, incorporate their own culture, incorporate their own data in that country. So, more and more excitement around these models and what they can be specific for those countries. So, yes, we are seeing some growth opportunity in front of us.
Operator
And your next question comes from the line of Joe Moore with Morgan Stanley. Your line is open.
Joe Moore
--
Analyst
Great. Thank you. Jensen, in the press release, you talked about Blackwell anticipation being incredible. But it seems like Hopper demand is also really strong.
I mean, you're guiding for a very strong quarter without Blackwell in October. So, how long do you see sort of coexisting strong demand for both? And can you talk about the transition to Blackwell? Do you see people intermixing clusters? Do you think most of the Blackwell activities, new clusters? Just some sense of what that transition looks like.
Jensen Huang
--
President and Chief Executive Officer
Yeah. Thanks, Joe. The demand for Hopper is really strong. And it's true, the demand for Blackwell is incredible.
There's a couple of reasons for that. The first reason is if you just look at the world's cloud service providers, the amount of GPU capacity they have available, it's basically none. And the reason for that is because they're either being deployed internally for accelerating their own workloads, data processing, for example. Data processing, we hardly ever talk about it because it's mundane.
It's not very cool because it doesn't generate a picture or generate words. But almost every single company in the world processes data in the background. And NVIDIA's GPUs are the only accelerators on the planet that process and accelerate data. SQL data, Panda's data, data science toolkits like Panda's, and the new one, Polar's.
These are the ones -- the most popular data processing platforms in the world. And aside from CPUs, which as I've mentioned before, really running out of steam, NVIDIA's accelerated computing is really the only way to get boosting performance out of that. And so, number one is the primary -- the No. 1 use case long before generative AI came along is that the migration of applications one after another to accelerated computing.
The second is, of course, the rentals. They're renting capacity to model makers. They're renting it to start-up companies. And a generative AI company spends the vast majority of their invested capital into infrastructure so that they could use an AI to help them create products.
And so, these companies need it now. They just simply can't afford -- you just raise money. They want you to put it to use now. You have processing that you have to do.
You can't do it next year, you got to do it today. And so, there's a fair -- that's one reason. The second reason for Hopper demand right now is because of the race to the next plateau. The first person to the next plateau gets to be -- get to introduce a revolutionary level of AI.
The second person who gets there is incrementally better or about the same. And so, the ability to systematically and consistently race to the next plateau and be the first one there is how you establish leadership. NVIDIA is constantly doing that, and we show that to the world and the GPUs we make and the AI factories that we make, the networking systems that we make, the SoCs we create. I mean, we want to set the pace.
We want to be consistently the world's best. And that's the reason why we drive ourselves so hard. Of course, we also want to see our dreams come true and all of the capabilities that we imagine in the future and the benefits that we can bring to society, we want to see all that come true. And so, these model makers are the same.
Of course, they want to be the world's best. They want to be the world's first. And although Blackwell will start shipping out in billions of dollars at the end of this year, the standing up of the capacity is still probably weeks and a month or so away. And so, between now and then is a lot of generative AI market dynamic.
And so, everybody is just really in a hurry. It's either operational reasons that they need it. They need accelerated computing. They don't want to build any more general-purpose computing infrastructure and even Hopper.
Of course, H200 is state-of-the-art. Hopper, if you have a choice between building CPU infrastructure right now for business or Hopper infrastructure for business right now, that decision is relatively clear. And so, I think people are just clamoring to transition the $1 trillion of established installed infrastructure to a modern infrastructure and Hopper's state-of-the-art.
Operator
And your next question comes from the line of Matt Ramsay with TD Cowen. Your line is open.
Matt Ramsay
--
Analyst
Thank you very much. Good afternoon, everybody. Jensen, I wanted to kind of circle back to an earlier question about the debate that investors are having about the ROI on all of this capex. And hopefully, this question and the distinction will make some sense.
But what I'm having discussions about is with like the percentage of folks that you see that are spending all of this money and looking to sort of push the frontier toward AGI convergence and, as you just said, a new plateau in capability, and they're going to spend regardless to get to that level of capability because it opens up so many doors for the industry and for their company versus customers that are really, really focused today on capex versus ROI. I don't know if that distinction makes sense. I'm just trying to get a sense of how you're seeing the priorities of people that are putting the dollars in the ground on this new technology and what their priorities are and their time frames are for that investment. Thanks.
Jensen Huang
--
President and Chief Executive Officer
Thanks, Matt. The people who are investing in NVIDIA infrastructure are getting returns on it right away. It's the best ROI infrastructure, computing infrastructure investment you can make today. And so, one way to think through it, probably the most -- the easiest way to think through it is just go back to first principles.
You have $1 trillion worth of general-purpose computing infrastructure. And the question is, do you want to build more of that or not? And for every $1 billion worth of Juniper CPU-based infrastructure that you stand up, you probably rent it for less than $1 billion. And so, because it's commoditized, there's already $1 trillion on the ground. What's the point of getting more? And so, the people who are clamoring to get this infrastructure, one, when they build out Hopper-based infrastructure and soon, Blackwell-based infrastructure, they start saving money.
That's a tremendous return on investment. And the reason why they start saving money is because data processing saves money, and data processing is probably just a giant part of it already. And so, recommender systems save money, so on and so forth, OK? And so, you start saving money. The second thing is everything you stand up are going to get rented because so many companies are being founded to create generative AI.
And so, your capacity gets rented right away and the return on investment of that is really good. And then the third reason is your own business. Do you want to either create the next frontier yourself or your own Internet services benefit from a next-generation ad system or a next-generation recommender system or a next-generation search system? So, for your own services, for your own stores, for your own user-generated content, social media platforms, for your own services, generative AI is also a fast ROI. And so, there's a lot of ways you could think through it.
But at the core, it's because it is the best computing infrastructure you could put in the ground today. The world of general-purpose computing is shifting to accelerated computing. The world of human-engineered software is moving to generative AI software. If you were to build infrastructure to modernize your cloud and your data centers, build it with accelerated computing NVIDIA.
That's the best way to do it.
Operator
And your next question comes from the line of Timothy Arcuri with UBS. Your line is open.
Timothy Arcuri
--
Analyst
Thanks a lot. I had a question on the shape of the revenue growth, both near and longer term. I know Colette, you did increase opex for the year. And if I look at the increase in your purchase commitments and your supply obligations, that's also quite bullish.
On the other hand, there's some school of thought that not that many customers really seem ready for liquid cooling, and I do recognize that some of these racks can be air-cooled. But Jensen, is that something to consider sort of on the shape of how Blackwell is going to ramp? And then I guess when you look beyond next year, which is obviously going to be a great year and you look into '26, do you worry about any other gating factors like, say, the power supply chain or at some point, models start to get smaller? I'm just wondering if you can speak to that. Thanks.
Jensen Huang
--
President and Chief Executive Officer
I'm going to work backwards. I really appreciate the question, Tim. So, remember, the world is moving from general-purpose computing to accelerated computing. And the world builds about $1 trillion worth of data centers.
$1 trillion worth of data centers in a few years will be all accelerated computing. In the past, no GPUs are in data centers, just CPUs. In the future, every single data center will have GPUs. And the reason for that is very clear: because we need to accelerate workloads so that we can continue to be sustainable, continue to drive down the cost of computing so that when we do more computing, we don't experience computing inflation.
Second, we need GPUs for a new computing model called generative AI that we could all acknowledge is going to be quite transformative to the future of computing. And so, I think working backwards, the way to think about that is the next $1 trillion of the world's infrastructure will clearly be different than the last $1 trillion, and it will be vastly accelerated. With respect to the shape of our ramp, we offer multiple configurations of Blackwell. Blackwell comes in either a Blackwell classic, if you will, that uses the HGX form factor that we pioneered with Volta.
And I think it was Volta. And so, we've been shipping the HGX form factor for some time. It is air-cooled. The Grace Blackwell is liquid-cooled.
However, the number of data centers that want to go to liquid-cooled is quite significant. And the reason for that is because we can, in a liquid-cooled data center, in any data center -- power-limited data center, whatever size data center you choose, you could install and deploy anywhere from three to five times the AI throughput compared to the past. And so, liquid cooling is cheaper. Liquid cooling, our TCO is better, and liquid cooling allows you to have the benefit of this capability we call NVLink, which allows us to expand it to 72 Grace Blackwell packages, which has essentially 144 GPUs.
And so, imagine 144 GPUs connected in NVLink. And that, we're increasingly showing you the benefits of that. And the next click is obviously very low latency, very high throughput large language model inference, and the large NVLink domain is going to be a game changer for that. And so, I think people are very comfortable deploying both.
And so, almost every CSP we're working with are deploying some of both. And so, I'm pretty confident that we'll ramp it up just fine. Your second question out of the third is that looking forward, yes, next year is going to be a great year. We expect to grow our Data Center business quite significantly next year.
Blackwell is going to be a complete game changer for the industry. And Blackwell is going to carry into the following year. And as I mentioned earlier, working backwards from first principles, remember that computing is going through two platform transitions at the same time. And that's just really, really important to keep your head on -- your mind focused on, which is general-purpose computing is shifting to accelerated computing, and human-engineered software is going to transition to generative AI or artificial intelligence-learned software.
OK.
Operator
And your next question comes from the line of Stacy Rasgon with Bernstein Research. Your line is open.
Stacy Rasgon
--
Analyst
Hi, guys. Thanks for taking my question. So, I have two short questions for Colette. The first several billion dollars of Blackwell revenue in Q4, is that additive? You said you expected Hopper demand to strengthen in the second half.
Does that mean Hopper strengthens Q3 to Q4 as well on top of Blackwell adding several billion dollars? And the second question on gross margins. If I have mid-70s for the year, let's say, where I want to draw that, if I have 75 for the year, I'd be something like 71 to 72 for Q4, somewhere in that range. Is that the kind of exit rate for gross margins that you're expecting? And how should we think about the drivers of gross margin evolution into next year as Blackwell ramps? And I mean, hopefully, I guess the yields and the inventory reserves and everything come up.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
So, Stacy, let's first take your question that you had about Hopper and Blackwell. So, we believe our Hopper will continue to grow into the second half. We have many new products for Hopper, our existing products for Hopper that we believe will start continuing to ramp in the next quarters, including our Q3 and those new products moving to Q4. So, let's say, Hopper there for versus H1 is a growth opportunity for that.
Additionally, we have the Blackwell on top of that, and the Blackwell starting ramping in Q4. So, I hope that helps you on those two pieces. Your second piece is in terms of our gross margin. We provided gross margin for our Q3.
We provided our gross margin on a non-GAAP at about 75. We'll work with all the different transitions that we're going through, but we do believe we can do that 75 in Q3. We provided that we're still on track for the full year also in the mid-70s or approximately the 75. So, we're going to see some slight difference possibly in Q4, again with our transitions and the different cost structures that we have on our new product introductions.
However, I'm not in the same number that you are there. We don't have exactly guidance, but I do believe you're lower than where we are.
Operator
And your next question comes from the line of Ben Reitzes with Melius. Your line is open.
Ben Reitzes
--
Melius Research -- Analyst
Yeah. Hey, thanks a lot for the question. I wanted to ask about the geographies. There was the 10-Q that came out, and the United States was down sequentially while several Asian geographies were up a lot sequentially.
Just wondering what the dynamics are there. And obviously, China did very well. You mentioned it in your remarks. What are the puts and takes? And then I just wanted to clarify from Stacy's question if that means the sequential overall revenue growth rates for the company accelerate in the fourth quarter, given all those favorable revenue dynamics.
Thanks.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Let me talk about a bit in terms of our disclosure in terms of the 10-Q, a required disclosure in a choice of geographies. Very challenging sometimes to create that right disclosure as we have to come up with one key piece. The pieces in terms of we have in terms of who we sell to and/or specifically who we invoice to, and so what you're seeing in terms of there is who we invoice. That's not necessarily where the product will eventually be and where it may even travel to the end customer.
These are just moving to our OEMs or ODMs and our system integrators for the most part across our product portfolio. So, what you're seeing there is sometimes just a swift shift in terms of who they are using to complete their full configuration before those things are going into the data center, going into notebooks and those pieces of it. And that shift happens from time to time. But yes, our China number there are invoicing to China.
Keep in mind that is incorporating both gaming, also Data Center, also automotive in those numbers that we have. Going back to your statement and regarding gross margin and also what we're seeing in terms of what we're looking at for Hopper and Blackwell in terms of revenue. Hopper will continue to grow in the second half. We'll continue to grow from what we are currently seeing.
Determining that exact mix in each Q3 and Q4, we don't have here. We are not here to guide yet in terms of Q4. But we do see right now the demand expectations. We do see the visibility that that will be a growth opportunity in Q4.
On top of that, we will have our Blackwell architecture.
Operator
And your next question comes from the line of C.J. Muse with Cantor Fitzgerald. Your line is open.
C.J. Muse
--
Analyst
Yeah. Good afternoon. Thank you for taking the question. You've embarked on a remarkable annual product cadence with challenges only likely becoming more and more, given rising complexity in a rather limit advanced package world.
So, curious, if you take a step back, how does this backdrop alter your thinking around potentially greater vertical integration, supply chain partnerships, and then taking through a consequential impact to your margin profile? Thank you.
Jensen Huang
--
President and Chief Executive Officer
Yeah. Thanks. Let's see. I think the first answer to your -- the answer to your first question is that the reason why our velocity is so high is simultaneously because the complexity of the model is growing, and we want to continue to drive its cost down.
It's growing so we want to continue to increase its scale. And we believe that by continuing to scale the AI models, that we'll reach a level of extraordinary usefulness and that it would open up, realize the next industrial revolution. We believe it. And so, we're going to drive ourselves really hard to continue to go up that scale.
We have the ability, fairly uniquely, to integrate, to design an AI factory because we have all the parts. It's not possible to come up with a new AI factory every year unless you have all the parts. And so, we have -- next year, we're going to ship a lot more CPUs than we've ever had in the history of our company, more GPUs, of course, but also NVLink switches, CX DPUs, ConnectX for East and West, BlueField DPUs for North and South, and data and storage processing to InfiniBand for supercomputing centers, to Ethernet, which is a brand-new product for us, which is well on its way to becoming a multibillion-dollar business to bring AI to Ethernet. And so, the fact that we could build -- we have access to all of this, we have one architectural stack, as you know, it allows us to introduce new capabilities to the market as we complete it.
Otherwise, what happens, you ship these parts, you go find customers to sell it to, and then you've got to build -- somebody's got to build up an AI factory, and the AI factory has got a mountain of software. And so, it's not about who integrates it. We love the fact that our supply chain is disintegrated in the sense that we could service Quanta, Foxconn, HP, Dell, Lenovo, Super Micro. We used to be able to serve ZTE.
They were recently purchased and so on and so forth. And so, the number of ecosystem partners that we have, Gigabyte, the number of ecosystem partners that we have that allows them to take our architecture, which all works, but integrated in a bespoke way into all of the world's cloud service providers, enterprise data centers, the scale and reach necessary from our ODMs and our integrators, integrated supply chain, is vast and gigantic because the world is huge. And so, that part, we don't want to do and we're not good at doing. And -- but we know how to design the AI infrastructure, provided the way that customers would like it and lets the ecosystem integrate it.
Well, yes. So, anyways, that's the reason why.
Operator
And your final question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.
Aaron Rakers
--
Analyst
Yes. Thanks for taking the question. I wanted to go back into the Blackwell product cycle. One of the questions that we tend to get asked is how you see the rack scale system mix dynamic as you think about leveraging NVLink, you think about GB NVL72 and how that go-to-market dynamic looks as far as the Blackwell product cycle.
I guess to put it simply, how do you see that mix of rack scale systems as we start to think about the Blackwell cycle playing out?
Jensen Huang
--
President and Chief Executive Officer
Yeah. Aaron, thanks. The Blackwell rack system, it's designed and architected as a rack but it's sold in disaggregated system components. We don't sell the whole rack.
And the reason for that is because everybody's rack's a little different surprisingly. Some of them are OCP standards, some of them are not. Some of them are enterprise. And the power limits for everybody could be a little different.
Choice of CDUs, the choice of power bus bars, the configuration and integration into people's data centers, all different. And so, the way we designed it, we architected the whole rack. The software is going to work perfectly across the whole rack. And then we provide the system components.
Like for example, the CPU and GPU compute board is then integrated into an MGX. It's a modular system architecture. MGX is completely ingenious. And we have MGX ODMs and integrators and OEMs all over the plant.
And so, just about any configuration you would like, where you would like that 3,000-pound rack to be delivered, it's got to be close to. It has to be integrated and assembled close to the data center because it's fairly heavy. And so everything from the supply chain from the moment that we ship the GPU, CPUs, the switches, the NICs, from that point forward, the integration is done quite close to the location of the CSPs and the locations of the data centers. And so, you can imagine how many data centers in the world there are and how many logistics hubs we've scaled out to with our ODM partners.
And so, I think because we show it as one rack and because it's always rendered that way and shown that way, we might have left the impression that we're doing the integration. Our customers hate that we do integration. The supply chain hates us doing integration. They want to do the integration.
That's their value-add. There's a final design-in, if you will. It's not quite as simple as shimmy into a data center but the design fit-in is really complicated. And so, the design fit-in, the installation, the bring-up, the repair and replace, that entire cycle is done all over the world.
And we have a sprawling network of ODM and OEM partners that does this incredibly well. So, integration is not the reason why we're doing racks. It's the anti-reason of doing it. The way we don't want to be an integrator, we want to be a technology provider.
Operator
And I will now turn the call back over to Jensen Huang for closing remarks.
Jensen Huang
--
President and Chief Executive Officer
Thank you. Let me make a couple more -- make a couple of comments that I made earlier again. The data center worldwide are in full steam to modernize the entire computing stack with accelerated computing and generative AI. Hopper demand remains strong and the anticipation for Blackwell is incredible.
Let me highlight the top five things, the top five things of our company. Accelerated computing has reached the tipping point. CPU scaling slows. Developers must accelerate everything possible.
Accelerated computing starts with CUDA-X libraries. New libraries open new markets for NVIDIA. We released many new libraries, including CUDA-X Accelerated Polars, Pandas, and Spark, the leading data science and data processing libraries, CUVI-S for vector databases. This is incredibly hot right now.
Ariel and for 5G wireless base station, a whole suite of a whole world of data centers that we can go into now. Parabricks for gene sequencing and AlphaFold2 for protein structure prediction is now CUDA accelerated. We are at the beginning of our journey to modernize $1 trillion worth of data centers from general-purpose computing to accelerated computing. That's number one.
Number two, Blackwall is a step-function leap over Hopper. Blackwell is an AI infrastructure platform, not just the GPU. Also happens to be the name of our GPU but it's an AI infrastructure platform. As we reveal more of Blackwell and sample systems to our partners and customers, the extent of Blackwell's lead becomes clear.
The Blackwell vision took nearly five years and seven one-of-a-kind chips to realize, the Gray CPU, the Blackwell dual GPU, and a colos package, ConnectX DPU for East-West traffic, BlueField DPU for North-South and storage traffic, NVLink switch for all-to-all GPU communications, and Quantum and Spectrum-X for both InfiniBand and Ethernet can support the massive traffic of AI. Blackwell AI factories are building-size computers. NVIDIA designed and optimized the Blackwell platform, full stack end to end, from chips, systems, networking, even structured cables, power and cooling, and mounds of software to make it fast for customers to build AI factories. These are very capital-intensive infrastructures.
Customers want to deploy it as soon as they get their hands on the equipment and deliver the best performance and TCO. Blackwell provides three to five times more AI throughput in a power-limited data center than Hopper. The third is NVLink. This is a very big deal with its all-to-all GPU switch is game-changing.
The Blackwell system lets us connect 144 GPUs in 72 GB200 packages into one NVLink domain, with an aggregate NVLink bandwidth of 259 terabytes per second in one rack. Just to put that in perspective, that's about 10x higher than Hopper. 259 terabytes per second kind of makes sense because you need to boost the training of multitrillion-parameter models on trillions of tokens. And so, that natural amount of data needs to be moved around from GPU to GPU.
For inference, NVLink is vital for low-latency, high-throughput large language model token generation. We now have three networking platforms, NVLink for GPU scale-up, Quantum InfiniBand for supercomputing and dedicated AI factories, and Spectrum-X for AI on Ethernet. NVIDIA's networking footprint is much bigger than before. Generative AI momentum is accelerating.
Generative AI frontier model makers are racing to scale to the next AI plateau to increase model safety and IQ. We're also scaling to understand more modalities from text, images, and video to 3D physics, chemistry, and biology. Chatbots, coding AIs, and image generators are growing fast but it's just the tip of the iceberg. Internet services are deploying generative AI for large-scale recommenders, ad targeting, and search systems.
AI start-ups are consuming tens of billions of dollars yearly of CSP's cloud capacity, and countries are recognizing the importance of AI and investing in sovereign AI infrastructure. And NVIDIA AI, NVIDIA Omniverse is opening up the next era of AI, general robotics. And now the enterprise AI wave has started, and we're poised to help companies transform their businesses. The NVIDIA AI Enterprise platform consists of Nemo, NIMs, NIM Agent Blueprints, and AI Foundry that our ecosystem partners, the world-leading IT companies used to help companies customize AI models and build bespoke AI applications.
Enterprises can then deploy on NVIDIA AI Enterprise run time, and at $4,500 per GPU per year, NVIDIA AI Enterprise is an exceptional value for deploying AI anywhere. And for NVIDIA software, TAM can be significant as the CUDA-compatible GPU installed base grows from millions to tens of millions. And as Colette mentioned, NVIDIA software will exit the year at a $2 billion run rate. Thank you all for joining us today.
Operator
[Operator signoff]
Duration: 0 minutes
Call participants:
Stewart Stecker
--
Senior Director, Investor Relations
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Vivek Arya
--
Analyst
Jensen Huang
--
President and Chief Executive Officer
Toshiya Hari
--
Analyst
Colette Kress
--
Chief Financial Officer, Executive Vice President
Joe Moore
--
Analyst
Matt Ramsay
--
Analyst
Timothy Arcuri
--
Analyst
Stacy Rasgon
--
Analyst
Ben Reitzes
--
Melius Research -- Analyst
C.J. Muse
--
Analyst
Aaron Rakers
--
Analyst
More NVDA analysis
All earnings call transcripts"
Nvidia Corporation (NVDA),Q3,2025,Nvidia (NVDA) Q3 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2024/11/20/nvidia-nvda-q3-2025-earnings-call-transcript/,"Nvidia
(
NVDA
+0.77%
)
Q3 2025 Earnings Call
Nov 20, 2024
,
5:00 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Operator
Good afternoon. My name is Jay, and I'll be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's third-quarter earnings call. All lines have been placed on mute to prevent any background noise.
After the speakers' remarks, there will be a question-and-answer session. [Operator instructions] Thank you. Stewart Stecker, you may begin your conference.
Stewart Stecker
--
Senior Director, Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2025. With me today from NVIDIA are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter of fiscal 2025. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, November 20, 2024, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Thank you, Stewart. Q3 was another record quarter. We continue to deliver incredible growth. Revenue of $35.1 billion was up 17% sequentially and up 94% year on year and well above our outlook of $32.5 billion.
All market platforms posted strong sequential and year-over-year growth, fueled by the adoption of NVIDIA accelerated computing and AI. Starting with data center. Another record was achieved in data center. Revenue of $30.8 billion, up 17% sequential and up 112% year on year.
NVIDIA Hopper demand is exceptional, and sequentially, NVIDIA H200 sales increased significantly to double-digit billions, the fastest prod ramp in our company's history. The H200 delivers up to 2x faster inference performance and up to 50% improved TCO. Cloud service providers were approximately half of our data center sales with revenue increasing more than 2x year on year. CSPs deployed NVIDIA H200 infrastructure and high-speed networking with installations scaling to tens of thousands of DPUs to grow their business and serve rapidly rising demand for AI training and inference workloads.
NVIDIA H200-powered cloud instances are now available from AWS, CoreWeave, and Microsoft Azure, with Google Cloud and OCI coming soon. Alongside significant growth from our large CSPs, NVIDIA GPU regional cloud revenue jumped year on year as North America, India, and Asia Pacific regions ramped NVIDIA Cloud instances and sovereign cloud build-outs. Consumer Internet revenue more than doubled year on year as companies scaled their NVIDIA Hopper infrastructure to support next-generation AI models training, multimodal, and agentic AI, deep learning recommender engines, and generative AI inference and content creation workloads. NVIDIA Ampere and Hopper infrastructures are fueling inference revenue growth for customers.
NVIDIA is the largest inference platform in the world. Our large installed base and rich software ecosystem encourage developers to optimize for NVIDIA and deliver continued performance and TCO improvements. Rapid advancements in NVIDIA software algorithms boosted Hopper inference throughput by an incredible 5x in one year and cut time to first token by 5x. Our upcoming release of NVIDIA NIM will boost Hopper inference performance by an additional 2.4x.
Continuous performance optimizations are a hallmark of NVIDIA and drive increasingly economic returns for the entire NVIDIA installed base. Blackwell is in full production after a successfully executed change. We shipped 13,000 GPU samples to customers in the third quarter, including one of the first Blackwell DGX engineering samples to OpenAI. Blackwell is a full-stack, full-infrastructure, AI data center scale system with customizable configurations needed to address a diverse and growing AI market from x86 to ARM, training to inferencing GPUs, InfiniBand to Ethernet switches, and NVLink.
And from liquid-cooled to air-cooled, every customer is racing to be the first to market. Blackwell is now in the hands of all of our major partners, and they are working to bring up their data centers. We are integrating Blackwell systems into the diverse data center configurations of our customers. Blackwell demand is staggering, and we are racing to scale supply to meet the incredible demand customers are placing on us.
Customers are gearing up to deploy Blackwell at scale. Oracle announced the world's first Zettascale AI cloud computing clusters that can scale to over 131,000 Blackwell GPUs to help enterprises train and deploy some of the most demanding next-generation AI models. Yesterday, Microsoft announced they will be the first CSP to offer, in private preview, Blackwell-based cloud instances powered by NVIDIA GB200 and Quantum InfiniBand. Last week, Blackwell made its debut on the most recent round of MLPerf training results, sweeping the per GPU benchmarks and delivering a 2.2x leap in performance over Hopper.
The results also demonstrate our relentless pursuit to drive down the cost of compute. The 64 Blackwell GPUs are required to run the GPT-3 benchmark compared to 256 H100s or a 4x reduction in cost. NVIDIA Blackwell architecture with NVLink Switch enables up to 30x faster inference performance and a new level of inference scaling, throughput, and response time that is excellent for running new reasoning inference applications like OpenAI's o1 model. With every new platform shift, a wave of start-ups is created.
Hundreds of AI-native companies are already delivering AI services with great success. Though Google, Meta, Microsoft, and OpenAI are the headliners, Anthropic, Perplexity, Mistral, Adobe Firefly, Runway, Midjourney, Light Tricks, Harvey, Podium, Purser, and the Bridge are seeing great success while thousands of AI-native start-ups are building new services. The next wave of AI are Enterprise AI and industrial AI. Enterprise AI is in full throttle.
NVIDIA AI Enterprise, which includes NVIDIA NeMo and NIMs micro services is an operating platform of agentic AI. Industry leaders are using NVIDIA AI to build Copilots and agents. Working with NVIDIA, Cadence, Cloudera, Cohesity, NetApp, Salesforce, SAP, and ServiceNow are racing to accelerate development of these applications with the potential for billions of agents to be deployed in the coming years. Consulting leaders like Accenture and Deloitte are taking NVIDIA AI to the world's enterprises.
Accenture launched a new business group with 30,000 professionals trained on NVIDIA AI technology to help facilitate this global build-out. Additionally, Accenture, with over 707,000 employees, is leveraging NVIDIA-powered agentic AI applications internally, including one case that cuts manual steps in marketing campaigns for 25% to 35%. Nearly 1,000 companies are using NVIDIA NIM, and the speed of its uptake is evident in NVIDIA AI Enterprise monetization. We expect NVIDIA AI Enterprise full-year revenue to increase over 2x from last year, and our pipeline continues to build.
Overall, our software, service, and support revenue is annualizing at $1.5 billion, and we expect to exit this year annualizing at over $2 billion. Industrial AI and robotics are accelerating. This is triggered by breakthroughs in physical AI, foundation models that understand the physical world, like NVIDIA NeMo for enterprise AI agents. We built NVIDIA Omniverse for developers to build, train, and operate industrial AI and robotics.
Some of the largest industrial manufacturers in the world are adopting NVIDIA Omniverse to accelerate their businesses, automate their workflows, and to achieve new levels of operating efficiency. Foxconn, the world's largest electronics manufacturer, is using digital twin and industrial AI built on NVIDIA Omniverse to speed the bring-up of its Blackwell factories and drive new levels of efficiency. In its Mexico facility alone, Foxconn expects to reduce -- a reduction of over 30% in annual hour usage. From a geographic perspective, our data center revenue in China grew sequentially due to shipments of export-compliant Hopper products to industries.
As a percentage of total data center revenue, it remained well below levels prior to the onset of export controls. We expect the market in China to remain very competitive going forward. We will continue to comply with export controls while serving our customers. Our AI initiatives continue to gather momentum as countries embrace NVIDIA accelerated computing for a new industrial revolution powered by AI.
India's leading CSPs include product communications and data services are building AI factories for tens of thousands of NVIDIA GPUs. By year-end, they will have boosted NVIDIA GPU deployments in the country by nearly 10x. Infosys, TFC, Wipro are adopting NVIDIA AI Enterprise and upskilling nearly 0.5 million developers and consultants to help clients build and run AI agents on our platform. In Japan, SoftBank is building the nation's most powerful AI supercomputer with NVIDIA DGX Blackwell and Quantum InfiniBand.
SoftBank is also partnering with NVIDIA to transform the telecommunications network into a distributed AI network with NVIDIA AI Aerial and ARN platform that can process both 5G RAN on AI on CUDA. We are launching the same in the U.S. with T-Mobile. Leaders across Japan, including Fujitsu, NEC, and NTT are adopting NVIDIA AI Enterprise, and major consulting companies, including EY Strategy and Consulting will help bring NVIDIA AI technology to Japan's industries.
Networking revenue increased 20% year on year. Areas of sequential revenue growth include InfiniBand and Ethernet switches, SmartNICs, and BlueField DPUs. Though networking revenue was sequentially down, networking demand is strong and growing, and we anticipate sequential growth in Q4. CSPs and supercomputing centers are using and adopting the NVIDIA InfiniBand platform to power new H200 clusters.
NVIDIA Spectrum-X Ethernet for AI revenue increased over 3x year on year. And our pipeline continues to build with multiple CSPs and consumer Internet companies planning large cluster deployments. Traditional Ethernet was not designed for AI. NVIDIA Spectrum-X uniquely leverages technology previously exclusive to InfiniBand to enable customers to achieve massive scale of their compute.
Utilizing Spectrum-X, xAI's Colossus 100,000-Hopper supercomputer experienced zero application latency degradation and maintained 95% of data throughput versus 60% for traditional Ethernet. Now, moving to Gaming and AI PCs. Gaming revenue of $3.3 billion increased 14% sequentially and 15% year on year. Q3 was a great quarter for Gaming with notebook, console, and desktop revenue all growing sequentially and year on year.
RTX end demand was fueled by strong back-to-school sales as consumers continue to choose GeForce RTX GPUs and devices to power gaming, creative, and AI applications. Channel inventory remains healthy, and we are gearing up for the holiday season. We began shipping new GeForce RTX AI PC with up to 321 AI TOPS from ASUS and MSI with Microsoft's Copilot+ capabilities anticipated in Q4. These machines harness the power of RTX ray tracing and AI technologies to supercharge gaming, photo, and video editing, image generation, and coding.
This past quarter, we celebrated the 25th anniversary of the GeForce 256, the world's first GPU. The transforming executing graphics to igniting the AI revolution. NVIDIA's GPUs have been the driving force behind some of the most consequential technologies of our time. Moving to ProViz.
Revenue of $486 million was up 7% sequentially and 17% year on year. NVIDIA RTX workstations continue to be the preferred choice to power professional graphics, design, and engineering-related workloads. Additionally, AI is emerging as a powerful demand driver, including autonomous vehicle simulation, generative AI model prototyping for productivity-related use cases, and generative AI content creation in media and entertainment. Moving to Automotive.
Revenue was a record $449 million, up 30% sequentially and up 72% year on year. Strong growth was driven by self-driving brands of NVIDIA Orin and robust end market demand for NAVs. Global Cars is rolling out its fully electric SUV built on NVIDIA Orin and DriveOS. OK, moving to the rest of the P&L.
GAAP gross margin was 74.6% and non-GAAP gross margin was 75%, down sequentially, primarily driven by a mix shift of the H100 systems to more complex and higher-cost systems within data center. Sequentially, GAAP operating expenses and non-GAAP operating expenses were up 9% due to higher compute, infrastructure, and engineering development costs for new product introductions. In Q3, we returned $11.2 billion to shareholders in the form of share repurchases and cash dividends. Well, let me turn to the outlook for the fourth quarter.
Total revenue is expected to be $37.5 billion, plus or minus 2%, which incorporates continued demand for Hopper architecture and the initial ramp of our Blackwell products. While demand greatly exceed supply, we are on track to exceed our previous Blackwell revenue estimate of several billion dollars as our visibility into supply continues to increase. On Gaming, although sell-through was strong in Q3, we expect fourth-quarter revenue to decline sequentially due to supply constraints. GAAP and non-GAAP gross margins are expected to be 73% and 73.5%, respectively, plus or minus 50 basis points.
Blackwell is a customizable AI infrastructure with seven different types of NVIDIA-built chips, multiple networking options, and for air and liquid-cooled data centers. Our current focus is on ramping to strong demand, increasing system availability, and providing the optimal mix of configurations to our customer. As Blackwell ramps, we expect gross margins to moderate to the low 70s. When fully ramp, we expect Blackwell margins to be in the mid-70s.
GAAP and non-GAAP operating expenses are expected to be approximately $4.8 billion and $3.4 billion, respectively. We are a data center-scale AI infrastructure company. Our investments include building data centers for development of our hardware and software stacks and to support new introductions. GAAP and non-GAAP other income and expenses are expected to be an income of approximately $400 million, excluding gains and losses from nonaffiliated investments.
GAAP and non-GAAP tax rates are expected to be 16.5%, plus or minus 1%, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website. In closing, let me highlight upcoming events for the financial community. We will be attending the UBS Global Technology and AI Conference on December 3 in Scottsdale.
Please join us at CES in Las Vegas, where Jensen will deliver a keynote on January 6, and we will host a Q&A session for financial analysts the next day on January 7. Our earnings call to discuss results for the fourth quarter of fiscal 2025 is scheduled for February 26, 2025. We will now open the call for questions. Operator, can you poll for questions, please?
Questions & Answers:
Operator
[Operator instructions] We'll pause for just a moment to compile the Q&A roster. As a reminder, please limit yourself to one question. Your first question comes from the line of C.J. Muse of Cantor Fitzgerald.
Your line is open.
C.J. Muse
--
Analyst
Yeah. Good afternoon. Thank you for taking the question. I guess just a question for you on the debate around whether scaling for large language models have stalled.
Obviously, we're very early here, but would love to hear your thoughts on this front. How are you helping your customers as they work through these issues? And then obviously, part of the context here is we're discussing clusters that have yet to benefit from Blackwell. So, is this driving even greater demand for Blackwell? Thank you.
Jensen Huang
--
President and Chief Executive Officer
Our foundation model pretraining scaling is intact, and it's continuing. As you know, this is an empirical law, not a fundamental physical law. But the evidence is that it continues to scale. What we're learning, however, is that it's not enough, that we've now discovered two other ways to scale.
One is post-training scaling. Of course, the first generation of post-training was reinforcement learning human feedback, but now we have reinforcement learning AI feedback, and all forms of synthetic data generated data that assists in post-training scaling. And one of the biggest events and one of the most exciting developments is Strawberry, ChatGPT o1, OpenAI's o1, which does inference time scaling, what is called test time scaling. The longer it thinks, the better and higher-quality answer it produces.
And it considers approaches like chain of thought and multi-path planning and all kinds of techniques necessary to reflect and so on and so forth. And it's -- intuitively, it's a little bit like us doing thinking in our head before we answer your question. And so, we now have three ways of scaling, and we're seeing all three ways of scaling. And as a result of that, the demand for our infrastructure is really great.
You see now that at the tail end of the last generation of foundation models were at about 100,000 Hoppers. The next generation starts at 100,000 Blackwells. And so, that kind of gives you a sense of where the industry is moving with respect to pretraining scaling, post-training scaling, and then now very importantly, inference time scaling. And so, the demand is really great for all of those reasons.
But remember, simultaneously, we're seeing inference really starting to scale up for our company. We are the largest inference platform in the world today because our installed base is so large. And everything that was trained on Amperes and Hoppers inference incredibly on Amperes and Hoppers. And as we move to Blackwells for training foundation models, it leads behind it a large installed base of extraordinary infrastructure for inference.
And so, we're seeing inference demand go up. We're seeing inference time scaling go up. We see the number of AI native companies continue to grow. And of course, we're starting to see enterprise adoption of agentic AI really is the latest rage.
And so, we're seeing a lot of demand coming from a lot of different places.
Operator
Your next question comes from the line of Toshiya Hari of Goldman Sachs. Your line is open.
Toshiya Hari
--
Analyst
Hi. Good afternoon. Thank you so much for taking the question. Jensen, you executed the mass change earlier this year.
There were some reports over the weekend about some heating issues. On the back of this, we've had investors ask about your ability to execute to the road map you presented at GTC this year with Ultra coming out next year and the transition to Rubin in '26. Can you sort of speak to that? And some investors are questioning that, so if you can sort of speak to your ability to execute on time, that would be super helpful. And then a quick part B.
On supply constraints, is it a multitude of componentry that's causing this, or is it specifically HBN? Is it supply constraints? Are the supply constraints getting better? Are they worsening? Any sort of color on that would be super helpful as well. Thank you.
Jensen Huang
--
President and Chief Executive Officer
Yeah. Thanks. So, let's see. Back to the first question.
Blackwell production is in full steam. In fact, as Colette mentioned earlier, we will deliver this quarter more Blackwells than we had previously estimated. And so, the supply chain team is doing an incredible job working with our supply partners to increase Blackwell, and we're going to continue to work hard to increase Blackwell through next year. It is the case that demand exceeds our supply.
And that's expected as we're in the beginnings of this generative AI revolution as we all know. And we're at the beginning of a new generation of foundation models that are able to do reasoning and able to do long thinking. And of course, one of the really exciting areas is physical AI, AI that now understands the structure of the physical world. And so, Blackwell demand is very strong.
Our execution is going well. And there's obviously a lot of engineering that we're doing across the world. You see now systems that are being stood up by Dell and CoreWeave. I think you saw systems from Oracle stood up.
You have systems from Microsoft, and they're about to preview their Grace Blackwell systems. You have systems that are at Google. And so, all of these CSPs are racing to be first. The engineering that we do with them is, as you know, rather complicated.
And the reason for that is because, although we build full stack and full infrastructure, we disaggregate all of this AI supercomputer, and we integrate it into all of the custom data centers and architectures around the world. That integration process, it's something we've done several generations now. We're very good at it but still there's still a lot of engineering that happens at this point. But as you see from all of the systems that are being stood up, Blackwell is in great shape.
And as we mentioned earlier, the supply and what we're planning to ship this quarter is greater than our previous estimates. With respect to the supply chain, there are seven different chips, seven custom chips that we built in order for us to deliver the Blackwell systems. The Blackwell systems go in air-cooled or liquid-cooled, NVLink 8 or NVLink 72 or NVLink 8, NVLink 36, NVLink 72. We have x86 or Grace.
And the integration of all of those systems into the world's data centers is nothing short of a miracle. And so, the component supply chain necessary to ramp at this scale, you have to go back and take a look at how much Blackwell we shipped last quarter, which was zero. And in terms of how much Blackwell total systems will ship this quarter, which is measured in billions, the ramp is incredible. And so almost every company in the world seems to be involved in our supply chain.
And we've got great partners, everybody from, of course, TSMC and Amphenol, the connector company, incredible company; Vertiv and SK Hynix and Micron; Spill Amcor; KYEC; and there's Foxconn and the factories that they've built; and Quanta and Wiwynn; and, gosh, Dell and HP, and Super Micro, Lenovo. And the number of companies is just really quite incredible. Quanta. And I'm sure I've missed partners that are involved in the ramping of Blackwell, which I really appreciate.
And so, anyways, I think we're in great shape with respect to the Blackwell ramp at this point. And then lastly, your question about our execution of our road map. We're on an annual road map and we're expecting to continue to execute on our annual road map. And by doing so, we increased the performance, of course, of our platform.
But it's also really important to realize that when we're able to increase performance and do so at factors at a time, we're reducing the cost of training. We're reducing the cost of inferencing. We're reducing the cost of AI so that it could be much more accessible. But the other factor that's very important to note is that when there's a data center of some fixed size and the data center always is of some fixed size.
It could be, of course, tens of megawatts in the past, and now it's -- most data centers are now 100 megawatts to several hundred megawatts, and we're planning on gigawatt data centers, it doesn't really matter how large the data centers are. The power is limited. And when you're in the power-limited data center, the best -- the highest performance per watt translates directly into the highest revenues for our partners. And so, on the one hand, our annual road map reduces costs.
But on the other hand, because our perf per watt is so good compared to anything out there, we generate for our customers the greatest possible revenues. And so, that annual rhythm is really important to us, and we have every intention of continuing to do that. And everything is on track as far as I know.
Operator
Your next question comes from the line of Timothy Arcuri of UBS. Your line is open.
Timothy Arcuri
--
Analyst
Thanks a lot. I'm wondering if you can talk about the trajectory of how Blackwell is going to ramp this year. I know Jensen, you did just talk about Blackwell being better than -- I think you had said several billions of dollars in January. It sounds like you're going to do more than that.
But I think in recent months also, you said that Blackwell crosses over Hopper in the April quarter. So, I guess I had two questions. First of all, is that still the right way to think about it, that Blackwell will cross over Hopper in April? And then Colette, you kind of talked about Blackwell bringing down gross margin to the low 70s as it ramps. So, I guess if April is the crossover, is that the worst of the pressure on gross margin? So, you're going to be kind of in the low 70s as soon as April.
I'm just wondering if you can sort of shape that for us. Thanks.
Jensen Huang
--
President and Chief Executive Officer
Colette, why don't you start?
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Sure. Let me first start with your question, Tim, thank you, regarding our gross margins. And we discussed that our gross margins, as we are ramping Blackwell in the very beginning, and the many different configurations, the many different chips that we are bringing to market, we are going to focus on making sure we have the best experience for our customers as they stand that up. We will start growing into our gross margins, but we do believe those will be in the low 70s in that first program.
So, you're correct, as you look at the quarters following after that, we will start increasing our gross margins, and we hope to get to the mid-70s quite quickly as part of that round.
Jensen Huang
--
President and Chief Executive Officer
Hopper demand will continue through next year, surely the first several quarters of the next year. And meanwhile, we will ship more Blackwells next quarter than this, and we'll ship more Blackwells the quarter after that than our first quarter. And so, that kind of puts it in perspective. We are really at the beginnings of two fundamental shifts in computing that is really quite significant.
The first is moving from coding that runs on CPUs to machine learning that creates neural networks that runs on GPUs. And that fundamental shift from coding to machine learning is widespread at this point. There are no companies who are not going to do machine learning. And so, machine learning is also what enables generative AI.
And so, on the one hand, the first thing that's happening is $1 trillion worth of computing systems and data centers around the world is now being modernized for machine learning. On the other hand, secondarily, I guess, is that on top of these systems are going to be -- we're going to be creating a new type of capability called AI. And when we say generative AI, we're essentially saying that these data centers are really AI factories. They're generating something.
Just like we generate electricity, we're now going to be generating AI. And if the number of customers is large, just as the number of consumers of electricity is large, these generators are going to be running 24/7. And today, many AI services are running 24/7, just like an AI factory. And so, we're going to see this new type of system come online, and I call it an AI factory because that's really as close to what it is.
It's unlike a data center of the past. And so, these two fundamental trends are really just beginning. And so, we expect this to happen, this growth, this modernization, and the creation of a new industry to go on for several years.
Operator
Your next question comes from the line of Vivek Arya of Bank of America Securities. Your line is open.
Vivek Arya
--
Analyst
Thanks for taking my question. Colette, just to clarify, do you think it's a fair assumption to think NVIDIA could recover to kind of mid-70s gross margin in the back half of calendar '25? Just wanted to clarify that. And then Jensen, my main question, historically, when we have seen hardware deployment cycles, they have inevitably included some digestion along the way. When do you think we get to that phase? Or is it just too premature to discuss that because you're just at the start of Blackwell? So, how many quarters of shipments do you think is required to kind of satisfy this first wave? Can you continue to grow this into calendar '26? Just how should we be prepared to see what we have seen historically, right, a period of digestion along the way of a long-term kind of secular hardware deployment?
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
OK. Vivek, thank you for the question. Let me clarify your question regarding gross margins. Could we reach the mid-70s in the second half of next year? And yes, I think it is a reasonable assumption or goal for us to do, but we'll just have to see how that mix of ramp goes.
But yes, it is definitely possible.
Jensen Huang
--
President and Chief Executive Officer
The way to think through that, Vivek, is I believe that there will be no digestion until we modernize $1 trillion with the data centers. Those -- if you just look at the world's data centers, the vast majority of it is built for a time when we wrote applications by hand and we ran them on CPUs. It's just not a sensible thing to do anymore. If you have -- if every company's capex -- if they're ready to build data center tomorrow, they ought to build it for a future of machine learning and generative AI because they have plenty of old data centers.
And so, what's going to happen over the course of the next X number of years, and let's assume that over the course of four years, the world's data centers could be modernized as we grow into IT, as you know, IT continues to grow about 20%, 30% a year, let's say. But let's say by 2030, the world's data centers for computing is, call it, a couple of trillion dollars. We have to grow into that. We have to modernize the data center from coding to machine learning.
That's number one. The second part of it is generative AI. And we're now producing a new type of capability the world's never known, a new market segment that the world's never had. If you look at OpenAI, it didn't replace anything.
It's something that's completely brand new. It's, in a lot of ways as when the iPhone came, was completely brand new. It wasn't really replacing anything. And so, we're going to see more and more companies like that.
And they're going to create and generate, out of their services, essentially intelligence. Some of it would be digital artist intelligence like Runway. Some of it would be basic intelligence like OpenAI. Some of it would be legal intelligence like Harvey, digital marketing intelligence like Rider's, so on and so forth.
And the number of these companies, these -- what are they called, AI-native companies, are just in hundreds. And almost every platform shift, there was -- there were Internet companies, as you recall. There were cloud-first companies. There were mobile-first companies.
Now, they're AI natives. And so, these companies are being created because people see that there's a platform shift, and there's a brand-new opportunity to do something completely new. And so, my sense is that we're going to continue to build out to modernize IT, modernize computing, number one; and then number two, create these AI factories that are going to be for a new industry for the production of artificial intelligence.
Operator
Your next question comes from the line of Stacy Rasgon of Bernstein Research. Your line is open.
Stacy Rasgon
--
Analyst
Hi, guys. Thanks for taking my questions. Colette, I had a clarification and a question for you. The clarification, just when you say low 70s gross margins, does 73.5% count as low 70s, or do you have something else in mind? And for my question, you're guiding total revenues, and so I mean, total data center revenues in the next quarter must be up several billion dollars.
But it sounds like Blackwell now should be up more than that. But you also said Hopper was still strong, so like is Hopper down sequentially next quarter? And if it is, like why? Is it because of the supply constraints? China has been pretty strong. Is China is kind of rolling off a bit into Q4? So any color you can give us on sort of the Blackwell ramp and the Blackwell versus Hopper behavior into Q4 would be really helpful. Thank you.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
So, first, starting on your first question there, Stacy, regarding our gross margin and define low. Low, of course, is below the mids, and let's say we might be at 71%, maybe about 72%, 72.5%. We're going to be in that range. We could be higher than that as well.
We're just going to have to see how it comes through. We do want to make sure that we are ramping and continuing that improvement, the improvement in terms of our yields, the improvement in terms of the product as we go through the rest of the year, so we'll get up to the mid-70s by that point. The second statement was a question regarding our Hopper and what is our Hopper doing. We have seen substantial growth for H200 not only in terms of orders but the quickness in terms of those that are standing that out.
It is an amazing product and it's the fastest growing and ramping that we've seen. We will continue to be selling Hopper in this quarter, in Q4 for sure. That is across the board in terms of all of our different configurations, and our configurations include what we may do in terms of China. But keep that in mind that folks are also, at the same time, looking to build out their Blackwell.
So, we've got a little bit of both happening in Q4. But yes. Is it possible for Hopper to grow between Q3 and Q4? It's possible, but we'll just have to see.
Operator
Your next question comes from the line of Joseph Moore of Morgan Stanley. Your line is open.
Joseph Moore
--
Analyst
Great. Thank you. I wonder if you could talk a little bit about what you're seeing in the inference market. You've talked about Strawberry and some of the ramifications of longer scaling influence projects.
But you've also talked about the possibility that as some of these Hopper clusters age, that you could use some of the Hopper chips for inference. So, I guess do you expect inference to outgrow training in the next kind of 12 months time frame? And just generally, your thoughts there.
Jensen Huang
--
President and Chief Executive Officer
Our hopes and dreams is that someday, the world does a ton of inference. And that's when AI has really exceeded is when every single company is doing inference inside their companies for the marketing department and forecasting department and supply chain group and their legal department and engineering, of course, and coding of course. And so, we hope that every company is doing inference 24/7 and that there will be a whole bunch of AI native start-ups, thousands of AI native start-ups that are generating tokens and generating AI. And every aspect of your computer experience from using Outlook to PowerPointing or when you're sitting there with Excel, you're constantly generating tokens.
And every time you read a PDF, open a PDF, it generated a whole bunch of tokens. One of my favorite applications is NotebookLM, this Google application that came out. I used the living daylights out of it just because it's fun. And I put every PDF, every archived paper into it just to listen to it as well as scanning through it.
And so, I think that's the goal is to train these models so that people use it. And there's now a whole new era of AI, if you will, a whole new genre of AI called physical AI. Just those large language models understand the human language and how the thinking process, if you will. Physical AI understands the physical world.
And it understands the meaning of the structure and understands what's sensible and what's not and what could happen and what won't. And not only does it understand but it can predict, roll out a short future. That capability is incredibly valuable for industrial AI and robotics. And so, that's fired up so many AI-native companies and robotics companies and physical AI companies that you're probably hearing about.
And it's really the reason why we built Omniverse. Omniverse is -- so that we can enable these AIs to be created and learn in Omniverse and learn from synthetic data generation and reinforcement, learning physics feedback. Instead of just a human feedback, it's now physics feedback. To have these capabilities, Omniverse was created so that we can enable physical AI.
And so, that -- the goal is to generate tokens. The goal is to inference, and we're starting to see that growth happening. So, I'm super excited about that. Now, let me just say one more thing.
Inference is super hard. And the reason why inference is super hard is because you need the accuracy to be high on the one hand. You need the throughput to be high so that the cost could be as low as possible, but you also need the latency to be low. And computers that are high-throughput as well as low latency is incredibly hard to build.
And these applications have long context lengths because they want to understand. They want to be able to inference within understanding the context of what they're being asked to do. And so, the context length is growing larger and larger. On the other hand, the models are getting larger.
They're multimodality. Just the number of dimensions that inference is innovating is incredible. And this innovation rate is what makes NVIDIA's architecture so great because we -- our ecosystem is fantastic. Everybody knows that if they innovate on top of CUDA and top of NVIDIA's architecture, they can innovate more quickly and they know that everything should work.
And if something were to happen, it's probably likely their code and not ours. And so, that ability to innovate in every single direction at the same time, having a large installed base so that whatever you create could land on an NVIDIA computer and be deployed broadly all around the world in every single data center all the way out to the edge into robotic systems, that capability is really quite phenomenal.
Operator
Your next question comes from the line of Aaron Rakers of Wells Fargo. Your line is open.
Aaron Rakers
--
Analyst
Yeah. Thanks for taking the question. I wanted to ask you as we kind of focus on the Blackwell cycle and think about the data center business. When I look at the results this last quarter, Colette, you mentioned that obviously, the networking business was down about 15% sequentially.
But then your comments were that you were seeing very strong demand. You mentioned also that you had multiple cloud CFP design wins for these large-scale clusters. So, I'm curious if you could unpack what's going on in the Networking business and where maybe you've seen some constraints and just your confidence in the pace of Spectrum-X progressing to that multiple billions of dollars that you previously had talked about. Thank you.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Let's first start with the networking. The growth year over year is tremendous. And our focus since the beginning of our acquisition of Mellanox has really been about building together the work that we do in terms of in the data center. The networking is such a critical part of that.
Our ability to sell our networking with many of our systems that we are doing in data center is continuing to grow and do quite well. So, this quarter is just a slight dip down and we're going to be right back up in terms of growing. We're getting ready for Blackwell and more and more systems that will be using not only our existing networking but also the networking that is going to be incorporated in a lot of these large systems we are providing them to.
Operator
Your next question comes from the line of Atif Malik of Citi. Your line is open.
Atif Malik
--
Analyst
Thank you for taking my question. I have two quick ones for Colette. Colette, on the last earnings call, you mentioned that sovereign demand is in low double-digit billions. Can you provide an update on that? And then can you explain the supply constrained situation in gaming? Is that because you're shifting your supply toward data center?
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
So, first, starting in terms of sovereign AI, such an important part of growth, something that is really surfaced with the onset of generative AI and building models in the individual countries around the world. And we see a lot of them, and we talked about a lot of them on the call today and the work that they are doing. So, our sovereign AI and our pipeline going forward is still absolutely intact as those are working to build these foundational models in their own language, in their own culture, and working in terms of the enterprises within those countries. And I think you'll continue to see this be growth opportunities that you may see with our regional clouds that are being stood up and/or those that are focusing in terms of AI factories for many parts of the sovereign AI.
This is areas where this is growing not only in terms of in Europe, but you're also seeing this in terms of growth in terms of in the Asia Pac as well. Let me flip to your second question that you asked regarding Gaming. So, our Gaming right now from a supply, we're busy trying to make sure that we can ramp all of our different products. And in this case, our gaming supply, given what we saw selling through was moving quite fast.
Now, the challenge that we have is how fast could we get that supply getting ready into the market for this quarter. Not to worry, I think we'll be back on track with more supply as we turn the corner into the new calendar year. We're just going to be tight for this quarter.
Operator
Your next question comes from the line of Ben Reitzes of Melius Research. Your line is open.
Ben Reitzes
--
Melius Research -- Analyst
Yeah. Hi. Thanks a lot for the question. I wanted to ask Colette and Jensen with regard to sequential growth.
So, very strong sequential growth this quarter, and you're guiding to about 7%. Do your comments on Blackwell imply that we reaccelerate from there as you get more supply just in the first half, there would be some catch-up. So, I was wondering how prescriptive you could be there. And then, Jensen, just overall with the change in administration that's going to take place here in the U.S.
and the China situation, have you gotten any sense or any conversations about tariffs or anything with regard to your China business? Any sense of what may or may not go on? It's probably too early, but wondering if you had any thoughts there. Thanks so much.
Jensen Huang
--
President and Chief Executive Officer
We guide one quarter at a time.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
We are working right now on the quarter that we're in and building what we need to ship in terms of Blackwell. We have every supplier on the planet working seamlessly with us to that. And once we get to next quarter, we'll help you understand in terms of that ramp that we'll see to the next quarter going after that.
Jensen Huang
--
President and Chief Executive Officer
Whatever the new administration decides, we'll, of course, support the administration. And that's our -- the highest mandate. And then after that, do the best we can and just as we always do. And so, we have to simultaneously and we will comply with any regulation that comes along fully and support our customers to the best of our abilities and to compete in the marketplace.
We'll do all of these three things simultaneously.
Operator
Your final question comes from the line of Pierre Ferragu of New Street Research. Your line is open.
Pierre Ferragu
--
Analyst
Hey, thanks for taking my question. Jensen, you mentioned in your comments, you have the pretraining, the actual language models and you have reinforcement learning that becomes more and more important in training and inference as well and then you have inference itself. And I was wondering if you have a sense like a high-level typical sense of out of an overall AI ecosystem, like maybe one of your clients or one of the large models that are out there today, how much of the compute goes into each of these buckets? How much for the pretraining? How much for the reinforcement? And how much into inference today? Do you have any sense for how it's splitting and where the growth is the most important as well?
Jensen Huang
--
President and Chief Executive Officer
Well, today, it's vastly in pretraining a foundation model because, as you know, post-training, the new technologies are just coming online. And whatever you could do in pretraining and post-training, you would try to do so that the inference cost could be as low as possible for everyone. However, there are only so many things that you could do a priority. And so, you'll always have to do on-the-spot thinking and in-context thinking and reflection.
And so, I think that the fact that all three are scaling is actually very sensible based on where we are. And in the area foundation model, now we have multimodality foundation models, and the amount of petabytes video that these foundation models are going to be trained on, it's incredible. And so, my expectation is that for the foreseeable future, we're going to be scaling pretraining, post-training, as well as inference time scaling and which is the reason why I think we're going to need more and more compute. And we're going to have to drive as hard as we can to keep increasing the performance by X factors out of time so that we can continue to drive down the cost and continue to increase the revenues and get the AI revolution going.
Operator
Thank you. I'd like to turn the call back over to Jensen Huang for closing remarks.
Jensen Huang
--
President and Chief Executive Officer
Thank you. The tremendous growth in our business is being fueled by two fundamental trends that are driving global adoption of NVIDIA computing. First, the computing stack is undergoing a reinvention, a platform shift from coding to machine learning, from executing code on CPUs to processing neural networks on GPUs. The $1 trillion installed base of traditional data center infrastructure is being rebuilt for Software 2.0, which applies machine learning to produce AI.
Second, the age of AI is in full steam. Generative AI is not just a new software capability but a new industry with AI factories manufacturing digital intelligence, a new industrial revolution that can create a multi-trillion-dollar AI industry. Demand for Hopper and anticipation for Blackwell, which is now in full production, are incredible for several reasons. There are more foundation model makers now than there were a year ago.
The computing scale of pretraining and post-training continues to grow exponentially. There are more AI-native start-ups than ever, and the number of successful inference services is rising. And with the introduction of ChatGPT o1, OpenAI o1, a new scaling law called test time scaling has emerged. All of these consume a great deal of computing.
AI is transforming every industry, company, and country. Enterprises are adopting agentic AI to revolutionize workflows. Over time, AI coworkers will assist employees in performing their jobs faster and better. Investments in industrial robotics are surging due to breakthroughs in physical AI, driving new training infrastructure demand as researchers train world foundation models on petabytes of video and Omniverse synthetically generated data.
The age of robotics is coming. Countries across the world recognize the fundamental AI trends we are seeing and have awakened to the importance of developing their national AI infrastructure. The age of AI is upon us, and it's large and diverse. NVIDIA's expertise, scale, and ability to deliver full stack and full infrastructure lets us serve the entire multitrillion-dollar AI and robotics opportunities ahead from every hyperscale cloud, enterprise private cloud to sovereign regional AI clouds, on-prem to industrial edge and robotics.
Thanks for joining us today, and catch up next time.
Operator
[Operator signoff]
Duration: 0 minutes
Call participants:
Stewart Stecker
--
Senior Director, Investor Relations
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
C.J. Muse
--
Analyst
Jensen Huang
--
President and Chief Executive Officer
Toshiya Hari
--
Analyst
Timothy Arcuri
--
Analyst
Colette Kress
--
Chief Financial Officer, Executive Vice President
Vivek Arya
--
Analyst
Stacy Rasgon
--
Analyst
Joseph Moore
--
Analyst
Aaron Rakers
--
Analyst
Atif Malik
--
Analyst
Ben Reitzes
--
Melius Research -- Analyst
Pierre Ferragu
--
Analyst
More NVDA analysis
All earnings call transcripts"
Nvidia Corporation (NVDA),Q4,2025,Nvidia (NVDA) Q4 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/02/26/nvidia-nvda-q4-2025-earnings-call-transcript/,"Nvidia
(
NVDA
+0.77%
)
Q4 2025 Earnings Call
Feb 26, 2025
,
5:00 p.m. ET
Contents:
Prepared Remarks
Questions and Answers
Call Participants
Prepared Remarks:
Operator
Good afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's fourth-quarter earnings call. All lines have been placed on mute to prevent any background noise.
After the speakers' remarks, there will be a question-and-answer session. [Operator instructions] Thank you. Stewart Stecker, you may begin your conference.
Stewart Stecker
--
Senior Director, Investor Relations
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the fourth quarter of fiscal 2025. With me today from NVIDIA are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website.
The webcast will be available for replay until the conference call to discuss our financial results for the first quarter of fiscal 2026. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without prior written consent. During this call, we may make forward-looking statements based on current expectations.
These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 26, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. Confine a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Thanks, Stewart. Q4 was another record quarter. Revenue of $39.3 billion was up 12% sequentially and up 78% year on year and above our outlook of $37.5 billion. For fiscal 2025 revenue was $130.5 billion, up 114% from the prior year.
Let's start with Data Center. Data center revenue for fiscal 2025 was $115.2 billion, more than doubling from the prior year. In the fourth quarter, Data Center revenue of $35.6 billion was a record, up 16% sequentially and 93% year on year as the Blackwell ramp commenced and Hopper 200 continued sequential growth. In Q4, Blackwell sales exceeded our expectations.
We delivered $11 billion of Blackwell revenue to meet strong demand. This is the fastest product ramp in our company's history, unprecedented in its speed and scale. Blackwell production is in full-year across multiple configurations, and we are increasing supply quickly expanding customer adoption. Our Q4 Data Center compute revenue jumped 18% sequentially and over 2x year on year.
Customers are racing to scale infrastructure to train the next generation of cutting-edge models and unlock the next level of AI capabilities. With Blackwell, it will be common for these clusters to start with 100,000 GPUs or more. Shipments have already started for multiple infrastructures of this size. Post-training and model customization are fueling demand for NVIDIA infrastructure and software as developers and enterprises leverage techniques such as fine-tuning reinforcement learning and distillation to tailor models for domain-specific use cases.
Hugging Face alone hosts over 90,000 derivatives freighted from the Llama foundation model. The scale of post-training and model customization is massive and can collectively demand orders of magnitude, more compute than pretraining. Our inference demand is accelerating, driven by test time scaling and new reasoning models like OpenAI's o3, DeepSeek-R1, and Grok 3. Long-thinking reasoning AI can require 100x more compute per task compared to one-shot inferences.
Blackwell was architected for reasoning AI inference. Blackwell supercharges reasoning AI models with up to 25x higher token throughput and 20x lower cost versus Hopper 100. It is revolutionary transformer engine is built for LLM and mixture of experts inference. And its NVLink Domain delivers 14x the throughput of PCIe Gen 5, ensuring the response time, throughput, and cost efficiency needed to tackle the growing complexity of infants of scale.
Companies across industries are tapping into NVIDIA's whole STAG inference platform to boost performance and slash costs. Now, tripled inference throughput and cut costs by 66%, using NVIDIA TensorRT for its screenshot feature. Perplexity sees 435 million monthly queries and reduced its inference costs 3x with NVIDIA Triton Inference Server and TensorRT-LLM. Microsoft Bing achieved a 5x speed up at major TCO savings for visual search across billions of images with NVIDIA, TensorRT, and acceleration libraries.
Blackwell has great demand for inference. Many of the early GB200 deployments are earmarked for inference, a first for a new architecture. Blackwell addresses the entire AI market from pretraining, post-training to inference across cloud, to on-premise, to enterprise. CUDA's programmable architecture accelerates every AI model and over 4,400 applications, ensuring large infrastructure investments against obsolescence in rapidly evolving markets.
Our performance and pace of innovation is unmatched. We're driven to a 200x reduction in inference costs in just the last two years. We delivered the lowest TCO and the highest ROI. And full stack optimizations for NVIDIA and our large ecosystem, including 5.9 million developers continuously improve our customers' economics.
In Q4, large CSPs represented about half of our data center revenue. and these sales increased nearly 2x year on year. Large CSPs were some of the first to stand up Blackwell with Azure, GCP, AWS, and OCI bringing GB200 systems to cloud regions around the world to meet certain surging customer demand for AI. Regional cloud hosting NVIDIA GPUs increased as a percentage of data center revenue, reflecting continued AI factory build-outs globally and rapidly rising demand for AI reasoning models and agents.
We've launched a 100,000 GB200 cluster-based incidents with NVLink Switch and Quantum 2 InfiniBand. Consumer Internet revenue grew 3x year on year, driven by an expanding set of generative AI and deep learning use cases. These include recommender systems, vision, language understanding, synthetic data generation search, and agentic AI. For example, xAI is adopting the GB200 to train and inference its next generation of Grok AI models.
Meta's cutting-edge Andromeda advertising engine runs on NVIDIA's Grace Hopper Superchip serving vast quantities of ads across Instagram, Facebook applications. Andromeda harnesses Grace Hopper's fast interconnect and large memory to boost inference throughput by 3x, enhance ad personalization, and deliver meaningful jumps in monetization and ROI. Enterprise revenue increased nearly 2x year on accelerating demand for model fine-tuning, RAG, and agentic AI workflows, and GPU-accelerated data processing. We introduced NVIDIA Llama Nemotron model family NIMs to help developers create and deploy AI agents across a range of applications including customer support, fraud detection, and product supply chain and inventory management.
Leading AI agent platform providers, including SAP and ServiceNow, are among the first to use new models. Health care leaders IQVIA, Illumina, Mayo Clinic, and Arc Institute are using NVIDIA AI to speed drug discovery enhanced genomic research and Pioneer advanced healthcare services with generative and agentic AI. As AI expands beyond the digital world, NVIDIA infrastructure and software platforms are increasingly being adopted to power robotics and physical AI development. One of the early and largest robotics applications and autonomous vehicles where virtually, every AV company is developing on NVIDIA in the data center, the car, or both.
NVIDIA's automotive vertical revenue is expected to grow to approximately $5 billion this fiscal year. At CES, Hyundai Motor Group announced it is adopting NVIDIA technologies to accelerate AV and robotics development and smart factory initiatives. Vision transformers, self-supervised learning, multimodal sensor fusion, and high-fidelity simulation are driving breakthroughs in AV development and will require 10x more compute. At CES, we announced the NVIDIA COSMO World Foundation model platform.
Just as language, foundation models have revolutionized Language AI, Cosmos is a physical AI to revolutionize robotics. The robotics and automotive companies, including ridesharing giant Uber, are among the first to adopt the platform. From a geographic perspective, sequential growth in our Data Center revenue was strongest in the U.S., driven by the initial ramp up Blackwell. Countries across the globe are building their AI ecosystem as demand for compute infrastructure is surging.
France's EUR 100 billion AI investment and the EU's EUR 200 billion invest AI initiatives offer a glimpse into the build-out to set redefined global AI infrastructure in the coming years. Now, as a percentage of total Data Center revenue, data center sales in China remained well below levels seen on the onset of export controls. Absent any change in regulations, we believe that China shipments will remain roughly at the current percentage. The market in China for data center solutions remains very competitive.
We will continue to comply with export controls while serving our customers. Networking revenue declined 3% sequentially. Our networking attached to GPU compute systems is robust at over 75%. We are transitioning from small NVLink 8 with InfiniBand, to large NVLink 72 with Spectrum-X.
Spectrum-X and NVLink Switch revenue increased and represents a major new growth vector. We expect networking to return to growth in Q1. AI requires a new class of networking. NVIDIA offers NVLink Switch systems for scale-up compute.
For scale-out, we offer quantum incentive for HPC supercomputers and Spectrum X for Ethernet environments. Spectrum-X enhances the Ethernet for AI computing and has been a huge success. Microsoft Azure, OCI, CoreWeave, and others are building large AI factories with Spectrum-X. The first Stargate data centers will use Spectrum-X.
Yesterday, Cisco announced integrating Spectrum-X into their networking portfolio to help enterprises build AI infrastructure. With its large enterprise footprint and global reach, Cisco will bring NVIDIA Ethernet to every industry. Now, moving to gaming and ARPCs. Gaming revenue of $2.5 billion decreased 22% sequentially and 11% year on year.
Full-year revenue of $11.4 billion increased 9% year on year, and demand remains strong throughout the holiday. However, Q4 shipments were impacted by supply constraints. We expect strong sequential growth in Q1 as supply increases. The new GeForce RTX 50 Series desktop and laptop GPUs are here.
Build for gamers, creators, and developers they fuse AI and graphics redefining visual computing, powered by the Blackwell architecture, fifth-generation Tensor cores, and fourth-generation RT cores and featuring UQ's400AI tops. These GPUs deliver a 2x performance leap and new AI-driven rendering including neuro shaders, digital human technologies, geometry, and lighting. The new DLSS 4 boost frame rates up to 8x with AI-driven frame generation, turning one rendered frame into three. It also features the industry's first real-time application of transformer models packing 2x more parameters and 4x to compute for unprecedented visual fidelity.
We also announced a wave of GeForce Blackwell laptop GPUs with new NVIDIA Max-Q technology that extends battery life by up to an incredible 40%. These laptops will be available starting in March from the world's top manufacturers. Moving to our professional visualization business. Revenue of $511 million was up 5% sequentially and 10% year on year.
Full-year revenue of $1.9 billion increased 21% year on year. Key industry verticals driving demand include automotive and healthcare. NVIDIA Technologies and generative AI are reshaping design, engineering, and simulation workloads. Increasingly, these technologies are being leveraged in leading software platforms from ANSYS, Cadence, and Siemens fueling demand for NVIDIA RTX workstations.
Now, moving to Automotive. Revenue was a record $570 million, up 27% sequentially and up 103% year on year. Full-year revenue of $1.7 billion increased 5% year on year. Strong growth was driven by the continued ramp in autonomous vehicles, including cars and robotaxis.
At CES, we announced Toyota, the world's largest automaker will build its next-generation vehicles on NVIDIA Orin running the safety-certified NVIDIA DriveOS. We announced Aurora and Continental will deploy driverless trucks at scale powered by NVIDIA Drive Thor. Finally, our end-to-end autonomous vehicle platform NVIDIA Drive Hyperion has passed industry safety assessments like TUV SUD and TUV Rheinland, two of the industry's foremost authorities for automotive-grade safety and cybersecurity. NVIDIA is the first AV platform that received a comprehensive set of third-party assessments.
OK. Moving to the rest of the P&L. GAAP gross margin was 73% and non-GAAP gross margin was 73.5% and down sequentially as expected with our first deliveries of the Blackwell architecture. As discussed last quarter, Blackwell is a customizable AI infrastructure with several different types of NVIDIA build chips multiple networking options, and for air and liquid-cooled data center.
We exceeded our expectations in Q4 in ramping Blackwell, increasing system availability, providing several configurations to our customers. As Blackwell ramps, we expect gross margins to be in the low 70s. Initially, we are focused on expediting the manufacturing of Blackwell systems to meet strong customer demand as they race to build out Blackwell infrastructure. When fully ramped, we have many opportunities to improve the cost, and gross margin will improve and return to the mid-70s, late this fiscal year.
Sequentially, GAAP operating expenses were up 9% and non-GAAP operating expenses were 11%, reflecting higher engineering development costs and higher compute and infrastructure costs for new product introductions. In Q4, we returned $8.1 billion to shareholders in the form of share repurchases and cash dividends. Let me turn to the outlook in the first quarter. Total revenue is expected to be $43 billion, plus or minus 2%.
Continuing with its strong demand, we expect a significant ramp of Blackwell in Q1. We expect sequential growth in both Data Center and Gaming. Within Data Center, we expect sequential growth from both compute and networking. GAAP and non-GAAP gross margins are expected to be 70.6% and 71%, respectively, plus or minus 50 basis points.
GAAP and non-GAAP operating expenses are expected to be approximately $5.2 billion and $3.6 billion, respectively. We expect full-year fiscal year '26 operating expenses to grow to be in the mid-30s. GAAP and non-GAAP other incoming expenses are expected to be an income of approximately $400 million. excluding gains and losses from nonmarketable and publicly held equity securities.
GAAP and non-GAAP tax rates are expected to be 17%, plus or minus 1%, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website, including a new financial information AI agent. In closing, let me highlight upcoming events for the financial community. We will be at the TD Cowen Health Care Conference in Boston on March 3 and at the Morgan Stanley Technology, Media, and Telecom Conference in San Francisco on March 5.
Please join us for our Annual GTC conference starting Monday, March 17 in San Jose, California. Jensen will deliver a news-packed keynote on March 18, and we will host a Q&A session for our financial analysts for the next day, March 19. We look forward to seeing you at these events. Our earnings call to discuss the results for our first quarter of fiscal 2026 is scheduled for May 28, 2025.
We are going to open up the call, operator, to questions. If you could start that, that would be great.
Questions & Answers:
Operator
Thank you. [Operator instructions] And your first question comes from C.J. Muse with Cantor Fitzgerald. Please go ahead.
C.J. Muse
--
Analyst
Yeah. Good afternoon. Thank you for taking the question. I guess for me, Jensen, as test-time compute and reinforcement learning shows such promise, we're clearly seeing an increasing blurring of the lines between training and inference.
What does this mean for the potential future of potentially inference dedicated clusters? And how do you think about the overall impact to NVIDIA and your customers? Thank you.
Jensen Huang
--
President and Chief Executive Officer
Yeah, I appreciate that, C.J. There are now multiple scaling laws. There's the pre-training scaling law, and that's going to continue to scale because we have multimodality, we have data that came from reasoning that are now used to do pretraining. And then the second is post-training skilling, using reinforcement learning human feedback, reinforcement learning AI feedback, reinforcement learning, verifiable rewards.
The amount of computation you use for post-training is actually higher than pretraining. And it's kind of sensible in the sense that you could, while you're using reinforcement learning, generate an enormous amount of synthetic data or synthetically generated tokens. AI models are basically generating tokens to train AI models. And that's post-trade.
And the third part, this is the part that you mentioned is test-time compute or reasoning, long thinking, inference scaling. They're all basically the same ideas. And there, you have a chain of thought, you have search. The amount of tokens generated the amount of inference compute needed is already 100x more than the one-shot examples and the one-shot capabilities of large language models in the beginning.
And that's just the beginning. This is just the beginning. The idea that the next generation could have thousands of times and even, hopefully, extremely thoughtful and simulation-based and search-based models that could be hundreds of thousands, millions of times more compute than today is in our future. And so, the question is, how do you design such an architecture? Some of it -- some of the models are auto-regressive.
Some of the models are diffusion-based. Some of it -- some of the times you want your data center to have disaggregated inference. Sometimes, it is compacted. And so, it's hard to figure out what is the best configuration of a data center, which is the reason why NVIDIA's architecture is so popular.
We run every model. We are great at training. The vast majority of our compute today is actually inference and Blackwell takes all of that to a new level. We designed Blackwell with the idea of reasoning models in mind.
And when you look at training, it's many times more performing. But what's really amazing is for long thinking test time scaling, reasoning AI models were tens of times faster, 25x higher throughput. And so, Blackwell is going to be incredible across the board. And when you have a data center that allows you to configure and use your data center based on are you doing more pretraining now, post-training now, or scaling out your inference, our architecture is fungible and easy to use in all of those different ways.
And so, we're seeing, in fact, much, much more concentration of a unified architecture than ever before.
Operator
Your next question comes from the line of Joe Moore with JPMorgan. Please go ahead.
Joe Moore
--
JPMorgan Chase and Company -- Analyst
Morgan Stanley, actually. Thank you. I wonder if you could talk about GB200 at CES, you sort of talked about the complexity of the rack-level systems and the challenges you have. And then as you said in the prepared remarks, we've seen a lot of general availability.
Where are you in terms of that ramp? Are there still bottlenecks to consider at a systems level above and beyond the chip level? And just have you maintained your enthusiasm for the NVL72 platforms?
Jensen Huang
--
President and Chief Executive Officer
Well, I'm more enthusiastic today than I was at CES. And the reason for that is because we've shipped a lot more since CES. We have some 350 plants manufacturing the 1.5 million components that go into each one of the Blackwell racks, Grace Blackwell racks. Yes, it's extremely complicated.
And we successfully and incredibly ramped up Grace Blackwell, delivering some $11 billion of revenues last quarter. We're going to have to continue to scale as demand is quite high, and customers are anxious and impatient to get their Blackwell systems. You've probably seen on the web, a fair number of celebrations about Grace Blackwell systems coming online and we have them, of course. We have a fairly large installation of Grace Blackwell for our own engineering and our own design teams and software teams.
CoreWeave has now been quite public about the successful bring-up of theirs. Microsoft has, of course, OpenAI has, and you're starting to see many come online. And so, I think the answer to your question is nothing is easy about what we're doing, but we're doing great, and all of our partners are doing great.
Operator
Your next question comes from the line of Vivek Arya with Bank of America Securities. Please go ahead.
Vivek Arya
--
Analyst
Thank you for taking my question. Colette if you wouldn't mind confirming if Q1 is the bottom for gross margins? And then Jensen, my question is for you. What is on your dashboard to give you the confidence that the strong demand can sustain into next year? And has DeepSeek and whatever innovations they came up with, has that changed that view in any way? Thank you.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Well, let me first take the first part of the question there regarding the gross margin. During our Blackwell ramp, our gross margins will be in the low 70s. At this point, we are focusing on expediting our manufacturing, expediting our manufacturing to make sure that we can provide to customers as soon as possible. Our Blackwell is fully round.
And once it does -- I'm sorry, once our Blackwell fully rounds, we can improve our cost and our gross margin. So, we expect to probably be in the mid-70s later this year. Walking through what you heard Jensen speak about the systems and their complexity, they are customizable in some cases. They've got multiple networking options.
They have liquid-cooled and water-cooled. So, we know there is an opportunity for us to improve these gross margins going forward. But right now, we are going to focus on getting the manufacturing complete and to our customers as soon as possible.
Jensen Huang
--
President and Chief Executive Officer
We know several things, Vivek. We have a fairly good line of sight of the amount of capital investment that data centers are building out toward. We know that going forward, the vast majority of software is going to be based on machine learning. And so, accelerated computing and generative AI, reasoning AI are going to be the type of architecture you want in your data center.
We have, of course, forecasts and plans from our top partners. And we also know that there are many innovative, really exciting start-ups that are still coming online as new opportunities for developing the next breakthroughs in AI, whether it's agentic AIs, reasoning AI, or physical AIs. The number of start-ups are still quite vibrant and each one of them needs a fair amount of computing infrastructure. And so, I think the -- whether it's the near-term signals or the midterm signals, near-term signals, of course, are POs and forecasts and things like that.
Midterm signals would be the level of infrastructure and capex scale-out compared to previous years. And then the long-term signals has to do with the fact that we know fundamentally software has changed from hand-coding that runs on CPUs to machine learning and AI-based software that runs on GPUs and accelerated computing systems. And so, we have a fairly good sense that this is the future of software. And then maybe as you roll it out, another way to think about that is we've really only tapped consumer AI and search and some amount of consumer generative AI, advertising, recommenders, kind of the early days of software.
The next wave is coming, agentic AI for enterprise, physical AI for robotics, and sovereign AI as different regions build out their AI for their own ecosystems. And so, each one of these are barely off the ground, and we can see them. We can see them because, obviously, we're in the center of much of this development and we can see great activity happening in all these different places and these will happen. So, near term, midterm, long term.
Operator
Your next question comes from the line of Harlan Sur with JPMorgan. Please go ahead.
Harlan Sur
--
Analyst
Yeah. Good afternoon. Thanks for taking my question. Your next-generation Blackwell Ultra is set to launch in the second half of this year, in line with the team's annual product cadence.
Jensen, can you help us understand the demand dynamics for Ultra given that you'll still be ramping the current generation Blackwell solutions? How do your customers and the supply chain also manage the simultaneous ramps of these two products? And is the team still on track to execute Blackwell Ultra in the second half of this year?
Jensen Huang
--
President and Chief Executive Officer
Yes. Blackwell Ultra is second half. As you know, the first Blackwell was we had a hiccup that probably cost us a couple of months. We're fully recovered, of course.
The team did an amazing job recovering and all of our supply chain partners and just so many people helped us recover at the speed of light. And so, now we've successfully ramped production of Blackwell. But that doesn't stop the next train. The next train is on an annual rhythm and Blackwell Ultra with new networking, new memories, and of course, new processors, and all of that is coming online.
We have been working with all of our partners and customers, laying this out. They have all of the necessary information, and we'll work with everybody to do the proper transition. This time between Blackwell and Blackwell Ultra, the system architecture is exactly the same. It's a lot harder going from Hopper to Blackwell because we went from an NVLink 8 system to an NVLink 72-based system.
So, the chassis, the architecture of the system, the hardware, the power delivery, all of that had to change. This was quite a challenging transition. But the next transition will slot right in Blackwell Ultra will slot right in. We've also already revealed and been working very closely with all of our partners on the click after that.
And the click after that is called Vera Rubin and all of our partners are getting up to speed on the transition of that and so preparing for that transition. And again, we're going to provide a big, huge step-up. And so, come to GTC, and I'll talk to you about Blackwell Ultra, Vera Rubin and then show you what we place after that. Really exciting new products to come to GTC piece.
Operator
Your next question comes from the line of Timothy Arcuri with UBS. Please go ahead.
Timothy Arcuri
--
Analyst
Thanks a lot. Jensen, we heard a lot about custom ASICs. Can you kind of speak to the balance between customer ASIC and merchant GPU? We hear about some of these heterogeneous superclusters to use both GPU and ASIC. Is that something customers are planning on building? Or will these infrastructures remain fairly distinct? Thanks.
Jensen Huang
--
President and Chief Executive Officer
Well, we built very different things than ASICs, in some ways, completely different in some areas we intercept. We're different in several ways. One, NVIDIA'S architecture is general whether you're -- you've optimized for unaggressive models or diffusion-based models or vision-based models or multimodal models, or text models. We're great in all of it.
We're great on all of it because our software stack is so -- our architecture is sensible. Our software stack ecosystem is so rich that we're the initial target of most exciting innovations and algorithms. And so, by definition, we're much, much more general than narrow. We're also really good from the end-to-end from data processing, the curation of the training data, to the training of the data, of course, to reinforcement learning used in post-training, all the way to inference with tough time scaling.
So, we're general, we're end-to-end, and we're everywhere. And because we're not in just one cloud, we're in every cloud, we could be on-prem. We could be in a robot. Our architecture is much more accessible and a great target initial target for anybody who's starting up a new company.
And so, we're everywhere. And the third thing I would say is that our performance in our rhythm is so incredibly fast. Remember that these data centers are always fixed in size. They're fixed in size or they're fixing power.
And if our performance per watt is anywhere from 2x to 4x to 8x, which is not unusual, it translates directly to revenues. And so, if you have a 100-megawatt data center, if the performance or the throughput in that 100-megawatt or the gigawatt data center is four times or eight times higher, your revenues for that gigawatt data center is eight times higher. And the reason that is so different than data centers of the past is because AI factories are directly monetizable through its tokens generated. And so, the token throughput of our architecture being so incredibly fast is just incredibly valuable to all of the companies that are building these things for revenue generation reasons and capturing the fast ROI.
And so, I think the third reason is performance. And then the last thing that I would say is the software stack is incredibly hard. Building an ASIC is no different than what we do. We build a new architecture.
And the ecosystem that sits on top of our architecture is 10 times more complex today than it was two years ago. And that's fairly obvious because the amount of software that the world is building on top of architecture is growing exponentially and AI is advancing very quickly. So, bringing that whole ecosystem on top of multiple chips is hard. And so, I would say that -- those four reasons.
And then finally, I will say this, just because the chip is designed doesn't mean it gets deployed. And you've seen this over and over again. There are a lot of chips that get built, but when the time comes, a business decision has to be made, and that business decision is about deploying a new engine, a new processor into a limited AI factory in size, in power, and in fine. And our technology is not only more advanced, more performance, it has much, much better software capability and very importantly, our ability to deploy is lightning fast.
And so, these things are enough for the faint of heart, as everybody knows now. And so, there's a lot of different reasons why we do well, why we win.
Operator
Your next question comes from the line of Ben Reitzes with Melius Research. Please go ahead.
Ben Reitzes
--
Analyst
Yeah. Hi. Ben Reitzes here. Hey, thanks a lot for the question.
Jensen, it's a geography-related question. You did a great job explaining some of the demand underlying factors here on the strength. But U.S. was up about $5 billion or so sequentially.
And I think there is a concern about whether U.S. can pick up the slack if there's regulations toward other geographies. And I was just wondering, as we go throughout the year, if this kind of surge in the U.S. continues and it's going to be -- whether that's OK.
And if that underlies your growth rate, how can you keep growing so fast with this mix shift toward the U.S.? Your guidance looks like China is probably up sequentially. So, just wondering if you could go through that dynamic and maybe collect can weigh in. Thanks a lot.
Jensen Huang
--
President and Chief Executive Officer
China is approximately the same percentage as Q4 and as previous quarters. It's about half of what it was before the export control. But it's approximately the same in percentage. With respect to geographies, the takeaway is that AI is software.
It's modern software. It's incredible modern software, but it's modern software and AI has gone mainstream. AI is used in delivery services everywhere, shopping services everywhere. If you were to buy a quart of milk, it's delivered to you.
AI was involved. And so almost everything that a consumer service provides AIs at the core of it. Every student will use AI as a tutor, healthcare services use AI, financial services use AI. No fintech company will not use AI.
Every Fintech company will. Climate tech companies use AI. Mineral discovery now uses AI. The number of -- every higher education, every university uses AI and so I think it is fairly safe to say that AI has gone mainstream and that it's being integrated into every application.
And our hope is that, of course, the technology continues to advance safely and advance in a helpful way to society. And with that, we're -- I do believe that we're at the beginning of this new transition. And what I mean by that in the beginning is, remember, behind us has been decades of data centers and decades of computers that have been built. And they've been built for a world of hand coding and general-purpose computing and CPUs and so on and so forth.
And going forward, I think it's fairly safe to say that world is going to be almost all software to be infused with AI. All software and all services will be based on -- ultimately, based on machine learning, the data flywheel is going to be part of improving software and services and that the future computers will be accelerated, the future computers will be based on AI. And we're really two years into that journey. And in modernizing computers that have taken decades to build out.
And so, I'm fairly sure that we're in the beginning of this new era. And then lastly, no technology has ever had the opportunity to address a larger part of the world's GDP than AI. No software tool ever has. And so, this is now a software tool that can address a much larger part of the world's GDP more than any time in history.
And so, the way we think about growth, and the way we think about whether something is big or small has to be in the context of that. And when you take a step back and look at it from that perspective, we're really just in the beginning.
Operator
Your next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead. Aaron, your line is open. Your next question comes from Mark Lipacis with Evercore ISI.
Please go ahead.
Mark Lipacis
--
Analyst
Hi. It's Mark. Thanks for taking the question. I had a clarification and a question.
Colette up for the clarification. Did you say that enterprise within the data center grew 2x year on year for the January quarter? And if so, does that -- would that make it the fast faster growing than the hyperscalers? And then, Jensen, for you, the question, hyperscalers are the biggest purchasers of your solutions, but they buy equipment for both internal and external workloads, external workflows being cloud services that enterprise is used. So, the question is, can you give us a sense of how that hyperscaler spend splits between that external workload and internal? And as these new AI workflows and applications come up, would you expect enterprises to become a larger part of that consumption mix? And does that impact how you develop your service, your ecosystem? Thank you.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Sure. Thanks for the question regarding our Enterprise business. Yes, it grew 2x and very similar to what we were seeing with our large CSPs. Keep in mind, these are both important areas to understand.
Working with the CSPs can be working on large language models, can be working on inference in their own work. But keep in mind, that is also where the enterprises are servicing. Your enterprises are both with your CSPs as well as in terms of building on their own. They're both growing quite well.
Jensen Huang
--
President and Chief Executive Officer
The CSPs are about half of our business. And the CSPs have internal consumption and external consumption, as you say. And we're using -- of course, used for internal consumption. We work very closely with all of them to optimize workloads that are internal to them because they have a large infrastructure of NVIDIA gear that they could take advantage of.
And the fact that we could be used for AI on the one hand, video processing on the other hand, data processing like Spark, we're fungible. And so, the useful life of our infrastructure is much better. If the useful life is much longer, then the TCO is also lower. And so, the second part is how do we see the growth of enterprise or not CSPs, if you will, going forward? And the answer is, I believe, long term, it is by far larger and the reason for that is because if you look at the computer industry today and what is not served by the computer industry is largely industrial.
So, let me give you an example. When we say enterprise, and let's use the car company as an example because they make both soft things and hard things. And so, in the case of a car company, the employees will be what we call enterprise and agentic AI and software planning systems and tools, and we have some really exciting things to share with you guys at GTC, build agentic systems are for employees to make employees more productive to design to market plan to operate their company. That's agentic AI.
On the other hand, the cars that they manufacture also need AI. They need an AI system that trains the cars, treats this entire giant fleet of cars. And today, there's 1 billion cars on the road. Someday, there will be 1 billion cars on the road, and every single one of those cars will be robotic cars, and they'll all be collecting data, and we'll be improving them using an AI factory.
Whereas they have a car factory today, in the future, they'll have a car factory and an AI factory. And then inside the car itself is a robotic system. And so, as you can see, there are three computers involved and there's the computer that helps the people. There's the computer that build the AI for the machineries that could be, of course, could be a tractor, it could be a lawn mower.
It could be a human or robot that's being developed today. It could be a building. It could be a warehouse. These physical systems require new type of AI we call physical AI.
They can't just understand the meaning of words and languages, but they have to understand the meaning of the world, friction and inertia, object permanence, and cause and effect. And all of those type of things that are common sense to you and I, but AIs have to go learn those physical effects. So, we call that physical AI. That whole part of using agentic AI to revolutionize the way we work inside companies, that's just starting.
This is now the beginning of the agentic AI era, and you hear a lot of people talking about it, and we got some really great things going on. And then there's the physical AI after that, and then there are robotic systems after that. And so, these three computers are all brand new. And my sense is that long term, this will be by far the larger of a mall, which kind of makes sense.
The world's GDP is representing -- represented by either heavy industries or industrials and companies that are providing for those.
Operator
Your next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead.
Aaron Rakers
--
Analyst
Yeah. Thanks for letting me back in. Jensen, I'm curious as we now approach the two-year anniversary of really the Hopper inflection that you saw in 2023 in GenAI in general. And when we think about the road map you have in front of us, how do you think about the infrastructure that's been deployed from a replacement cycle perspective and whether if it's GB300 or if it's the Rubin cycle where we start to see maybe some refresh opportunity? I'm just curious how you look at that.
Jensen Huang
--
President and Chief Executive Officer
Yeah. I appreciate it. First of all, people are still using Voltas and Pascals, and Amperes. And the reason for that is because there are always things that because CUDA is so programmable you could use it Blackwell, one of the major use cases right now is data processing and data curation.
You find a circumstance that an AI model is not very good at. You present that circumstance to a vision language model, let's say, it's a car. You present that circumstance to a vision language model. The vision language model actually looks in the circumstances, said, this is what happened and I was very good at it.
You then take that response to the prompt, and you go and prompt an AI model to go find in your whole lake of data other circumstances like that, whatever that circumstance was. And then you use an AI to do domain randomization and generate a whole bunch of other examples. And then from that, you can go train the bottle. And so, you could use an peers to go and do data processing and data curation and machine learning-based search.
And then you create the training data set, which you then present to your Hopper systems for training. And so, each one of these architectures are completely -- they're all CUDA-compatible and so everything wants on everything. But if you have infrastructure in place, then you can put the less intensive workloads onto the installed base of the past. All of us are very well employed.
Operator
We have time for one more question, and that question comes from Atif Malik with Citi. Please go ahead.
Atif Malik
--
Analyst
Hi. Thank you for taking my question. I have a follow-up question on gross margins for Colette. So, I understand there are many moving parts the Blackwell yields, NVLink 72, and Ethernet mix.
And you kind of tipped to the earlier question the April quarter is the bottom, but second half would have to ramp like 200 basis points per quarter to get to the mid-70s range that you're giving for the end of the fiscal year. And we still don't know much about tariff impact to broader semiconductor, so what kind of gives you the confidence in that trajectory in the back half of this year?
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
Yeah. Thanks for the question. Our gross margins, they're quite complex in terms of the material and everything that we put together in a Blackwell system, a tremendous amount of opportunity to look at a lot of different pieces of that on how we can better improve our gross margins over time. Remember, we have many different configurations as well on Blackwell that will be able to help us do that.
So, together, working after we get some of these really strong ramping completed for our customers, we can begin a lot of that work. If not, we're going to probably start as soon as possible if we can. If we can improve it in the short term, we will also do that. Tariff at this point, it's a little bit of an unknown it's an unknown until we understand further what the U.S.
government's plan is, both its timing, it's where, and how much. So, at this time, we are awaiting, but again, we would, of course, always follow export controls and/or tariffs in that manner.
Operator
Ladies and gentlemen, that does conclude our question-and-answer session. I'm sorry.
Jensen Huang
--
President and Chief Executive Officer
Thank you.
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
We are going to open up to Jensen. A couple of things.
Jensen Huang
--
President and Chief Executive Officer
I just wanted to thank you. Thank you, Colette. The demand for Blackwell is extraordinary. AI is evolving beyond perception and generative AI into reasoning.
With resenting AI, we're observing another scaling law, inference time or test time scaling, more computation. The more the model thinks the smarter the answer. Models like OpenAI, Grok 3, DeepSeek-R1 are reasoning models that apply inference time scaling. Reasoning models can consume 100x more compute.
Future reasoning models can consume much more compute. DeepSeek-R1 has ignited global enthusiasm. It's an excellent innovation. But even more importantly, it has open-sourced a world-class reasoning AI model.
Nearly every AI developer is applying R1 or chain of thought and reinforcement learning techniques like R1 to scale their model's performance. We now have three scaling laws, as I mentioned earlier, driving the demand for AI computing. The traditional scaling loss of AI remains intact. Foundation models are being enhanced with multimodality, and pretraining is still growing.
But it's no longer enough. We have two additional scaling dimensions: post-training scaling, where reinforcement learning, fine-tuning, model distillation require orders of magnitude more compute than pretraining alone; inference time scaling and reasoning where a single query and demand 100x more compute. We defined Blackwell for this moment, a single platform that can easily transition from pre-trading, post-training, and test time scaling. Blackwell's FP4 transformer engine and NVLink 72 scale-up fabric and new software technologies led Blackwell process reasoning AI models 25 times faster than Hopper.
Blackwell in all of this configuration is in full production. Each Grace Blackwell NVLink 72 rack is an engineering marvel. 1.5 million components produced across 350 manufacturing sites by nearly 100,000 factory operators. AI is advancing at light speed.
We're at the beginning of reasoning AI and inference time scaling. But we're just at the start of the age of AI, multimodal AIs, enterprise AI sovereign AI and physical AI are right around the corner. We will grow strongly in 2025. Going forward, data centers will dedicate most of capex to accelerated computing and AI.
Data centers will increasingly become AI factories, and every company will have either rented or self-operated. I want to thank all of you for joining us today. Come join us at GTC in a couple of weeks. We're going to be talking about Blackwell Ultra, Rubin, and other new computing, networking, reasoning AI, physical AI products, and a whole bunch more.
Thank you.
Operator
[Operator signoff]
Duration: 0 minutes
Call participants:
Stewart Stecker
--
Senior Director, Investor Relations
Colette M. Kress
--
Chief Financial Officer, Executive Vice President
C.J. Muse
--
Analyst
Jensen Huang
--
President and Chief Executive Officer
Joe Moore
--
JPMorgan Chase and Company -- Analyst
Vivek Arya
--
Analyst
Colette Kress
--
Chief Financial Officer, Executive Vice President
Harlan Sur
--
Analyst
Timothy Arcuri
--
Analyst
Ben Reitzes
--
Analyst
Mark Lipacis
--
Analyst
Aaron Rakers
--
Analyst
Atif Malik
--
Analyst
More NVDA analysis
All earnings call transcripts"
Alphabet Inc. (GOOGL),Q2,2025,Alphabet GOOGL Q2 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/07/23/alphabet-googl-q2-2025-earnings-call-transcript/,"DATE
Wednesday, July 23, 2025 at 4:30 p.m. ET
CALL PARTICIPANTS
Chief Executive Officer — Sundar Pichai
Chief Business Officer — Philipp Schindler
Chief Financial Officer — Anat Ashkenazi
Director of Communications — Jim Friedland
Need a quote from one of our analysts? Email pr@fool.com
RISKS
Chief Financial Officer Anat Ashkenazi noted, Total operating expenses increased 20% to $26.1 billion, driven primarily by a $1.4 billion charge related to a legal settlement and higher R&D expenses.
Ashkenazi stated, Given the recent increase in CapEx investments, we expect the growth rate in depreciation to accelerate further in Q3 2025, indicating continued margin pressure from higher depreciation expense.
Management highlighted that year-over-year comparisons will be negatively impacted by the strong spend on US elections in the second half of 2024, particularly on YouTube, which may create challenging advertising comps for the remainder of 2025.
Ashkenazi said, ""We expect to remain in a tight demand-supply environment going into 2026."" signaling ongoing capacity constraints for Google Cloud despite increased investment.
TAKEAWAYS
Consolidated Revenue
: $96.4 billion, up 14%, reflecting double-digit gains in Search, YouTube, subscriptions, and Cloud.
Google Services Revenue
: Increased 12% to $82.5 billion, with Search and YouTube advertising and subscriptions as key drivers.
Google Cloud Revenue
: Rose 32% to $13.6 billion, outpacing overall Cloud growth in both core and AI product lines.
Operating Income
: Increased 14% to $31.3 billion, with operating margin of 32.4%, partially offset by the legal charge and higher depreciation.
Net Income
: $28.2 billion, up 19%, with earnings per share up 22% to $2.31 (GAAP).
Free Cash Flow
: $5.3 billion in free cash flow and $66.7 billion for the trailing twelve months, though quarterly free cash flow was reduced by increased CapEx and tax payments.
YouTube Advertising Revenue
: Grew 13% to $9.8 billion, driven by direct response advertising, followed by brand.
Google Cloud Operating Margin
: Improved from 11.3% to 20.7%, driven by efficiencies and strong revenue performance.
Cloud Backlog
: Increased 18% sequentially, reaching $106 billion at quarter-end, signaling robust customer demand.
CapEx
: $22.4 billion, with management raising 2025 CapEx guidance to $85 billion from $75 billion, citing server delivery timing and accelerated data center construction.
Gemini Token Processing
: Surpassed nine hundred and eighty trillion monthly tokens, doubling since May, indicating rapid adoption of AI services across user bases.
Gemini App Usage
: More than 450 million monthly active users, with daily requests growing over 50% from Q1 2025.
Paid Clicks
: Chief Business Officer Philipp Schindler said paid clicks were up 4% year-over-year, but noted that a variety of factors impact this metric and suggested caution in drawing broad conclusions from it.
Waymo Autonomous Driving
: Surpassed one hundred million miles driven autonomously on public roads, with expansion into Atlanta and territory growth in Austin, Los Angeles, and the San Francisco Bay Area.
Return of Capital
: Repurchased $13.6 billion in stock and paid $2.5 billion in dividends.
SUMMARY
Management increased full-year 2025 CapEx guidance by $10 billion to $85 billion, driven by higher investments in servers and accelerated data center construction to meet strong Google Cloud demand. AI initiatives contributed to significant adoption gains, with new product platforms and expansions into multimodal and agentic capabilities fueling customer and developer engagement. Cloud backlog rose 38% year-over-year to $106 billion, enabled by a doubling of $250 million-plus deals and a 28% quarter-over-quarter increase in new GCP customers. Significant legal and infrastructure costs, as well as challenging advertising revenue comps, will affect profitability and growth rates in upcoming quarters according to management, specifically referencing the second half of 2025. Operating margin expansion in Cloud and momentum in subscriptions highlight evolving monetization strategies, while Supply constraints and elevated CapEx signal persistent infrastructure bottlenecks.
Schindler stated, Advertisers that activate AI Max in search campaigns typically see 14% more conversions, and Campaigns using Smart Bidding Exploration see a 19% increase in conversions on average.
Management introduced the AgentSpace enterprise agent platform and reported over one million subscriptions booked ahead of general availability, reinforcing ecosystem building beyond core products.
Google Lens searches increased 70% year-over-year, with shopping queries driving additional incremental growth in Search engagement.
YouTube Shorts now delivers over two hundred million daily views, and In the US, Shorts earn as much revenue per watch hour as traditional in-stream formats.
Waymo's new markets and service expansions signal growing commercialization of autonomous mobility within the Other Bets segment, despite ongoing operating losses.
INDUSTRY GLOSSARY
TPU (Tensor Processing Unit)
: Custom-developed Google hardware accelerators optimized for machine learning workloads, particularly deep neural networks.
Gemini
: Alphabet’s proprietary family of AI models deployed across products including Search, Workspace, Cloud, and consumer apps; notably includes multimodal and agentic capabilities.
Circle to Search
: A multimodal search feature enabling users to interact visually with content by circling objects on their mobile screens.
AI Overview
: Summarized responses in Google Search powered by Gemini models, designed to answer complex queries using generative AI.
Smart Bidding Exploration
: Google’s AI-powered advertising bidding strategy update for enhanced value and less overtly searched queries.
AgentSpace
: Open, interoperable enterprise platform supporting chat, search, and AI agent development, as described by management.
Cloud Backlog
: The contractual value of cloud services arranged but not yet recognized as revenue, serving as a future revenue indicator.
AssetStudio
: Google's AI-powered creative asset generation tool for advertisers and businesses.
Full Conference Call Transcript
Sundar Pichai:
Thanks, Jim. Good afternoon, everyone. Q2 was a standout quarter for us with robust growth across the company. As you saw at I/O, we are leading at the frontier of AI and shipping at an incredible pace. AI is positively impacting every part of the business, driving strong momentum. This quarter, search delivered double-digit revenue growth. Our new search features continue to perform well. AI mode has launched in the US and India and is going well, while AI overviews now have over two billion monthly users across more than two hundred countries and territories and forty languages. I'll give some more details on search in a moment.
We continue to see strong performance in YouTube as well as subscriptions, reflecting great momentum across these high-growth businesses. In the US, Shorts now earn as much revenue per watch hour as traditional in-stream on YouTube, and in some countries, it now even exceeds in-stream's rate. Cloud had another great quarter of strong growth in revenues, backlog, and profitability. Annual revenue run rate is now more than $50 billion. We are seeing significant demand for our comprehensive AI product portfolio. Of course, this is all possible because of the long-term investments we have made in our differentiated full-stack approach to AI.
This spans AI infrastructure, world-class research, models and tooling, and our products and platforms that bring AI to people all over the world. I'll briefly touch on the AI stack before turning to quarterly highlights. First, AI infrastructure. We operate the leading global network of AI-optimized data centers and cloud regions. We also offer the industry's widest range of TPUs and GPUs along with storage and software built on top. That's why nearly all Gen AI unicorns use Google Cloud, and it's why a growing number, including leading AI research labs like SAFE Superintelligence and Physical Intelligence, use TPU specifically. Our AI infrastructure investments are crucial to meeting the growth and demand from cloud customers.
Next, world-class AI research, including models and tooling. We continue to expand our Gemini 2.5 family of hybrid reasoning models, which provide industry-leading performance in nearly every major benchmark. In addition to improving our popular workhorse model, Flash, we debuted an extremely fast Flash Lite version. We achieved gold medal level performance in the International Math Olympiad using an advanced version of Gemini with Deep Tech. We can't wait to bring DeepTink to users soon. We have some of the best models available today at every price point. Our 2.5 models have been a catalyst for growth, and nine million developers have now built for Gemini. I also want to mention VO3, our state-of-the-art video generation model.
It's been a viral hit with people sharing clips created in the Gemini app and with our new AI filmmaking tool, Flow. Since May, over seventy million videos have been generated using VO3, and we recently introduced a feature in the Gemini app to turn photos into videos, which people absolutely love. It's also rolling out to Google Photos users starting today. Third, our products and platforms. We are bringing AI to all our users and partners through surfaces like Workspace, Grow, and Mold. The growth in usage has been incredible. At I/O in May, we announced that we processed four hundred and eighty trillion monthly tokens across our surfaces.
Since then, we have doubled that number, now processing over nine hundred and eighty trillion monthly tokens—a remarkable increase. The Gemini app now has more than four hundred and fifty million monthly active users, and we continue to see strong growth in engagement, with daily requests growing over fifty percent from Q1. In June alone, over fifty million people used AI-powered meeting notes in Google Meet. And powered by VO3, our new short video product in Workspace called Google Meets reached nearly one million monthly active users. This month at Samsung Galaxy Unpacked, we announced new Android and AI features that are available on Samsung's latest devices.
And we are really pleased with the growth in subscriptions, which got a boost from our Google AI Pro and Ultra plans. Now some key highlights from Search, Cloud, YouTube, and Waymo for the quarter. First up, this is an incredibly exciting moment for Search. We see AI powering an expansion in how people are searching for and accessing information, unlocking completely new kinds of questions you can ask Google. Overall queries and commercial queries on search continue to grow year over year, and our new AI experiences significantly contributed to this increase in usage. We are also seeing that our AI features cause users to search more as they learn that search can meet more of their needs.
That's especially true for younger users. Let me go deeper on our new search experiences. We know how popular AI overviews are because they are now driving over ten percent more queries globally for the types of queries that show them, and this growth continues to increase over time. AI overviews are now powered by Gemini 2.5, delivering the fastest AI responses in the industry. We also saw strong growth in the use of multimodal search, particularly the combination of Lens or Circle to Search, together with AI overviews. This growth was most pronounced among younger users. Our new end-to-end AI search experience, AI mode, continues to receive very positive feedback, particularly for longer and more complex questions.
It's still rolling out but already has over one hundred million monthly active users in the US and India. We plan to keep enhancing the AI mode experience for users by shipping great features fast. That includes our advanced research tool, Deep Search, and more personalized responses. Next, Google Cloud. We see strong customer demand driven by our product differentiation and our comprehensive AI product portfolio. Four stats show this. One, the number of deals over $250 million doubling year over year. Two, in the first half of 2025, we signed the same number of deals over $1 million that we did in all of 2024. Three, the number of new GCP customers increased by nearly 28% quarter over quarter.
More than eighty-five thousand enterprises, including LVMH, Salesforce, and Singapore's DBS Bank, now build with Gemini, driving a 35x growth in Gemini usage year over year. Our models have served on our AI infrastructure, which offers industry-leading performance and cost efficiency for both training and inference. Along with our AI accelerators, we introduced new innovations in storage, including Anywhere Cache, which improves inference latency by up to 70%, and Rapid Storage, which delivers a 5x improvement in latency compared to leading hyperscalers. In addition, we have optimized AI software packages, including PyTorch and JAX, with full open-source support for various AI training and serving demands. We've also integrated AI agents deeply into each of our cloud products.
Wayfair is leveraging our databases integrated with AI to streamline data pipelines and deliver more personalized customer experiences. Mattel is leveraging our Gemini-powered data agents and BigQuery to review and act on product feedback more quickly. Target is using our Gemini-powered threat intelligence and security operations agents to improve cybersecurity. Capgemini is utilizing our AI software engineering agents to deliver higher quality software faster by automating tasks from code generation to testing. And BBVA says Gemini and Google Workspace are saving employees nearly three hours per week by automating repetitive tasks. It's now rolling it out to one hundred thousand employees globally. We are also focused on building a flourishing AI agent ecosystem.
We introduced an open-source agent development kit, which now has over a million downloads in less than four months. We also introduced AgentSpace, an open and interoperable enterprise chat, search, and agent platform. Gordon Foodservice is bringing AgentSpace to its US employees, which is enabling better, more efficient decision-making. And over one million subscriptions have been booked for AgentSpace ahead of its general availability. Turning now to YouTube. Nielsen data shows YouTube has led US streaming watch time for over two years. A generation that grew up with YouTube on their devices is now increasingly watching their favorite creators and content on their televisions. That includes millions of sports fans too.
Globally, they consume more than forty million hours of sports content on YouTube annually. And in September, we'll stream the NFL's first Friday game of the season live from Brazil. From sports to Shorts, we now average over two hundred million daily views on YouTube Shorts. AI is helping improve our recommendations and auto-dubbing, which translates to better returns for creators and brands by dramatically increasing the potential audiences they can reach. And today, we began rolling out a whole draft of new AI tools for creators on YouTube Shorts. Finally, YouTube continues to diversify its subscription options, recently expanding its premium light offerings to fifteen new countries, with more to come.
And lastly, Waymo continues to scale and expand to safely serve more riders in more places. Last month, Waymo launched in Atlanta, more than doubled its Austin service territory, and expanded its Los Angeles and San Francisco Bay Area territories by approximately fifty percent. Waymo also launched teen accounts, starting with riders aged fourteen to seventeen in Phoenix. Overall, great momentum here. The Waymo driver has now autonomously driven over one hundred million miles on public roads, and the team is testing across more than ten cities this year, including New York and Philadelphia. We hope to serve riders in all ten in the future. As I said, a standout quarter.
A big thank you as always to our employees and partners for an amazing Q2.
Philipp Schindler:
Thanks, Sundar, and hello, everyone. I'll quickly cover performance for Google Services for the quarter, then structure the rest of my remarks around the great progress we're delivering across search, ads, YouTube, and partnerships. Google Services revenues were $83 billion for the quarter, up 12% year on year, driven by strong growth in search and YouTube, partially offset by year-on-year decline in network revenues. To add some further color to our results, the 12% increase in search and other revenues was led by growth across all verticals, with the largest contribution from retail and financial services. YouTube saw similar performance across verticals, with 30% growth in advertising revenues driven by direct response, followed by brand.
Starting with search and other revenues, which delivered over $54 billion in revenue for the quarter. Shifts like AI are what propels our industry forward. Gemini's native multimodality is helping bring the offline audio and visual world back into the online world, creating a number of opportunities for search. Let me share a few examples. Take visual queries. Google Lens searches are one of the fastest-growing query types on search and grew 70% since this time last year. The majority of Lens searches are incremental, and we're seeing healthy growth in shopping queries using Lens. And you can obviously take this to the next level by moving from image to video-based capabilities like SearchLive.
Then there's Circle to Search, which is now on over three hundred million Android devices. We've been adding capabilities to help people explore complex topics and ask follow-up questions without switching apps. For example, gamers can now use Circle to Search while playing mobile games to see an AI overview or answers. And just last week, we brought a new agenda capability directly into search for all US users with AI-powered calling to local businesses. Finally, shopping. In Q2, we introduced a virtual try-on experience for SearchLabs users in the US. Now people can try billions of clothing products on themselves virtually.
Early results and engagement have been extremely positive, particularly with Gen Z users, and we'll be bringing this functionality to all US users imminently. All these innovations are opening up completely new ways for people to use technology, bringing the offline world into the online world in ways that simply have not been possible before. Add in our amazing AI translation capabilities and just imagine the possibilities. People can access more content in their language, and businesses large and small, international or local, can reach even more customers. I'm excited about how all of these elements will come together and the opportunities ahead of us in Search.
Moving to ads, where our strategy to reinvent the entire marketing process with AI is delivering value for our customers and our business. Last quarter, we introduced AI Max in Search, a new suite of AI-powered features and existing search campaigns. Advertisers that activate AI Max in search campaigns typically see 14% more conversions. On media buying, Smart Bidding Exploration, the biggest update to bidding strategy in a decade, brings better performance to advertisers by allowing them to bid on less obvious but potentially higher value queries more often. Campaigns using Smart Bidding Exploration see a 19% increase in conversions on average. DemandGen continues to drive revenue growth and deliver measurable impact for our customers.
As an example, Depop, Etsy's resale clothing marketplace, used the Shorts-only DemandGen campaign to drive new customers to the site. Shorts drove 80% brand lift and double click-through rates versus benchmarks. On creatives, we launched AssetStudio using our latest models to help businesses large and small generate creative assets. Small businesses benefit from top-quality assets and deployment scaling capabilities, but larger businesses can go faster from proof of concept to launch and resize at lower costs. Over two million advertisers now use Google's AI-powered asset generation tools to run ads, a 50% increase on this time last year. Turning to YouTube, where we saw continued strong revenue growth driven by direct response followed by brand.
YouTube creators are connected to the global zeitgeist and trusted by their audiences like no others. As part of BrandConnect, we launched Creator Partnership Hub, which allows brands to more easily work with the right creators and tap into cultural moments. We introduced VO3, photo-to-video, and generative effects to Shorts, making content creation easier and offering unexplored avenues for creativity. We're seeing both the volume and the price of ads in Shorts increase, particularly in developed markets. The feed-based nature of the product allows for more ad opportunities on average, and this growth is further supported by ad formats native to Shorts, AI-powered ad creative resizing tools, improved ad targeting, and the rise in viewer engagement.
McDonald's USA harnessed the influence of YouTube creators to ignite awareness for the Minecraft Movie Meal. It leveraged YouTube Shorts partnership ads to increase its reach, generating a 3.3 times higher view-through rate than the industry benchmark. Finally, on CTV, where the momentum continues. According to the Gauge report by Nielsen, YouTube has been number one in streaming watch time in the US for more than two years, hitting a record high of 12.8% of total TV viewing in June 2025. In the past twelve months, YouTube ads viewed on CTV screens drove over one billion conversions.
We saw strong growth in retail thanks to CTV shopping ads, which allow viewers to shop directly via QR codes, helping us leverage direct marketing opportunities. As always, I'll wrap up with the momentum we're seeing in partnerships, where our customers increasingly recognize the strength and breadth of Google's ability to help them transform their business with AI. For instance, a new partnership with PayPal will improve the digital commerce experience for their merchants and customers. PayPal will expand its Google Cloud adoption for AI-driven recommendations, transaction processing, and enhanced security. The partnership also broadens the availability and functionality of PayPal's payment services capabilities across a range of Google products.
In closing, I'd like to thank Googlers everywhere for their contributions and commitment to our success and to our customers and partners for their continued trust. Anat, over to you.
Anat Ashkenazi:
Thank you, Philipp. My comments will focus on year-over-year comparisons for the second quarter unless I state otherwise. I will start with results at the Alphabet level and will then cover our segment results. I'll end with some commentary on our outlook for the second half of 2025. We had another solid quarter in Q2. Consolidated revenue of $96.4 billion increased by 14% or 13% in constant currency. Search and YouTube advertising, subscription platforms and devices, and Google Cloud each had double-digit revenue growth this quarter, reflecting strong momentum across the business. Total cost of revenue was $39 billion, up 10%.
TAC was $14.7 billion, up 10%, and other costs of revenue were $24.3 billion, up 10%, with the increase primarily driven by content acquisition costs largely for YouTube, followed by depreciation. Total operating expenses increased 20% to $26.1 billion. The biggest driver of growth was expense for legal and other matters, which reflected the impact of a $1.4 billion charge related to a settlement in principle of certain legal matters. R&D investments increased by 16%, primarily driven by increases in compensation and depreciation expenses. Sales and marketing expenses increased 5%, primarily reflecting an increase in advertising and promotional expenses. Operating income increased 14% this quarter to $31.3 billion, and operating margin was 32.4%.
Operating margin benefited from strong revenue growth and continued efficiencies in our expense base, partially offset by the legal charge I mentioned earlier and a significant increase in depreciation expense. Net income increased 19% to $28.2 billion, and earnings per share increased 22% to $2.31. We generated free cash flow of $5.3 billion in the second quarter and $66.7 billion for the trailing twelve months. Free cash flow in the second quarter was affected by a sizable sequential increase in CapEx and cash tax payments as we make federal tax payments in the second quarter for both Q1 and Q2. We ended the quarter with $95 billion in cash and marketable securities. Turning to segment results.
Google Services revenues increased 12% to $82.5 billion, reflecting strength in Google Search and YouTube advertising and subscriptions. Google Search and other revenues increased by 12% to $54.2 billion. Search and other revenues delivered growth across all verticals, with the largest contributions coming from retail and financial services. YouTube advertising revenues increased 13% to $9.8 billion, driven by direct response advertising, followed by brand. Network advertising revenue of $7.4 billion was down 1%. Subscription platforms and devices revenues increased 20% to $11.2 billion, primarily reflecting growth in subscription revenues. This growth was driven by YouTube subscription offerings, followed by Google One, with the growth in paid subscriptions being the biggest driver of revenue growth.
Google Services operating income increased 11% to $33.1 billion. Operating margin was flat year on year at 40.1% as healthy revenue growth and continued efficiency in our expense base were partially offset by the legal charge I mentioned earlier. Turning to the Google Cloud segment, which delivered very strong results this quarter. Revenues increased by 32% to $13.6 billion in the second quarter, reflecting growth in GCP across core and AI products at a rate that was much higher than cloud's overall revenue growth, and growth in Google Workspace driven by an increase in average revenue per seat and the number of seats. Google Cloud operating income increased to $2.8 billion, and operating margin increased from 11.3% to 20.7%.
The expansion in cloud operating margin was driven by strong revenue performance and continued efficiencies in our expense base, partially offset by higher technical infrastructure usage costs, which includes the associated depreciation. As we ramp our AI investments, we continue to focus on driving improvements in productivity and efficiency to offset growth in technical infrastructure-related expenses, particularly from higher depreciation. Google Cloud backlog increased 18% sequentially in Q2 and 38% year over year, reaching $106 billion at the end of the quarter. This growth was driven by strong demand for our products and services from both new and existing customers. As Sundar mentioned, we have signed multiple billion-dollar-plus deals in the first half of the year.
As for Other Bets, in the second quarter, revenue was $373 million, and operating loss was $1.2 billion. Within Other Bets, we're allocating more resources to businesses like Waymo, where we see opportunities to create additional value. With respect to CapEx, in the second quarter, our CapEx was $22.4 billion. The vast majority of our CapEx was invested in technical infrastructure, with approximately two-thirds of investments in servers and one-third in data centers and networking equipment. In Q2, we returned capital to shareholders through repurchase of stock of $13.6 billion and dividend payments of $2.5 billion.
Turning to our outlook, I would like to provide some commentary on several factors that will impact our business performance in the second half of 2025, as well as an updated outlook for full-year CapEx. First, in terms of revenues, we're pleased with the overall momentum we're seeing across the business. At current spot rates, we could see a tailwind to our revenue in Q3. However, volatility in exchange rates could affect the impact of FX on Q3 revenue.
As for our segments, in Google Services, advertising revenues in the second half of 2025 will be affected by the following: the continued lapping of the strength we experienced in financial service verticals throughout 2024, and year-over-year comparisons will be negatively impacted by the strong spend on US elections in the second half of 2024, particularly on YouTube. In Cloud, as I mentioned, the demand for our products is high, as evidenced by the continued revenue growth and the cloud backlog of $106 billion. We have been working hard to increase capacity and have improved the pace of server deployment. We expect to remain in a tight demand-supply environment going into 2026.
Moving to investments, given the strong demand for our cloud products and services, we now expect to invest approximately $85 billion in CapEx in 2025, up from a previous estimate of $75 billion. Our updated outlook reflects additional investment in servers, the timing of delivery of servers, and an acceleration in the pace of data center construction, primarily to meet cloud customer demand. Looking out to 2026, we expect a further increase in CapEx due to the demand we're seeing from customers as well as growth opportunities across the company. We will provide more details on the 2026 CapEx outlook in a future earnings call.
In terms of expenses, first, as I mentioned on our previous earnings call, the significant increase in our investments in CapEx over the past few years will continue to put pressure on the P&L, primarily in the form of higher depreciation. In the second quarter, depreciation increased $1.3 billion year over year to $5 billion, reflecting a growth rate of 35%. Given the recent increase in CapEx investments, we expect the growth rate in depreciation to accelerate further in Q3. Second, as we've previously said, we expect some headcount growth in 2025 in key investment areas. In the third quarter, we expect a sequential increase in total headcount additions due in part to the hiring of new graduates.
And third, Q3 will reflect the expense associated with the upcoming August launch of the new Pixel family of products. In conclusion, as you heard from Sundar and Philipp, we're pleased with the momentum in the business and excited about the pace of innovation. Our full-stack approach, which combines AI infrastructure, AI research, and AI products and platforms, positions us well to deliver new products and services across the company. We're seeing great momentum with our AI efforts, as demonstrated by the increase in cumulative token process. Search revenues are seeing healthy growth with features like AI overviews, AI mode, and Lens offering new ways for users to access information.
Cloud has reached an annual revenue run rate of more than $50 billion and is delivering margin expansion while continuing to invest to meet customer demand. And YouTube has expanded its addressable market by building new services like Shorts, which now averages over two hundred billion daily views. We're excited to see the value our products and services are bringing to customers and partners around the globe. Now I'll turn the call over to the operator, and Sundar, Philipp, and I will take your questions.
Operator:
Thank you. To prevent any background noise, we ask that you please mute your line once your question has been stated. Your first question comes from Eric Sheridan with Goldman Sachs. Your line is now open.
Eric Sheridan:
Thank you so much for taking the question. Maybe one for Sundar and one for Philipp. Sundar, when you think about the journey you're on with respect to the evolution of products and platforms, how do you think about some of the implications of changing consumer behavior and how investors should think about that from the volume perspective versus the monetization perspective? Because I think there's a lot of longstanding dynamics out there about clicks and click monetization that might be very different when you look out over the next three to five years. And, Philipp, when you think about the evolution of YouTube, you made a number of comments there about subscription revenue.
I'm just curious how you think about the mix of advertising versus subscription and what some of your key learnings might have been as the
Sundar Pichai:
Thank you. Thanks, Eric. Appreciate the question. I do think looking ahead, based on everything we are seeing, people are excited about AI. They are adopting it well across our products. For me, just seeing multimodality help people have modified their behavior to include images both through Lens and Circle to Search seamlessly as part of interacting with Google. The early indications are that people are going to be adopting through these moments very, very well. I think I'm trying to understand your question in terms of clicks and click monetization. Maybe that's something Philipp can touch on.
But overall, we expect as we build out our organic experiences, we have a good understanding of how to continue training on monetization, so that'll work well with organic experiences. But we will lead with organic experience. So in terms of newer services like the Gemini app, etc., we'll focus on the organic experience for the near term. But just like we are doing with AI overviews and with AI mode over time, we'll be able to bring very, very good commercial experiences there as well, and we think people will adapt to them as they've always done. Maybe Philipp can add more. Philipp?
Philipp Schindler:
Yeah. So on your question on YouTube subscription versus ads, look, I mean, we love our ads business. We love our subscription. YouTube subscriptions are increasingly important for YouTube. We'll definitely continue our long-term focus here. We had strong growth across YouTube subscription products, which includes, just to be clear, YouTube TV, YouTube Music, and Premium. And I think one common theme for our subscription services in general is offering viewers more choice here. We also have a very deep understanding of the monetization side here. Where are we monetizing more with ads? Where can we potentially monetize more with subscriptions? So I think we will continue this as a double-tier strategy, active going forward.
Eric Sheridan:
Thank you.
Operator:
Our next question comes from Doug Anmuth with JPMorgan. Your line is now open.
Doug Anmuth:
Thanks so much for taking the questions. One for Sundar and one for Philipp. Sundar, can you just talk about how you're thinking about your current access to compute even as you spend $10 billion more this year in CapEx? You also said that you're still in a tight supply environment, so just trying to marry those. And then, Philipp, on search growth, can you talk a little bit about paid click and pricing growth just within the 12% search growth and how we should think about volume versus monetization trends going forward? Thanks.
Sundar Pichai:
Doug, thanks. On the CapEx stuff, obviously, we are seeing strong momentum across our portfolio, and especially in cloud. You are right. It's a tight supply environment, and we are investing more to expand, but there is obviously a time delay between this additional investment will play out in future years. And so, that's why both of them are true at the same time. But we are planning ahead and we are investing, and it's exciting to see the traction, particularly in cloud.
I think the comprehensiveness of our AI portfolio, the breadth of our offerings, both providing our models on GPUs and TPUs for our customers, all of that has been really driving demand, and so we are investing to match up to it.
Philipp Schindler:
Look, to be very clear, I think we said this before, we manage the business to drive great outcomes for our users and an attractive ROI for our advertisers. We actually don't manage to pay clicks and CPC targets. Some of the product and policy changes we make actually drive better monetization at the expense of paid clicks. You will actually see in the 10-Q paid clicks were up 4% year on year, but a number of factors affect these metrics from quarter to quarter, such as a few examples, advertiser spending, product changes, policy changes, user engagement, and so on.
So it's really important when it comes to paid clicks and CPCs to avoid drawing overly broad conclusions solely based on these metrics.
Doug Anmuth:
Thank you.
Operator:
Our next question comes from Brian Nowak with Morgan Stanley. Your line is now open.
Brian Nowak:
Thanks for taking my questions. I have two. First one, Sundar, there's a lot of discussion about agentic search for commercial activities and agents that can be broadly deployed. Maybe could you just, from a technology perspective, when you sit down with the engineering teams working on some of these new agentic capabilities that could come, what are some of the predominant technological hurdles they need to be cleared in order to launch scalable agents for commercial queries? That's the first one. Second one, I think in the past, you've updated us on stats on sources of internal efficiency you've seen from Gen AI-enabled capabilities. Any updates there?
And then any sort of learnings on trick points that also need to be overcome for some of these internal tools with Gen AI? Thanks.
Sundar Pichai:
Thanks, Brian. Let me start with the first one on agenting capabilities. We are definitely, in many ways, when we built 2.5, our series of 2.5 models, particularly with Pro, etc., it's the direction where we are investing the most. There's definitely exciting progress, including the models we haven't fully released yet. The main gaps we are all trying to do is, you're obviously chaining a sequence of events. And so being able to do it reliably, the latency compounds, the cost compounds. And being able to do it reliably in a way for the users, all of this comes together. In each of this, we are making progress; it all needs to kind of hang together.
The good news is we are making robust progress. We think we are at the frontier there. And in all of these areas, when you look back on a twelve-month basis, you end up making the models much more efficient for any given capability. So the forward-looking trajectory, I think, will really unlock these agentic experiences. We see the potential. We're able to do them, but they're a bit slow and costly and take time and sometimes are brittle. But we're making progress on all of that. And I think that's what will really unlock. And I expect 2026 to be the year in which people kind of use agent experiences more broadly. So it's an exciting opportunity ahead.
On the second part, I think when you say source of internalization, I presume you're talking about how we are using all of this internally. Again, given you've asked a question about agents, we are now beginning to roll out agent coding journeys for our software engineers within the company. And it's been exciting to see just over the last few months, particularly over the last few weeks, people are definitely doing more agentic workflows in software engineering as well internally.
And that's a good example of the kind of the same experiences a few months ago had a lot of friction points, but we are overcoming it and people are beginning to use it internally on the coding side as well as in certain other areas of the company as well. So exciting progress. I expect it to be an active area where we will roll out journeys for our users as well, so I'm still looking forward to it.
Brian Nowak:
Thanks, Sundar. That's great.
Operator:
Our next question comes from Michael Nathanson with MoffettNathanson. Your line is now open.
Michael Nathanson:
Thanks. Sundar, I have two for you. At I/O, you announced a partnership with Warby Parker to develop glasses. So I wonder if you share your view of how important a cycle of new devices will be to further scale AI and do you envision a world in which the mobile phone is no longer central to our consumer experience? That's one. And secondly, how does Google Search with AI mode usage differ versus Gemini standalone apps? I'm wondering if you see any differences in usage or the types of consumers who go to the app versus who go to traditional search with AI. Thanks.
Sundar Pichai:
Thanks, Michael. On the first thing, look, I think anytime AI changes, you can drive new experiences, including on hardware experiences too. So I think AI will particularly enable, you've long had the promise of glasses and other form factors. I think AI will spur a whole new wave of innovation there. We are super excited about our investment in glasses, and found experiences have taken a dramatic step up compared to the last iteration. So I think it'll be an exciting new emerging category. But I still expect phones to be at the center of the experience for the next two to three years at least.
And so I still think that's going to be phones would continue to be at the center of the consumer experience. But we are excited about the emerging categories as well. On your second question on AI mode versus Gemini standalone app, broadly, there are some use cases where you can get a great experience in both places. But there are use cases that are very specific. I think where the queries are information-oriented, but people really wanted to rely on the information, but have the full power of AI. I think AI mode really shines in that. You can go there and you know it's backed up. The Gemini models are using search deeply as a tool.
And so it's on-ground and in that search experience, and I think users are responding very positively to it. Whereas in the Gemini standalone app, you see everything from people can have a long conversation or chat just kind of pass time, in the Gemini app. You've seen early cases where people may get into it in a therapy-like experience. So these are all emerging experiences of what people do, and I think this is why I'm glad we have both surfaces. And we can innovate in both of these areas. And, of course, there'll be areas that will be commonly served by both applications, and over time, I think we can make the experience more seamless for our users.
Michael Nathanson:
Excellent, Sundar.
Operator:
Our next question comes from Mark Shmulik with Bernstein. Your line is now open.
Mark Shmulik:
Yes. Thanks for taking the question. Sundar, it seems there's almost like a daily news report about the AI talent war and high-profile folks moving around, which is kind of like your perspective on how you think Google's been doing in both kind of attracting and retaining key AI talent. And along similar lines, how do we think about AI-related resourcing costs alongside the step-up in capital investments required to go build for AI? Thank you.
Sundar Pichai:
Mark, on the first question, look, I think we've gone through these moments before. We've obviously always deeply invested in talent, including in AI talent for well over a decade now, and I think we have an extraordinary both breadth and depth of the talent. In my experience, the top people look for a combination of they want to really be at the frontier driving progress, and so the mission and how state-of-the-art your work is matters. So that's super important to them, access to compute resources, and access to your peers. Working with the best people in the industry, and it's a combination of all of that and using it to drive impact.
And I think we are pretty competitive on all those fronts. And through this moment, we continue to either at both our retention metrics as well as the new talent coming in. And both are healthy. I do know individual cases can make headlines, but when we look at numbers deeply, I think we are doing very well through this moment. And we'll continue investing in the people and the talent and the compute needed to make sure we are set up for the opportunity ahead. Maybe I'll pass it on to Anat.
Anat Ashkenazi:
Yeah. And on the question on how we integrate this into our overall cost structure, and I've mentioned before, having the benefit of having the full stack includes research, which is our people and one of our most critical resources. So we make sure that we invest appropriately to have the best brightest minds in the industry sitting here at Google and advancing our innovation to customers. It is part of what you're seeing now in our operating expense line across the organization, but we're also working hard to offset not just growth and investment across the business, but also to ensure that we can allocate resources appropriately. So Sundar mentioned earlier the use of AI tools within the company.
So that's another area where we can drive efficiency across the business is to use these tools internally in terms of how we run the organizations. And then we're continuing on the same efforts that I've talked about before with regards to running the company with a high level of discipline execution and driving efficiency across the business.
Operator:
Our next question comes from Ross Sandler with Barclays. Your line is now open.
Ross Sandler:
Great. If I can have two, that'd be great. The first one's on search click-through rates as a driver of monetization. So you guys have done a great job over the past decade of driving better ad relevancy and higher click-through rates in search. Just curious as we look forward and we see lower ad impressions per SERP, and all these things that are changing with AI overviews and different AI search formats, do you feel about your ability to drive CTR going forward? And then the second question is, it looks like you're now working with OpenAI for some aspect of cloud infrastructure. Just curious how that relationship might expand in the future. Thank you.
Philipp Schindler:
I can take the first one. Look. Specifically, you're referring to the AI overview. So understood your question correctly. Sundar mentioned it. They continue to drive higher satisfaction. They continue to drive higher search users. They're scaling up very nicely, and they're actually working for our entire user base now, scaled to over two billion users and over two hundred countries. So very happy with this development. When it comes specifically to the monetization of it, we talked about it before. We see monetization at approximately the same rate, which gives us actually a really strong base on which we can then innovate and drive actually more innovative and new and next-generation ad formats.
That's how we look at it at this moment in time.
Sundar Pichai:
On the second part with respect to OpenAI, we are very excited to be partnering with them on Google Cloud. Google Cloud is an open platform, and we have a strong history of supporting great companies, startups, AI labs, etc. So super excited about our partnership there on the cloud side. And we look forward to investing more in that relationship and growing it there.
Operator:
Our next question comes from Mark Mahaney with Evercore. Your line is now open.
Mark Mahaney:
Okay. Two questions, please. First, can you just describe maybe Philipp what you see in terms of the ad environment maybe for the back half of the year? You know, maybe versus last year? Does it seem as certain or as uncertain as it was last year? The results seem pretty strong. Are there any unusual concerns you would have for the back half of the year? And then Sundar, I want to ask again about the two surfaces approach to search. And, you know, you obviously got some, you must have some internal metrics that tell you that's the optimal way for you to approach the market.
But, you know, there's I'm sure there's a counterargument that just having that unified search and being able to discern the intent of the search, whether it's pure information or commercial, just from the query that could give you a material advantage over other offerings in the market. Just talk a little bit about what metrics you've seen that make the two surface solution seem to be optimal. Thank you.
Philipp Schindler:
So let me start. Look. We said our ad business performed strongly in Q2. Give you maybe some vertical color of it in Q2, search and other performance was led by growth across all verticals. We mentioned the largest contributions from retail and financial services, which was probably due actually to strength in insurance. We saw healthcare as a sizable contributor to growth as well. Look, we're only a few weeks into Q3, so I think it's really too early to comment on anything happening in the second half of the year.
Sundar Pichai:
On the second part of the question. Look, I think between these two surfaces, you pretty much, you know, you're covering the entire breadth and depth of what humanity can possibly do. So I think there's plenty for two surfaces to tackle at this moment. Obviously, you know, search is more information-focused. And we think of the Gemini app as more your assistant, more personal, proactive, and powerful assistant for every aspect of your daily life. And so you can imagine wanting to call deeply or create a long video, etc. Like, you know, those things can be done by the Gemini app today better.
Over time, like we've always done, we've gone through these evolutions before, like, as you point out. You know, we can understand user intent better and abstract some of the complexity for our users. At one point, people used to go to, you know, query separately for text differently from images, differently from videos, etc. And we kind of made it all seamless with universal search. So we have the experience of being able to bring together experiences in a way that makes sense for users. And do the heavy lifting for them.
But I think, you know, when you're in this early stage of new emerging paradigms, I think we want to make sure we can meet them where they are expecting today. And over time, I think, it'll give us an opportunity to serve them better. So I think that's how we are thinking about it.
Mark Mahaney:
Okay. Thank you.
Operator:
Our next question comes from Ken Gawrelski with Wells Fargo.
Ken Gawrelski:
Thank you very much. Two, if I may, please. The first on cloud, I'm just hoping maybe you could clarify your back half outlook given last quarter, you talked about some supply constraints that would ease towards the end of 2025, but yet you put up a really nice acceleration in Q2. Now you're talking about some supply constraints easing into 2026. If you could just clarify a little bit on the back half outlook for cloud, given the strong results in Q2. And then the second is a bigger picture question, which is an agentic experience. Does it democratize the web like search did two decades ago?
Enabling discovery in the long tail, or does it lead to more concentration with a smaller group of vertical winners? Would love it if you could opine on that. Thank you.
Anat Ashkenazi:
Okay. On your first question on the cloud second half outlook and the comments I previously made with regards to where we're going to see the capacity increase. So, obviously, we're working hard to bring more capacity online, which means data centers and servers are coming online, and we see more of an increase towards the back end of the year. But we're increasing capacity with every quarter that goes by, as you can see with the growth rates we've had both this quarter and in the previous quarter. As Sundar mentioned earlier, this is not the type of investment that's a light switch. It takes time to make this investment.
So what you're seeing now is investment we made some time ago that's now translating to additional capacity coming online, but more of that towards the back end of the year. I will say it's important as you think about cloud growth not to think about this in a linear fashion. Because the quarter-on-quarter growth rates could depend on the timing of capacity delivery and when that comes online. So that could move a little bit from quarter to quarter.
Sundar Pichai:
Look. On the agent experience. Look, I think, those earlier questions on the technology aspects of it and how we are making progress. Obviously, there is the value proposition for all the players involved, and I think that's going to be an equally important thing to create the unlock here. And I do think, over time, users will, you know, it's clear to me as we make progress on the agentic experience, it's going to be a much better experience for users. Right? And so you'll find savvier players leaning into these experiences, and that'll help them grow and meet this moment. And I think I do think it's an opportunity for some of the players.
And so you are right. Just like the early days of the web, there are aspects about it that will expand access, grow the use cases, etc. And I think those elements are there. But I do think it's important. It's not just a technology claim, but we have to solve the business models for the varying players involved. So and I think that's going to be an important part of this evolution as well. Thank you.
Operator:
And our last question comes from Justin Post with BAML. Your line is now open.
Justin Post:
Great. Thank you. A couple for Sundar. First, it looks like the subscription businesses are all tracking well, and you know, certainly, Gemini 2.5 has got some much good reviews. How are you doing with Gemini subscriptions? I know it's a focus area for the company. And anything you can kind of do to accelerate the consumer subscriptions of Gemini within Google One? And then secondly, just on the course change of CapEx, obviously, a bigger increase, which appears to be because of cloud demand. But just your comments on cloud ROI and, I'm sorry, CapEx ROI. What gives you confidence so you're going to get good returns on that spend? Thank you.
Sundar Pichai:
Great. On the first thing on subscriptions, you know, we've definitely, yeah. Google One has been an attractive value proposition powered by storage. But with now, our AI plans, including both Pro and Ultra, and particularly with the 2.5 series of models, they've definitely seen accelerated transactions. It was a very healthy quarter, and so we are definitely excited about the opportunities ahead. And you will find, you know, through this moment, I think we'll be able to drive growth in that area based on our AI offerings. And so it's definitely an area we are both excited by, and we are actually seeing traction particularly in the last quarter ever since we introduced 2.5 Pro.
So we are excited about the trajectory there. On the CapEx on the cloud side, look, I think we are definitely investing because we are delivering a lot of value through our cloud offerings, and I think it's important to understand, you know, as we build more and more of an installed base with Google Cloud, you know, we have very high customer satisfaction. Our churn rates are very low. And we are much more efficient in the investments needed to grow those lines of businesses. So you are seeing all that play out in our margin trajectory, particularly if you look at it annually sequentially over the past few years.
And so all of that gives us confidence as we are investing in this. You know, we'll be able to have a healthy ROI on our investments. And particularly in this AI moment, you know, there's definitely the value we are delivering to the customers is also growing pretty significantly on a forward-looking basis. And so I think all of that will help us do well here.
Operator:
Thank you. And that concludes our Q&A session. I will now turn the call over to Jim Friedland for any further remarks.
Jim Friedland:
Thanks, everyone, for joining us today. We look forward to speaking with you again on our third quarter 2025 call. Thank you, and have a good evening.
Operator:
Thank you, everyone. This concludes today's conference call. Thank you for participating. You may now disconnect."
Alphabet Inc. (GOOGL),Q3,2025,Alphabet (GOOGL) Q3 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/11/27/alphabet-googl-q3-2025-earnings-call-transcript/,"Date
Oct. 29, 2025 at 8:46 p.m. ET
Call participants
Chief Executive Officer — Sundar Pichai
Senior Vice President & Chief Business Officer — Philipp Schindler
Chief Financial Officer — Anat Ashkenazi
Director of Investor Relations — James Friedland
Need a quote from a Motley Fool analyst? Email pr@fool.com
Risks
Operating expenses
— Total operating expenses increased 28% to $29.7 billion, driven significantly by a $3.5 billion charge for a European Commission fine and higher R&D expenses.
Operating margin impact
— Operating margin in Google Services declined year-over-year to 38.5% due to the EC fine and increased technical infrastructure costs.
Incremental cost pressure
— CFO Ashkenazi stated, “the significant increase in our investments in technical infrastructure will continue to put pressure on the P&L in the form of higher depreciation expenses and related data center operations costs such as energy.”
Headwinds in advertising growth comparison
— Management indicated, “year-over-year comparisons in advertising will be negatively impacted by the strong spend on U.S. elections in the fourth quarter of 2024, particularly on YouTube.”
Takeaways
Total revenue
-- $102.3 billion, up 16% year-over-year or 15% in constant currency, marking
Alphabet
(
GOOGL
+0.65%
)
's first-ever quarter above $100 billion.
Operating income
-- $31.2 billion, up 9% year-over-year; excluding the $3.5 billion EC fine, operating income rose 22% and operating margin reached 33.9%.
Net income
-- $35 billion, a 33% increase year-over-year on double-digit growth from all major segments.
EPS
-- $2.87, increasing 35% year-over-year.
Free cash flow
-- $24.5 billion in the quarter, with $73.6 billion over the trailing twelve months, “benefited from strong operating cash flow and recent tax changes,” partially offset by higher CapEx.
Google Services revenue
-- $87.1 billion, up 14%, led by Search, YouTube Advertising, and subscriptions.
Google Search & Other Ads revenue
-- $56.6 billion, up 15% with largest contributions from retail and financial services.
YouTube advertising revenue
-- $10.3 billion, up 15%, driven by direct response and brand ad growth.
Network advertising revenue
-- $7.4 billion, down 3% year-over-year.
Subscriptions, Platforms & Devices revenue
-- $12.9 billion, up 21%, driven by YouTube and Google One subscription growth.
Google Cloud revenue
-- $15.2 billion, an increase of 34% year-over-year with growth driven by enterprise AI products.
Cloud operating income
-- Increased 85% to $3.6 billion and operating margin improved to 23.7% from 17.1% a year ago.
Cloud backlog
-- $155 billion, up 46% sequentially and 82% year-over-year, driven primarily by enterprise AI demand.
Paid clicks and CPC
-- Philipp Schindler said, “paid clicks were up 7% year-on-year and CPCs were up 7% year-on-year.”
Monthly active Gemini app users
-- Over 650 million, with queries tripling from Q2.
YouTube Shorts revenue per watch hour
-- In the U.S, “Shorts now earn more revenue per watch hour than traditional in-stream on YouTube.”
Gemini AI and generative models
-- Products built on generative AI models grew revenue by more than 200% year-over-year.
Cloud customer growth
-- Number of new Google Cloud Platform customers increased by nearly 34% year-over-year.
Major Cloud deals
-- More deals above $1 billion have been signed in the first nine months than in the previous two years combined.
AI Mode daily active users
-- Over 75 million, with strong week-over-week growth since launch and queries doubled over the quarter.
CapEx
-- $24 billion in the quarter; full-year CapEx now expected at $91 billion-$93 billion, raised from $85 billion prior estimate.
Headcount
-- CEO Pichai and CFO Ashkenazi noted ongoing productivity and discipline initiatives, including AI-generating nearly half of code and efforts to moderate headcount growth.
EC fine
-- $3.5 billion European Commission fine fully expensed in the quarter, impacting G&A costs and Google Services margin.
Summary
Alphabet
(
GOOGL
+0.65%
)
delivered a milestone quarter, surpassing $100 billion in consolidated revenue for the first time, with the entire business achieving double-digit growth and substantive momentum in AI-enabled products. The Google Cloud segment accelerated, with revenue up 34% and backlog expanding $49 billion sequentially, reflecting robust enterprise AI demand and multiple billion-dollar deal signings. YouTube reached $10.3 billion in advertising revenue, while Shorts profitability exceeded that of traditional formats in the U.S. Alphabet raised full-year CapEx expectations to a $91 billion-$93 billion range, citing sustained technical infrastructure investment. Management directly identified increasing operating costs, particularly from depreciation, energy, and a large European Commission fine, as sources of margin pressure and noted that year-over-year ad growth comparisons in Q4 will be affected by elevated prior election spending.
Pichai highlighted that first-party models, like Gemini, now process 7 billion tokens per minute via direct API used by customers.
Management reported more than 300 million paid subscriptions across products, with notable YouTube Premium and Google One momentum.
Ashkenazi confirmed Cloud GCP’s enterprise AI offerings generate “billions in quarterly revenue,” indicating tangible AI monetization.
Philipp Schindler characterized YouTube’s business as powered by a twin engine monetization strategy, combining its advertising business and its growing subscription services. Both YouTube ads and subscription saw strong growth this quarter. Looking at YouTube Music and Premium, users are, on average, delivering more value to creators, to music, media partners and YouTube itself than even ad-supported users. On average, a YouTube Music and Premium subscriber generates a meaningfully higher gross profit than an ad-supported user.
Pichai said, “the number of deals greater than $1 billion that we signed in the first 3 quarters of this year are greater than the 2 years prior.”
Ashkenazi projected a continued “tight demand-supply environment in Q4 and 2026” for Cloud due to rapid infrastructure expansion.
Schindler reported that AI Max, launched globally in September, is “the fastest-growing AI-powered search ads product,” unlocking billions of “net new queries” for advertisers.
Industry glossary
TAC
: Traffic acquisition costs; payments made to affiliates and distribution partners for search and other traffic.
TPU
: Tensor Processing Unit; a custom-developed AI accelerator chip designed by Google for machine learning workloads.
GCP
: Google Cloud Platform; Alphabet’s cloud services platform for infrastructure, AI, and enterprise applications.
EC fine
: Penalty imposed by the European Commission for regulatory or antitrust violations.
AI Max
: Google’s global AI-powered search ads product, designed to match advertisers with additional queries and customers using advanced AI models.
Shorts
: YouTube’s vertically formatted, short-form video product competing with TikTok.
Agentic commerce
: AI-enabled e-commerce experiences that interpret and execute user intent beyond traditional search and transaction flows.
ROAS
: Return on advertising spend; efficiency metric for ad campaign performance.
Full Conference Call Transcript
Sundar Pichai:
Thank you, Jim. Good afternoon, everyone, and thanks for joining us. This was a terrific quarter for Alphabet, driven by double-digit growth across every major part of our business. We are seeing AI now driving real business results across the company. We delivered our first ever $100 billion quarter. 5 years ago, our quarterly revenue was at $50 billion. Our revenue number has doubled since then, and we are firmly in the generative AI era. In parallel, we've built for the long term and diversified with successful businesses in cloud, YouTube and subscriptions. Our momentum is strong, and we are shipping at speed.
As just a few examples: our first-party models, like Gemini, now process 7 billion tokens per minute via direct API used by our customers. The Gemini app now has over 650 million monthly active users, and queries increased by 3x from Q2. Cloud had another great quarter of accelerating growth with AI revenue as a key driver. Cloud backlog grew 46% quarter-over-quarter to $155 billion. And we crossed $300 million paid subscriptions led by growth in Google One and YouTube Premium. Today, I'll discuss progress in our full stack approach to AI and then share highlights from search, cloud, YouTube and Waymo.
As a reminder, our full stack approach spans AI infrastructure, world-class research including models and tooling, and our products and platforms that bring AI to people everywhere. First up, AI infrastructure. Our extensive and reliable infrastructure, which powers all of Google's products is the foundation of our stack and a key differentiator. We are scaling the most advanced chips in our data centers, including GPUs from our partner, NVIDIA, as well as our own purposeful TPUs. And we are the only company providing a wide range of both. As we announced yesterday at NVIDIA GTC, we are now shipping the new A4X Max instances powered by NVIDIA GB300 to our cloud customers.
Our highly sought-after TPU portfolio is led by our 7-generation TPU, Ironwood, which will be generally available soon. We are investing in TPU capacity to meet the tremendous demand we are seeing from customers and partners, and we are excited that Anthropic recently shared plans to access up to 1 million TPUs. Next world-class AI research, including models and tooling. Our models are world-leading. GEMINI 2.5 Pro, Veo, Genie 3 under viral sensation Nano Banana are among the very best in class. Over 230 million videos have been generated with Veo 3, and more than 13 million developers have built with our generative models. We are looking forward to the release of Gemini 3 later this year.
Our research leadership is advancing next frontier technologies. Last week, we announced that our Willow quantum chip achieved a major breakthrough, running an algorithm 13,000x faster than 1 of the world's best supercomputers, and the result is verifiable, paving the way to future practical applications. Speaking of quantum, let me congratulate Michel Devoret, our Chief Scientist for Quantum Hardware. He received a Nobel in physics for early research he did in the 1980s. Three Nobels awarded to current Googlers in 2 years, incredible. And third, our products and platforms. We are bringing AI to more people and developers than anyone else. In July, we announced that we processed 980 trillion monthly tokens across all our surfaces.
We are now processing over 1.3 quarterly and monthly tokens, more than 20x growth in a year, phenomenal. This quarter, we took big steps to reimagine Chrome as a browser powered by AI through deep integrations with Gemini and AI Mode in search with more agentic capabilities coming soon. In August at Made by Google, we unveiled our Pixel 10 series of devices. They are the first with our most powerful chip designed to run on Gemini Tensor G5. They're our best reviewed devices ever. And last week, we launched Android XR, our new operating system at Samsung's Galaxy XR device. It brings new ways to use headsets and glasses with Gemini at the core.
Now turning to highlights from Search. AI is driving an expansionary moment for Search. As people learn what they can do with our new AI experiences, they're increasingly coming back to Search more. Search and its AI experiences are built to highlight the web, sending billions of clicks to sites every day. During the Q2 call, we shared that overall queries and commercial queries continue to grow year-over-year. This growth rate increased in Q3, largely driven by our AI investments in Search, most notably AI Overviews and AI Mode. Let me dive into the momentum we are seeing. As we have shared before, AI Overviews drive meaningful query growth.
This effect was even stronger in Q3 as users continue to learn that Google can answer more of their questions, and it's particularly encouraging to see the effect was more pronounced with younger people. We're also seeing that AI Mode is resonating well with users. In the U.S., we have seen strong and consistent week-over-week growth in usage since launch and queries doubled over the quarter. Over the last quarter, we rolled out AI Mode globally across 40 languages in record time. It now has over 75 million daily active users, and we shipped over 100 improvements to the product in Q3, an incredibly fast pace. Most importantly, AI Mode is already driving incremental total query growth for Search.
Philipp will talk more about monetization and share how AI is helping people connect with businesses and shop on Search. Next, Google Cloud. Our complete enterprise AI product portfolio is accelerating growth in revenue, operating margins and backlog. In Q3, customer demand strengthened in 3 ways. One, we are signing new customers faster. The number of new GCP customers increased by nearly 34% year-over-year. Two, we are signing larger deals. We have signed more deals over $1 billion through Q3 this year than we did in the previous 2 years combined. Third, we are deepening our relationships. Over 70% of existing Google Cloud customers use our AI products, including Banco BV, Best Buy and FairPrice Group.
As we scale, we are diversifying revenue. Today, 13 product lines are each at an annual run rate over $1 billion. And we are improving operating margin with highly differentiated products built with our own technology. This deep product differentiation starts with our AI infrastructure. We have a decade of experience building AI accelerators and today, offer the widest array of chips. This leadership is winning customers like HCA Healthcare, LG AI Research and Macquarie Bank, and it's why 9 of the top 10 AI labs choose Google Cloud. We are also the only cloud provider offering our own leading generative AI models including Gemini, Imagen, Veo, Chirp and Lyria. Adoption is rapidly accelerating.
In Q3, revenue from products built on our generative AI models grew more than 200% year-over-year. Over the past 12 months, nearly 150 Google Cloud customers each processed approximately 1 trillion tokens with our models for a wide range of applications. For example, WPP is creating campaigns with up to 70% efficiency gains. Swarovski has increased e-mail open rates by 17% and accelerated campaign localization by 10x. Earlier this month, we launched Gemini Enterprise, the new front door for AI in the workplace, and we are seeing strong adoption for agents built on this platform. Our packaged enterprise agents in Gemini Enterprise are optimized for a variety of domains, are highly differentiated and offer significant out-of-box value to customers.
We have already crossed 2 million subscribers across 700 companies. Next, YouTube. In the living room, YouTube has remained #1 in streaming watch time in the U.S. for more than 2 years, according to Nielsen. Last month marked YouTube's first time as a live NFL broadcaster. This exclusive global broadcast live from Brazil drew more than 19 million fans and set a new record for most concurrent viewers of a live stream on YouTube. YouTube Shorts also continues to perform well. In the U.S., Shorts now earn more revenue per watch hour than traditional in-stream on YouTube.
At our Made on YouTube event, we rolled out a number of AI-powered features that are helping create a supercharged creation and build their businesses. AI is now streamlining the entire content creation workflow from generated video tools and more efficient editing to AI-powered insights that help creators optimize their channels. We are also using AI to expand monetization, automatically identifying products to make their videos more shoppable. Philipp will discuss in more detail. And finally, Waymo, next year Waymo aims to open service in London, and they are working to bring service to Tokyo. They've also announced expansions to Dallas, Nashville, Denver and Seattle and secured permission to operate fully autonomously at San Jose and San Francisco Airports.
Autonomous testing continues to scale in New York City. The new Waymo for Business allows enterprises to offer Waymo as a work travel option. And we launched Waymo teens accounts in Phoenix this summer. We are pleased to see usage steadily increase with positive feedback from teens and their parents alike. Waymo's growth and momentum are strong, and 2026 is shaping up to be an exciting year. Overall, a milestone quarter, the incredible work of our teams is driving momentum across the board and our leadership in AI positions us so well for the opportunity ahead. I want to thank all of our partners and our employees for their hard work and an excellent Q3.
With that, I'll turn it over to Philipp.
Philipp Schindler:
Thanks, Sundar, and hello, everyone. I'll quickly cover performance for Google Services for the quarter, then structure the rest of my remarks around the great progress we're delivering across search, ads, YouTube and partnerships. Google Services revenues were $87 billion for the quarter, up 14% year-on-year driven by accelerated growth in Search and YouTube, partially offset by year-on-year decline in network revenues. Adding some further color to our results. The 15% increase in Search and other was led by growth across all major verticals with the largest contributions from retail and financial services. YouTube saw similar performance across verticals. Its 15% growth in advertising revenues was driven by direct response followed by brand.
Starting with Search and other revenues, which delivered over $56 billion in revenue for the quarter. As Sundar mentioned, AI is driving an expansionary moment and transforming how people use Google Search. Our investments in new AI experiences, such as AI Overviews and AI Mode, continued to drive growth in overall queries, including commercial queries, creating more opportunities for monetization. These AI experiences are enhancing how people connect with businesses and shop on Search. We recently added shopping capabilities in AI Mode, which now help people shop conversationally in Search, and we expanded try-on capabilities to more clothing items, now available to anyone in the U.S.
Lastly, we're making it easier for consumers to benefit from deals through new loyalty offerings like personalized annotations on organic results and ads. Looking at monetization. Businesses can now tap into our most powerful AI search experiences. Using our most advanced AI models, we can understand and predict intent like never before, unlocking entirely new commercial pathways to provide valuable new consumer connections and helping us monetize even more efficiently. Rolled out globally in September, AI Max and Search is already used by hundreds of thousands of advertisers, currently making it the fastest-growing AI-powered search ads product. In Q3 alone, AI Max unlocked billions of net new queries.
By delivering the most relevant ad across surfaces and matching advertisers against additional queries they weren't reaching before, AI Max helps advertisers discover new customers at the exact moment they need their product or service. Kayak, for example, look to grow conversions while staying within their ROAS goals. After turning on AI Max and Search, they grew their conversion value by 12% in early tests. We continue to infuse generative AI capabilities at every step of the marketing process. We rolled out Imagen 4 in Asset Studio and Product Studio, helping businesses produce more and better creatives.
On the measurement front, we enriched the model supporting Meridian, our marketing mix model, with additional variables, and more granular reporting in PMax is making bidding more effective. Financial services company SoFi has been using PMax to meet its ambitious growth targets and help drive a 39% improvement in its conversion volume year-over-year. Moving to YouTube, where we saw accelerated revenue growth. Our recommendation systems are driving robust watch time growth in our key monetization areas like shorts and living room. As we leverage Gemini models, we're seeing further discovery improvement. On direct response, we're excited about the growth in revenue we're seeing, especially from small and medium advertisers adopting demand gen.
We also improved performance on demand gen with over 100 launches helping to increase conversion value by more than 40% for advertisers using target-based bidding on YouTube. The retail vertical continues to lead our growth on YouTube with demand gen helping us further monetize shopping-related categories. Looking at the living room, our long-term bet, more advertisers are adopting interactive direct response ads, leading to an annual revenue run rate exceeding $1 billion globally for this format. For our viewers, we continue to give fans greater access across sports, while tapping into the best of YouTube's product innovation and creator-led content. Sundar mentioned that we expanded our NFL partnership with our first-ever exclusive global broadcast of an NFL game.
Brands love the opportunity, and we sold all our ad inventory within a couple of weeks. Looking at creators. A significant force behind the thriving YouTube creator economy is the collaboration between creators and brands. Tools like direct linking to deals, websites and shorts and swappable brand segments in long form will soon help creators show how they deliver great value for brands. Thanks to a collaboration with Dude Perfect, Comcast, Xfinity drove an 8% search lift, beating other Xfinity ads, recall lift on shorts by 34%. At the same time, it decreased the cost per lifted user by 50% when compared to the next most efficient ad.
We continue to invest in AI-powered features that are helping creators supercharge creation and build their businesses. with Veo 3 integration and speech to song, creators go from idea to iteration quicker, and new channel insights help them better understand performance. Ending on YouTube with our subscriptions product. We're also seeing momentum with strong growth in offerings such as YouTube Music and Premium and YouTube TV. We're also applying Gemini internally to help us serve customers with increased speed, intelligence and efficiency. Our sales teams use Gemini enriched with ads knowledge to streamline customer interactions.
This increased productivity by over 10% led to hundreds of millions in incremental revenue and frees up sellers to engage with more customers at a deeper, more strategic level. In our customer support division, Gemini-powered solutions have managed over 40 million customer sessions so far this year and resolved hundreds of thousands of customer inquiries, and we're just getting started. As always, I'll wrap with the progress we're seeing across partnerships where our customers tap into the strength and breadth of Google's products to accelerate their transformation. Revolut, the global financial services company, leverages Google Cloud's Vertex AI platform and Gemini models to help power its advanced customer service chatbot, develop new hyper-personalized financial products and offer predictive insights.
Revolut is also increasing its presence on YouTube adopting Veo 3 for personalized creatives, making Google a key ads partner for delivering growth and launching new markets. In closing, I'd like to thank Googlers everywhere for their contributions to our success and as always, to our customers and partners for their continued trust. And of course, a huge thanks to all of you as we celebrate 25 years of Google Ads. Anat, over to you.
Anat Ashkenazi:
Thank you, Philipp. My comments will focus on year-over-year comparisons for the third quarter, unless I state otherwise. I will start with results at the Alphabet level and will then cover our segment results. I'll end with some commentary on our outlook for the fourth quarter of 2025. We had an outstanding quarter in Q3, continuing the strong momentum we've had throughout the year, delivering double-digit revenue growth across Search and YouTube advertising, subscriptions, platforms and devices, and Google Cloud. Consolidated revenue reached $102.3 billion, a 16% year-over-year increase or 15% in constant currency. Total cost of revenue was $41.4 billion, up 13%. TAC was $14.9 billion, up 8%.
Other cost of revenues was $26.5 billion, up 16%, with the increase primarily driven by content acquisition costs largely for YouTube, followed by depreciation and other technical infrastructure operations costs. Total operating expenses increased 28% to $29.7 billion. R&D expenses increased by 22%, driven by compensation, depreciation expenses related to our AI efforts. Sales and marketing expenses were flat, and G&A expenses increased meaningfully, primarily due to the $3.5 billion charge related to the European Commission fine mentioned in the earnings press release. Operating income increased 9% this quarter to $31.2 billion, and operating margin was 30.5%. Excluding the EC fine, operating income increased 22%, and operating margin was 33.9%.
Operating margin benefited from strong revenue growth and continued efficiencies in our expense base, offset by the legal charge and a significant increase in depreciation expense. Other income and expenses was $12.8 billion, primarily due to unrealized gains in our nonmarketable equity securities portfolio. Net income increased 33% to $35 billion, and earnings per share increased 35% to $2.87. We generated free cash flow of $24.5 billion in the third quarter and $73.6 billion for the trailing 12 months. Free cash flow in Q3 benefited from strong operating cash flow and recent tax changes regarding the timing of when research and development costs are expensed and assets are depreciated. This was partially offset by higher CapEx.
We ended the quarter with $98.5 billion in cash and marketable securities. Turning to segment results. Google Services revenues increased 14% to $87.1 billion, reflecting strength in Google Search, YouTube advertising and subscriptions. Google Search and other advertising revenues increased by 15% to $56.6 billion, representing another robust quarter with continued growth across all major verticals with the largest contributions from retail and financial services. YouTube advertising revenues increased 15% to $10.3 billion driven by direct response advertising, followed by brand. Network advertising revenues of $7.4 billion were down 3%. Subscriptions, platforms and devices revenues increased 21% this quarter to $12.9 billion, driven by very strong growth in both YouTube and Google One subscriptions.
Google Services operating income increased 9% to $33.5 billion. Operating margin declined year-over-year to 38.5% as healthy revenue growth and continued efficiencies in our expense base were offset by the impact of the EC fine, which was fully reflected in the Google Services segment. Turning to the Google Cloud segment, which again delivered very strong results this quarter as cloud continued to benefit from our enterprise AI optimized stack, including our own custom TPUs and our industry-leading AI models. Cloud revenue increased by 34% to $15.2 billion in the third quarter, driven by strong performance in GCP, which continued to grow at a rate that was much higher than Cloud's overall revenue growth rate.
GCP's growth was driven by enterprise AI products, which are generating billions in quarterly revenue. We had strong growth in enterprise AI infrastructure and enterprise AI solutions, which benefited from demand for our industry-leading models, including Gemini 2.5. Core GCP was also a meaningful contributor to growth. And we had double-digit growth in Workspace, which was driven by an increase in average revenues per seat and the number of seats. Cloud operating income increased by 85% to $3.6 billion, and operating margin increased from 17.1% in the third quarter last year to 23.7% this quarter.
The expansion in Cloud operating margin was driven by strong revenue performance and continued efficiencies in our expense base partially offset by higher technical infrastructure usage costs, which includes depreciation expense and other operations costs such as energy. Google Cloud's backlog increased 46% sequentially and 82% year-over-year, reaching $155 billion at the end of the third quarter. The increase was driven primarily by strong demand for enterprise AI. As Sundar mentioned earlier, Cloud has signed more billion-dollar deals in the first 9 months of 2025 than in the past 2 years combined. In Other Bets, revenues were $344 million, and operating loss was $1.4 billion in the third quarter.
Within Other Bets, we continue to allocate more resources to businesses like Waymo, where we see opportunities to create substantial value. With respect to CapEx, in the third quarter, our CapEx was $24 billion. The vast majority of our CapEx was invested in technical infrastructure with approximately 60% of that investment in servers and 40% in data centers and networking equipment. In Q3, we returned capital to shareholders through repurchases of stock of $11.5 billion and dividend payments of $2.5 billion. Turning to our outlook. I would like to provide some commentary on factors that will impact our business performance in the fourth quarter of 2025 as well as an updated outlook for CapEx for the year.
First, in terms of revenues, we're pleased with the overall momentum of our business. At the current spot rates, we could see an FX tailwind to our revenues in Q4. However, the volatility in exchange rates could affect the impact of FX on Q4 revenues. As for our segments, in Google Services, year-over-year comparisons in advertising will be negatively impacted by the strong spend on U.S. elections in the fourth quarter of 2024, particularly on YouTube. In Cloud, demand for our products remains high as evidenced by the accelerating revenue growth and the $49 billion sequential increase in Cloud backlog in Q3.
In GCP, we see strong demand for enterprise AI infrastructure, including TPUs and GPUs, enterprise AI solutions driven by demand for Gemini 2.5 and our other AI models, and core GCP infrastructure and other services such as cybersecurity and data analytics. As I've mentioned on previous earnings calls, while we have been working hard to increase capacity and have improved the pace of server deployments and data center construction, we still expect to remain in a tight demand-supply environment in Q4 and 2026. Moving to investments. We're continuing to invest aggressively due to the demand we're experiencing from Cloud customers as well as the growth opportunities we see across the company.
We now expect CapEx to be in the range of $91 billion to $93 billion in 2025, up from our previous estimate of $85 billion, keeping in mind that the timing of cash payments can cause variability in the reported CapEx number. Looking out to 2026, we expect a significant increase in CapEx, and we'll provide more detail on our fourth quarter earnings call. In terms of expenses, first, as I've mentioned on the previous earnings calls, the significant increase in our investments in technical infrastructure will continue to put pressure on the P&L in the form of higher depreciation expenses and related data center operations costs such as energy.
In the third quarter, depreciation increased $1.6 billion year-over-year to $5.6 billion, reflecting a growth rate of 41%. Given the overall increase in CapEx investments, we expect the growth rate in depreciation to accelerate slightly in Q4. Second, we expect sales and marketing expenses to be more heavily weighted to the end of the year in part to support product launches and the holiday season. Q3 was a strong quarter, and we're excited with the adoption of our AI products helped by a rapid pace of innovation and great execution by our teams. This translated into strong momentum in Search, YouTube ads, subscription, platforms and devices in Cloud, resulting in our first $100 billion-plus quarter.
Now Sundar, Philipp and I will now take your questions.
Operator:
[Operator Instructions]
Our first question comes from Brian Nowak with Morgan Stanley.
Brian Nowak:
The first one maybe for Philipp or Sundar. It's on agentic e-commerce and agentic travel. There's a lot of external Wall Street discussion about agentic e-commerce potentially monetizing at a lower rate than search. So the question is what factors are you most focused on to sort of ensure a smooth transition for your search business and for your advertisers as you move over to a more agentic world? And the second one, Sundar, is on Waymo.
How far are we from an integration of Waymo into more of the core Gemini capabilities and the users on the platform taking your user data of where I'm going, what hotel I'm staying at, what airport I'm staying at and having integrated that into Waymo? If you can actually have users use their profiles to pre-schedule Waymos, how far off is that? What do we have to do?
Philipp Schindler:
Brian, great question. This is all early, but we see agentic experiences really as additive to the way people seek information. It helps us answer people's tough questions. It helps us -- it helps people get stuff done, and it helps businesses in the process. And we're working on multiple agentic experiences across key verticals such as travel, commerce, shopping and so on, and we're paying a lot of attention to creating a seamless user experience but also to the fact that we need to integrate different partner ecosystems in a way that it creates value for them.
And by the way, we're also working closely with a lot of our partners on the other side through our cloud services to improve their own agentic experiences. And so maybe we go a little deeper on the shopping side where we actually use AI already very actively to improve the shopping experience. As you know, we launched a more visual experience on AI Mode. That gives people a much more intuitive conversational way to shop. You can simply describe what you're looking for now like the way you talk to a friend, and we'll show you the visual shopping results.
And then we think about building an agentic shopping future and it has to be one, again, that benefits both users and merchants here. And you know that AIO, we also introduced new agentic checkout, which will let shoppers use like agentic AI to buy products from merchant sites and so on. We have a partnership with PayPal to help merchants build agentic commerce experiences. We have a new open protocols for agent-to-agent transactions and so on and so on.
Sundar Pichai:
And Brian, on Waymo, a great question. I was reflecting, I think, on the exact same topic. I'm scheduled to meet with the team to do a review on it in a few weeks out. Look, it is an exciting time. Waymo clearly is scaling up, particularly in 2026. And I think the possibility, as you said, of Gemini, particularly with the multimodal experience as well as services like YouTube, I think there's a real opportunity to make the in-car experience dramatically better. Definitely something we are excited about, and you'll see newer experiences in 2026 for sure.
Operator:
Our next question comes from Doug Anmuth with JPMorgan.
Douglas Anmuth:
Philipp, maybe you can just talk more about some of the drivers of the core search strength. And I guess, in particular, when you think about AI Overviews and AI Mode, we know that query growth is accelerating. But can you help us understand from there kind of what happens in terms of clicks per query and conversion rates and pricing in these AI-driven search formats? And then, Anat, can you talk about where you see opportunities in the core cost base as you look to make room to absorb the rapid growth in infrastructure and depreciation going forward?
Philipp Schindler:
So let me give you a bit of vertical color first. In Q3, Search and other revenues again delivered growth across all major verticals, as we said, was from retail and financial services. Health care was also a contributor to the growth here. Our new AI experiences, you mentioned the AI Overviews, AI Mode, continued to drive growth in overall queries, including commercial queries, really creating more opportunities for monetization. AI Overviews is scaling up and working for our entire user base. We're now scaled to over 2 billion users here, and we're continuing to expand ads in AI Overviews in English to more countries, across desktop, mobile and so on.
And as I've shared before, for AI Overviews, even at our current baseline of ads below and within the AI's response, overall, we see the monetization at approximately the same rate. So over time, we're excited about the opportunity of richer experiences in AI Mode and AI Overviews to basically open up then the opportunity for also much richer placements. And I think as I've said on a prior call, we manage the business to drive great outcomes for our users and an attractive ROI for advertisers. We don't really manage to paid clicks and CPC targets. But as you will see in the 10-Q, paid clicks were up 7% year-on-year and CPCs were up 7% year-on-year.
Anat Ashkenazi:
Doug, and to your question around where else can we see more opportunity for efficiency and productivity, and I think you heard me say before, this is not a onetime type of effort but rather an ongoing way in which we manage the business, and the key here is that the more we drive productivity across our business, the more we can invest in the business for growth and obviously continue to drive improvement in the P&L.
Some of the areas are things that you've heard us talk about in the past such as moderating the pace of head count growth, optimizing real estate footprint but also as we invest more and more in our technical infrastructure, ensuring that we are optimizing that build-out and the overall technical infrastructure we have that a lot of the data centers, for example, that we build ourselves, so they're optimized and we make sure we do them in the most efficient way. Sundar mentioned on one of the previous calls the productivity associated with leveraging AI for Google.
So this -- the example, the percent of code, now nearly half of all code generated by AI, that's a way for us to leverage AI to drive further productivity across the business. And obviously, we always look at making sure that when we provide services or products that we get the right economics and the right value for what we provide. So the one good example is Shorts, which has a lower revenue share than in stream that helps to improve some of our gross margins. So this is an effort. We have ongoing -- I've mentioned in the past that we have a headwind with depreciation, obviously, increasing alongside our CapEx increase.
So we're -- we have efforts across the organization to ensure we run the business in the most disciplined and productive way while continuing to invest for future growth.
Operator:
Our next question comes from Eric Sheridan with Goldman Sachs.
Eric Sheridan:
Maybe 2 if I could. Sundar, when you think about your custom silicon efforts across the organization, can you reflect a little bit about the opportunity set you see with each passing generation of custom silicon both in terms of driving operating efficiencies inside the organization and potentially increased monetization efforts around those outside of the organization? Second question would be for Philipp. Obviously, we could see the YouTube advertising revenue number in the reported results. Can you reflect little bit about the scaling of the subscription side of YouTube offerings and how the 2 parts together maybe represent an interesting framework in thinking about the monetization side of YouTube increasingly being a mix of both ads and subscription?
Sundar Pichai:
Eric, overall, I would say, we are seeing substantial demand for our AI infrastructure products, including TPU-based and GPU-based solutions. It is one of the key drivers of our growth over the past year. And I think on a going-forward basis, I think we continue to see very strong demand, and we are investing to meet that. I do think a big part of what differentiates Google Cloud effectively, we are the -- we have taken a full -- deep full stack approach to AI. So we are -- and that really plays out, right? We are the only hyperscaler who is really building offerings on our own models, and we are also highly differentiated on our own technology.
So to your question, I think that does give us the opportunity to continue driving growth in operating margins in Cloud as we have done in the past. And also, I think from a revenue, sets the infrastructure portion of our business to be a growth driver looking ahead as well.
Philipp Schindler:
And to the second part of your question, look, just taking a quick step back, we often describe YouTube's business as a flywheel. Obviously, it, first of all, starts with the creators, and we have significantly invested here to be the place that YouTube creators really call their home. That's a big piece of it, the #1 piece. Viewers, of course, YouTube has billions of monthly logged-in users and every day, people watch billions of hours of video. And we talked about how our recommendation systems are driving robust watch time growth and so on and so on.
So on the monetization side, YouTube's business is really powered, I would say, at, let's call it, a twin engine monetization strategy, combining its advertising business and its growing subscription services. Both YouTube ads and subscription saw strong growth this quarter. And so looking at YouTube Music and Premium, users are, on average, delivering more value to creators, to music, media partners and YouTube itself than even ad-supported users do. So in other words, on average, a YouTube Music and Premium subscriber generates a meaningful higher gross profit than they were simply an ad-supported users. Fans come from all over the world.
You know this and this engagement through ads and subscription generates YouTube's revenues and funds what I started with, these creators here and this then drives more viewership and engagement and so on. And that's the flywheel. And so our priority continues like this growth cycle. We're happy with this twin engine monetization strategy.
Operator:
Our next question comes from Mark Shmulik with Bernstein.
Mark Shmulik:
Sundar, with the strong adoption of Gemini, AI Mode and Overviews across the user base, are there any meaningful differences to call out kind of around the behavior and depth of engagement for those users across the entire Google ecosystem. And then, Philipp, I know we kind of asked this most quarters, but I'm curious kind of what some of the adoption you've seen around AI Overviews and Mode, how you see the economics of search evolving with the higher commercial and total query volume and how it kind of compares against the incremental cost to deliver these results.
Sundar Pichai:
Mark, look, I think obviously, AI Overviews are a natural part of the Google experience, and so engagement is very, very high. I would say AI Mode, you have varied cohorts that are people who are casual users, who are checking it out. And then -- but there's a core group, which really likes AI Mode and is passionate about it, and so you see the early adopters. The product is resonating very strongly, and they are seeking it out. So I think that's how I would highlight the difference.
With Gemini, again, a set of engaged user base who are seeking out the product and so on, but across the board, I think the trajectory has been we are definitely seeing in each of those use cases, a set of early adopters and then more people coming in and the people who are using it continue to use it more over time and report high user satisfaction. So I would say the underlying product metrics are pretty encouraging to see as well.
Philipp Schindler:
Look, into the second part of your question, I think we covered before -- Sundar covered the query development. And as I've just said before, for the AI Overviews, even at our current baseline of ads, right, whether above, below and within the AI response, overall, we see the monetization at approximately the same rate. And this is a great baseline for further innovation. We talked about this. We're excited about where this can go. And on the AI Mode side, we're testing as an AI Mode, and we'll continue to test and learn before we expand this any further. So that's in combination with what we mentioned about the commercial query overall development.
I think we're in a good place here. You could also argue that on queries, that historically have not been well monetized. We think there is a potential opportunity here where you can obviously imagine that we can build this out with smart AI integration.
Operator:
Our next question comes from Michael Nathanson with MoffettNathanson.
Michael Nathanson:
I have 2, 1 for Philipp, 1 for Anat. Philipp, it's clear that when people use AI Mode, the query length is much longer. Could you talk about how that longer length may be impacting your ability to drive ROAS and what you're seeing in terms of some of the early -- the benefits of maybe longer query length? And then, Anat, you came to Alphabet from a pharmaceutical company. You've been there more than a year. Can you talk a bit about how you're working to look at ROIC internally? And what early signs are you seeing that gives you confidence that the spending is really driving better returns longer term?
Philipp Schindler:
Look, as Sundar shared, AI Mode now has over like 75 million daily active users in the U.S. and we see a strong and consistent week-over-week growth in usage since launch, and the queries doubled over the quarter. And as I also mentioned, we're testing ads in AI Mode. We'll continue to test before we expand any further. It's really too early to tell and go into any of the details of that testing.
Anat Ashkenazi:
Yes. And the question related to ROIC and how we look at just overall our business and where do we see early signs that are encouraging, so first, I would say it's not just early signs because we're seeing returns, obviously, in the Cloud business. You've heard us talk about the fact that we already are generating billions of dollars from AI in the quarter. But then across the board, we have a rigorous framework and approach by which we evaluate these long-term investments that are meant to do 2 things.
One is to ensure we have -- we built a resilient growth profile for the company, but also that we meet the demand of the customers that we have here in the more near and midterm. So we look at it across the business. We evaluate the potential return for each one of them whether it's in Cloud, and I think that's more visible, obviously, externally given that you see the revenue generated and the fact that we're unable to meet, at this point, customer demand. We have more demand than we have supplied. In our ads business, you see the fact that we're investing to transform search, as you heard from Philipp and Sundar, with AIO and AI Mode.
So we're excited to see what our investments are -- how our investments are helping advertisers as well; YouTube, where it's helping power recommendations. So we're -- when we make a decision on investment in the long term, we go through a very rigorous process of assessing what the return could be and over what time frame we will see that return to give us the high level of confidence to then invest and make those investments for the long term. So it's a very rigorous approach.
Operator:
Our next question comes from Ross Sandler with Barclays.
Ross Sandler:
Great. About 20% of Google's search queries are commercial historically, and you've talked a bunch on this call about how AI Overviews are kind of expanding the breadth of queries. Could you talk about how new products from the monetization side, like AI Max, are potentially increasing the percent of commercial queries?
Philipp Schindler:
So look, AI Max, and I mentioned this in my call before, improves the ability for advertisers to target a wider range of queries. Separately, there is the question of whether queries actually increase with AI Mode, and Sundar actually talked about it and mentioned the opportunity that he sees here. So I think it's important to separate those 2 things.
And I personally also see this, what I just said in my last remarks, that I think, over time, there's an opportunity to actually take, let's say, queries that are not fully commercial but could have an adjacent commercial relationship to basically expand this into more attractive ads offerings without -- while really creating a really interesting user experience at the same time.
Sundar Pichai:
Yes. And the only thing I would add is just stepping back broadly, I think AI Overviews and AI Mode are dramatically improving search. We can see it in user satisfaction, user quality, all our metrics, and they're universal in the nature. They apply across the universality of human needs. So I think we are seeing it in breadth. And so naturally, over time, that will apply to commercial categories as well.
Operator:
Our next question comes from Ken Gawrelski with Wells Fargo.
Kenneth Gawrelski:
Two questions, please. First, it appears more and more clear that all the new modes -- Google with Gemini Overview -- AI Overviews, AI Mode, even ChatGPT is growing the addressable market for engagement and search-like behavior. Could you talk about what gives you confidence that it will also grow the addressable market for marketing activity and overall revenue associated with that behavior? That's question one. And question two is just more about as you think about AI Mode, AI Overviews and traditional Google Search, how do you think -- do you see a world in 12 to 24 months, those all will exist? And does the user eventually pick what mode they want?
Is -- does the algorithm pick the mode? Can you talk a little bit about how you think that will progress over the next 12 to 24 months?
Sundar Pichai:
Ken, thanks. Look, I think it's a dynamic moment, and I think we are meeting people in the moment with what they are trying to do. Obviously, search is evolving, and between AI Overviews and AI Mode, I think we are able to kind of give that range of experience for people in this moment. Over time, you will expect us to -- you can expect us to make the experiences simpler in a way that, just like we did universal search many, many years ago, we may have done text search, image search, video search, et cetera, and then we kind of brought it together as universal search.
So you will see evolutions like that, but I think we want to be sensitive to making sure we are meeting the users in terms of what they are looking for. I think Gemini allows us to build a more personal, proactive, powerful AI assistant for that moment. And I think having the 2 surfaces search in Gemini allows us to really serve users across the breadth of their needs. And -- but over time, we will thoughtfully look for opportunities to make the experience better for users.
And to the first part, I would broadly say, as I do think we've been consistently saying for a while now, this is an expansionary moment, and we are seeing people engage more. And I think when they do that, naturally, a portion of that information for users, those journeys are commercial in nature. So I would expect that to play out over time as well.
Operator:
Our last question comes from Justin Post with BAML.
Justin Post:
Great. Just a couple. Sundar, I think you mentioned Gemini 3 is coming. Maybe you can comment on the pace of innovation in frontier models. Is there still just a tremendous amount of innovation? Or is it slowing at all? And then you mentioned a number of large deals signed in the last 9 months for cloud, which is great. Any changes in the economics of these deals as far as long-term profitability? Anything we should be aware of?
Sundar Pichai:
Thanks, Justin. The first on the on the pace of frontier model research and development. Look, I think 2 things are both simultaneously true. I'm incredibly impressed by the pace at which the teams are executing and the pace at which we are improving these models. But it also is true at the same time that each of the prior model you're trying to get better over is now getting more and more capable. So I think both the pace is increasing, but sometimes we are taking the time to put out a notably improved model, so I think -- and that may take slightly longer. But I do think the underlying pace is phenomenal to see.
And I'm excited about our Gemini 3.0 release later this year. On cloud, I would point out as a sign of the momentum, I think the number of deals greater than $1 billion that we signed in the first 3 quarters of this year are greater than the 2 years prior. So we are definitely seeing strong momentum, and we are executing at pace. And in terms of long-term economics, I would say that, again, us being a full stack AI player and the fact that we are developing highly differentiated products on our own technology, I think, will help us drive a good trajectory here as you have seen over the past few years.
Operator:
And that concludes our question-and-answer session for today. I'd like to turn the conference back over to Jim Friedland for any further remarks.
James Friedland:
Thanks, everyone, for joining us today. We look forward to speaking with you again on our fourth quarter 2025 call. Thank you, and have a good evening.
Operator:
Thank you, everyone. This concludes today's conference call. Thank you for participating. You may now disconnect."
Amazon.com Inc. (AMZN),Q3,2025,Amazon (AMZN) Q3 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/10/31/amazon-amzn-q3-2025-earnings-call-transcript/,"Date
Thursday, October 30, 2025 at 5:00 p.m. ET
Call participants
Chief Executive Officer — Andrew Jassy
Chief Financial Officer — Brian Olsavsky
Director of Investor Relations — Dave Fildes
Need a quote from a Motley Fool analyst? Email pr@fool.com
Takeaways
Total revenue
-- $180.2 billion in revenue for the third quarter of 2025, representing 12% year-over-year growth, excluding foreign exchange impact.
Operating income
-- $17.4 billion in operating income for the third quarter, reduced by $2.5 billion from a Federal Trade Commission (FTC) settlement and $1.8 billion in estimated severance costs; operating income would have been $21.7 billion without these charges.
Trailing 12-month free cash flow
-- $14.8 billion, as directly reported.
North America revenue
-- $106.3 billion in revenue for the North America segment, up 11% year-over-year.
International revenue
-- International segment revenue was $40.9 billion, increasing 10% year-over-year, excluding foreign exchange effects.
AWS revenue
-- $33 billion in AWS revenue for the quarter; AWS annualized run rate reached $132 billion.
AWS backlog
-- Grew to $200 billion by the end of the quarter, with additional new deals in October 2025 exceeding total deal volume for the quarter.
AWS operating income
-- $11.4 billion in AWS operating income, with margins subject to variability due to increased data center depreciation for AI capacity.
Paid units growth
-- Worldwide paid units increased 11% year-over-year.
Third-party seller unit mix
-- Rose to 62% in the quarter, up 200 basis points from the prior year.
Advertising revenue
-- $17.7 billion in advertising revenue, growing 22% year-over-year, with three consecutive quarters of accelerating growth.
Cash CapEx
-- $34.2 billion in cash CapEx in the quarter. Cash CapEx has reached $89.9 billion so far this year; the full-year cash CapEx estimate for 2025 is approximately $125 billion, with an expected increase in 2026.
North America operating income
-- $4.8 billion in North America segment operating income, with a margin of 4.5%. Excluding the FTC charge, income was $7.3 billion and margin was 6.9% for the North America segment, excluding the $2.5 billion charge related to the legal settlement with the FTC.
International operating income
-- International segment operating income was $1.2 billion, with a margin of 2.9%. Margin expanded year-over-year, excluding severance expense.
Anthropic investment gain
-- Net income of $21.2 billion included a $9.5 billion pretax gain from Anthropic, classified under nonoperating income.
Trainium2 growth
-- Trainium2 is fully subscribed and has become a multibillion-dollar business, growing 150% quarter-over-quarter, according to Andrew Jassy.
AI-driven commerce features
-- Rufus saw 250 million active customers in 2025, monthly users up 140% year-over-year, and interactions up 210% year-over-year. Rufus is on track to deliver over $10 billion in incremental annualized sales.
Infrastructure expansion
-- More than 3.8 gigawatts of AWS power capacity were added in the past 12 months, with plans to double total capacity by 2027. Project Rainier, an AI cluster with nearly 500,000 Trainium2 chips, is currently in use by Anthropic.
Same-day perishables delivery
-- Reached over 1,000 U.S. cities, with plans to expand to 2,300 by the end of 2025, impacting the grocery business trajectory.
Prime Day event
-- Marked the largest ever, with customers saving “billions of dollars” according to Andrew Jassy, across 35 categories.
Amazon Connect
-- Exceeded $1 billion in annualized revenue run rate, handled 12 billion customer interaction minutes by AI in the last year, and serves major enterprise clients.
Robotics in fulfillment
-- Over 1 million robots deployed, with continued investment forecasted to drive safety, productivity, and speed in operations.
Summary
Amazon
(
AMZN
+1.25%
)
reported third quarter results with material impacts from special charges related to regulatory settlements and severance. AWS delivered its highest growth in nearly three years, fueled by substantial momentum in AI-related demand, with AWS revenue growing 20.2% year-over-year, and continues aggressive capacity expansion with multibillion-dollar investments in infrastructure and custom silicon. Key AI-driven commerce enhancements, such as Rufus and other generative features, demonstrated substantial customer engagement and incremental sales. The company highlighted strategic advances in core retail operations, including expansion of same-day perishable grocery delivery and the Prime member offering. Significant capital expenditures were allocated to support ongoing AWS infrastructure and supply chain innovation, with cash CapEx expected to increase further in 2026.
Chief Executive Officer Jassy stated, “we're bringing in quite a bit of capacity today, overall in the industry, maybe the bottleneck is power,” signaling no current constraint in key chip supply.
Jassy said, “Trainium3 should preview at the end of this year with much fuller volumes coming in the beginning of '26,” referencing expected broadening customer adoption.
Jassy explained Project Rainier's infrastructure scale: “it's not simple to be able to build a cluster that has 500,000 plus chips going to 1 million. That's an infrastructure feat that's hard to do at scale.”
CFO Olsavsky reported, “AWS revenue increased $2.1 billion quarter-over-quarter,” highlighting sequential growth in the segment.
Olsavsky revealed operating efficiencies, noting, “reduction of U.S. inbound lead time by nearly 4 days compared to last year,” improving working capital management.
Management disclosed that paid units grew 11% year-over-year.
Jassy described the head count reduction as culturally driven, not “really financially driven and it's not even really AI-driven, not right now, at least.”
Industry glossary
Trainium
: Amazon's custom-designed AI accelerator chip family, used for optimizing machine learning training and inference in AWS cloud environments.
AgentCore
: AWS infrastructure suite for building, deploying, and managing secure, scalable AI agents and agentic workloads.
Rufus
: Amazon's AI-powered shopping assistant increasing conversion and engagement on the platform.
Amazon Bedrock
: AWS-managed service providing access to foundation AI models and tools to build generative AI applications at scale.
Project Rainier
: Large-scale AWS compute cluster featuring Trainium2 chips, supporting major AI training workloads for clients such as Anthropic.
Agentic commerce
: Commerce enablement where automated AI agents assist customers in researching, selecting, and purchasing products.
Full Conference Call Transcript
Dave Fildes:
Hello, and welcome to our Q3 2025 financial results conference call. Joining us today to answer your questions is Andy Jassy, our CEO; and Brian Olsavsky, our CFO. As you listen to today's conference call, we encourage you to have our press release in front of you, which includes our financial results as well as metrics and commentary on the quarter. Please note, unless otherwise stated. All comparisons in this call will be against our results for the comparable period of 2024. Our comments and responses to your questions reflect management's views as of today, October 30, 2025 only, and will include forward-looking statements. Actual results may differ materially.
Additional information about factors that could potentially impact our financial results is included in today's press release and our filings with the SEC, including our most recent annual report on Form 10-K and subsequent filings. During this call, we may discuss certain non-GAAP financial measures. In our press release, slides accompanying this webcast and our filings with the SEC, each of which is posted on our IR website. You will find additional disclosures regarding these non-GAAP measures, including reconciliations of these measures with comparable GAAP measures. Our guidance incorporates the order trends that we've seen to date and what we believe today to be appropriate assumptions.
Our results are inherently unpredictable and may be materially affected by many factors, including fluctuations in foreign exchange rates, changes in global economic and geopolitical conditions, tariff and trade policies and customer demand and spending, including the impact of recessionary fears; inflation, interest rates, regional labor market constraints, world events, the rate of growth of the Internet, online commerce cloud services and new and emerging technologies and the various factors detailed in our filings with the SEC. Our guidance assumes, among other things, that we don't conclude any additional business acquisitions, restructurings or legal settlements. It's not possible to accurately predict demand for our goods and services, and therefore, our actual results could differ materially from our guidance.
And now I'll turn the call over to Andy.
Andrew Jassy:
Thanks, Dave. We saw strong growth across our business in Q3, and we're reporting $180.2 billion in revenue, up 12% year-over-year, excluding the impact from foreign exchange rates. Operating income was $17.4 billion, but would have been over $21 billion, if not for 2 special Q3 expenses, $2.5 billion for an FTC settlement and $1.8 billion for estimated severance costs. Trailing 12-month free cash flow was $14.8 billion. I'll start with AWS. AWS is growing at a pace we haven't seen since 2022, reaccelerating to 20.2% year-over-year, our largest growth rate in 11 quarters. It's worth remembering that year-over-year percentage growth is a relative term.
It's very different having 20% year-over-year growth on a $132 billion annualized run rate and to have a higher percentage growth rate on a meaningfully smaller annual revenue, which is the case with our competitors. Backlog grew to $200 billion by Q3 quarter end and doesn't include several unannounced new deals in October, which together or more than our total deal volume for all of Q3. AWS is gaining momentum. Customers want to be running their core and AI workloads in AWS given its stronger functionality, security and operational performance and the scale I see in front of us gives me significant confidence in what lies ahead. I'll share a little more detail on why.
It starts with AWS having much broader infrastructure functionality. Start-ups, enterprises and governments want to move their production workloads to the place that has the broadest and deepest array of capabilities. AWS has more services and deeper features within those services than anybody else and continues to innovate at a rapid clip. These are key building blocks for anything that customers want to create, and they're a big part of why Gartner has named AWS leader in its strategic cloud platform services Magic Quadrant for 15 consecutive years. We're bringing the same building block approach to AI. SageMaker makes it much simpler for companies to build and deploy their own foundation models.
Bedrock gives customers leading selection of foundation models and superior price performance to deploy inference into their next-generation applications. A lot of the future value companies will get from AI will be in the form of agents. AWS is heavily investing in this area and well positioned to be a leader. Companies will both create their own agents and use agents from other companies. For those building their own, it's been harder to build than it should be. It's why we launched strands to make it much easier to create agents from any foundation model that builders desire.
For companies who successfully built agents, they've hesitated putting them into production because they lack secure scalable runtime services or memory or observability built specifically for agents. It's why we launched AgentCore, a set of infrastructure building blocks that allow builders to deploy secure, scalable agents. Ericsson used AgentCore to deliver AI agents across their workforce, Sony used it to build a agentic AI platform with enterprise-level security, observability and scalability. And Cohere Health is using AgentCore to deploy agents that will reduce medical review times by up to 30% to 40%. AgentCore's SDK has already been downloaded over 1 million times, and our builders are excited about it. It's an enabler.
Companies will also use other agents, and AWS continues to build many of the agents we believe builders will use in the future. For coding, we've recently opened up our agentic coding IDE called Kiro. More than 100,000 developers jumped into Kiro in just the first few days of preview and that number has more than doubled since. It's processed trillions of tokens thus far, weekly actives are growing fast, and developers love its unique spec and tool call and capabilities. For migration and transformation, we offer an agent called Transform. Year-to-date, customers have already used it to save 700,000 hours of manual effort. The equivalent of 335 developer years of work.
For example, Thomson Reuters used it to transform 1.5 million lines of code per month, moving from Windows to open source alternatives and completing tasks or a times faster than with other migration tools. Customers have also already used Transform to analyze nearly 1 billion lines of mainframe code as they move mainframe applications to the cloud. For business customers, we've recently launched QuickSleep to bring a consumer AI-like experience to work, making it easy to find insights, conduct deep research, automate tasks, visualize data and take actions. We've already seen users churn months long projects in today's get 80% plus time savings on complex tasks and realize 90% plus cost savings.
And for contact centers, we offer Amazon Connect which creates a more personalized and efficient experience for contact center agents, managers and their customers. Connect has recently crested $1 billion annualized revenue run rate with 12 billion minutes of customer interactions being handled by AI in the last year and is being used by large enterprises like Capital One, Toyota, American Airlines and Ryanair. These are real practical results for customers, and there are many more examples like them. Because of its advantaged capabilities, security, operational performance and customer focus, AWS continues to earn most of the big enterprise and government transformations to the cloud.
As a result, AWS is where the preponderance of company's data and workloads reside and part of why most companies want to run AI and AWS. To enable customers to do so, we need to have the requisite capacity, and we've been focused on accelerating capacity the last several months, adding more than 3.8 gigawatts of power in the past 12 months, more than any other cloud provider. To put that into perspective, we're now double the power capacity that AWS was in 2022, and we're on track to double again by 2027. In the last quarter of this year alone, we expect to add at least another 1 gigawatt of power.
This capacity consists of power, data center and chips, primarily our custom silicon, Trainium and NVIDIA. We've recently brought Project Rainier Online, our massive AI compute cluster spanning multiple U.S. data centers and containing nearly 500,000 of our Trainium2 chips. Anthropic is using it now to build and deploy its industry-leading AI model, Claude, which we expect to be on more than 1 million Trainium2 chips by year-end. Trainium2 continues to see strong adoption, is fully subscribed is now a multibillion-dollar business that grew 150% quarter-over-quarter. Today, Trainium is being used by a small number of very large customers but we expect to accommodate more customers starting with Trainium3.
We're building Bedrock to be the biggest inference engine in the world and in the long run, believe Bedrock could be as big a business for AWS as EC2, and the majority of token usage in Amazon Bedrock is already running on Trainium. We're also continuing to work closely with chip partners like NVIDIA, with whom we continue to order very significant amounts as well as with AMD and Intel. These are very important partners with whom we expect to keep growing our relationships over time. You're going to see us continue to be very aggressive in investing in capacity because we see the demand. As fast as we're adding capacity right now, we're monetizing it.
It's still quite early and represents an unusual opportunity for customers in AWS. I'll now turn to stores. Where the team continues to deliver and innovate for customers across our key priorities, selection, low prices and convenience, particularly fast delivery, we're offering 14% more selection since last quarter from popular brands like The North Face and Charlotte Tilbury, and we've added hundreds of thousands of items from popular brands this year. Everyday Essentials continues to grow quickly, and year-to-date is growing nearly twice as fast as the rest of the business.
We continue to make it easier for customers to order low-priced perishable groceries from Amazon, and customers in more than 1,000 cities and towns now can shop fresh groceries alongside millions of Amazon.com products with free same-day delivery. This is a game changer for customers who can now order milk alongside electronics, check out with one cart and have everything delivered to their doorstep within hours. The team also invented a new add to delivery button that lets customers add items to previously scheduled orders and it's been used more than 80 million times since launch, and it's just launch. It's an example of one of those seemingly simple but powerful innovations that make customers' lives easier.
We remain committed to staying sharp on price and meeting or beating prices of other major retailers. In July, we had our biggest Prime Day event ever, with customers saving billions of dollars across more than 35 categories. We continue to break records on speed. We're on track to deliver at our fastest speeds ever for Prime members globally once again this year, and we've started rolling out 3-hour delivery in select U.S. cities. We're also continuing to invest in infrastructure to speed up rural deliveries and serve more customers in more communities. That includes committing over $4 billion to expand our rural delivery network across the U.S.
These are small towns where people want fast delivery, but where other companies have been backing out and reducing service. In contrast, we've already increased the number of rural communities with access to our same-day and next-day delivery by 60%, reaching roughly half of the total communities we plan to expand to by the end of the year. The stores team is also innovating rapidly with AI. For example, Rufus, our AI-powered shopping assistant has had 250 million active customers this year with monthly users up 140% year-over-year, interactions up 210% year-over-year and customers using Rufus during a shopping trip being 60% more likely to complete a purchase.
Rufus is on track to deliver over $10 billion in incremental annualized sales. Here are the highlights. Our generative AI-powered audio feature that combines product summaries and reviews to make shopping easier has expanded from hundreds of products at launch to millions of products and millions of customers have used it streaming almost 3 million minutes. In Amazon Lens, an AI-powered visual search tool that lets customers find products with their phones camera, a screenshot or a bar code, now includes Lens Live, which instantly scans products and shows real-time matches in a swipeable carousel. Tens and millions of customers are using Amazon Lens each month. Moving on to Amazon ads.
We're pleased with the continued strong growth, generating $17.6 billion of revenue in the quarter and growing 22% year-over-year. We see strength across our broad portfolio of full photo advertising offerings that helps advertisers reach an average ad-supported audience of more than $300 million in the U.S. alone. We also continue to be excited about our demand side platform, Amazon DSP, which lets advertisers plan, activate and measure full funnel investments. Last quarter, I mentioned our partnership with Roku and we've built on that with a partnership with Netflix, providing advertisers using Amazon DSP with direct access to Netflix's premium ad inventory. We announced integrations with Spotify and SiriusXM.
With Spotify, we provide advertisers with direct programmatic access to a global audience of more than 400 million monthly ad-supported listeners. And with SiriusXM, brands can reach 160 million monthly digital listeners across services like Pandora and SoundCloud and we're excited about the advertising opportunity around prime video live sports. Live sports got a lot of interest from advertisers in upfront negotiations for 2025, '26, and we exceeded our own expectations for upfront commitments with significant growth across the board. Finally, we're continuing to invade for advertisers with AI. For example, in September, we announced an agentic AI tool and creative studio that plans and executes the entire creative process in a matter of hours instead of weeks.
We're also inventing and seeing strong momentum in several other areas, and I'll mention just a few. In Prime Video live sports, NBA on Prime tipped off last week and our opening night doubleheader averaged 1.25 million viewers in the U.S., a double-digit increase over last season on cable. You'll see us bring the same constant innovation here that we brought to our NFL broadcast. We're adding golf with The Masters in 2026 and new skins competition with the PGA Tour on Black Friday this year. And we've added Peacock and FOX One to Prime Videos add-on subscription offering of over 100 channels in the U.S.
We continue to be energized by the response to Alexa+ compared to what we call the classic Alexa experience, Alexa+ customers are talking to Alexa 2x more. Those interactions are much longer, and they're covering a broader range of topics. So using Alexa+ and Fire TV at 2.5x the rate of classic using natural conversation to discover audio content 4x more, engaging with photos 4x more and customers are completing 4x more shopping conversations that end in a purchase. We've expanded the number of project hyper satellites and space to more than 150 and delivered over 1 gigabit per second speeds and test with our enterprise-grade customer terminal, the first commercial phased array we know of to clear that threshold.
Finally, Zoox robotaxis are available to riders in Las Vegas, and we've announced Washington, D.C. as the eighth testing location. We're excited for these to continue rolling out to more riders. Q4 is one of our busiest and most energizing times of the year, and we're excited about the continued demand for AWS. The innovations will announce the reinvent in December, the positive customer response to our AI-powered experiences, all the guests will be delivering throughout the holiday season and a lot more. Thanks in advance to our teammates around the world who are gearing up to deliver for customers once again. With that, I'll turn it over to Brian for a financial update.
Brian Olsavsky:
Thanks, Andy. Starting with our top line financial results. Worldwide revenue was $180.2 billion, a 12% increase year-over-year, excluding a 90 basis point favorable impact of foreign exchange. In Q3, we reported worldwide operating income of $17.4 billion. This operating income includes 2 special charges, which reduced operating income by $4.3 billion. The first charge of $2.5 billion is related to a legal settlement with the Federal Trade Commission, which impacts the North America segment and is recorded in the other operating expense line. The second charge of $1.8 billion relates to severance costs for roll eliminations and impacts all 3 of our segments.
The severance charge is recorded primarily in the technology and infrastructure, sales and marketing and general and administrative expense line items. Excluding these 2 charges, worldwide operating income would have been $21.7 billion or $1.2 billion above the high end of our guidance range. Moving to our segment results. We remain encouraged by the innovation our teams are delivering for customers across all 3 segments. In the North America segment, third quarter revenue was $106.3 billion, an increase of 11% year-over-year. International segment revenue was $40.9 billion, an increase of 10% year-over-year, excluding the impact of foreign exchange. Worldwide paid units grew 11% year-over-year. We continue to prioritize the inputs that matter most to our customers.
In the third quarter, our sharp pricing, broad selection and fast delivery speeds continue to resonate with customers. Customers appreciate the ability to quickly receive items essential for their daily needs, including perishable groceries and have them delivered in the same day. Our millions of global third-party sellers continue to be important contributors to our vast selection, which helps customers find the items they need at competitive prices. We're committed to building innovative services and features for our sellers, including our ongoing advancements in generative AI. Today, more than 1.3 million sellers have used our generative AI capabilities to more quickly launch high-quality listings. Better listings translate into better traction with customers.
And in Q3, worldwide third-party seller unit mix was 62%, up 200 basis points from Q3 of last year. Shifting to profitability. North America segment operating income was $4.8 billion, with an operating margin of 4.5%. Excluding the $2.5 billion charge related to the legal settlement with the FTC, North America segment operating income would have been $7.3 billion with an operating margin of 6.9%. North America segment operating margin also includes a portion of the severance charge. International segment operating income was $1.2 billion, with an operating margin of 2.9%. Excluding the impact of the severance charge International segment operating margins expanded year-over-year.
Globally, our progress on key inputs is delivering a better customer experience while driving a more efficient cost structure. For example, we're making notable strides in improving inventory placement to speed up delivery to customers. And as a result, for the third year in a row, we are on track to deliver our fastest speeds ever for Prime members in 2025. We continue to tune and improve our fulfillment operations and our regionalized network is operating at scale. We see many benefits of our inbound process improvements, including a reduction of U.S. inbound lead time by nearly 4 days compared to last year. This allows us to be more efficient with our inventory purchasing, which benefits working capital.
We're also placing inventory more strategically throughout the network. And by leveraging our existing infrastructure, we're now offering U.S. customers the ability to order perishable groceries and receive them the same day and as little as 5 hours. We're seeing positive early results since launching in January, when customers start shopping groceries on Amazon, they are visiting the site more often and returning twice as often as nonperishable shoppers. Looking ahead, we see further opportunity to improve our activity in our global fulfillment and transportation network. We continue to improve inventory placement to drive down distance travel and touches for package.
We will also build on the gains from our regionalized network through algorithmic improvements as well as launching robotics and automation. Operating margin may fluctuate quarter-to-quarter, we have a delivered approach to achieve sustained progress over the long term. Shifting to advertising. Advertising revenue was $17.7 billion and growth accelerated for the third consecutive quarter. We continue to see strong growth on an increasingly large base, as our full funnel advertising approach of connecting brands with customers is resonating. Moving next to our AWS segment. Revenue was $33 billion, up 20.2% year-over-year.
This is an acceleration of 270 basis points compared to last quarter, driven by strong growth across both our AI and core services and more capacity, which has come online to support customer demand. AWS revenue increased $2.1 billion quarter-over-quarter and now has an annualized revenue run rate of $132 billion. AWS operating income was $11.4 billion, and reflects our continued growth, coupled with our focus on driving efficiencies across the business. We are expanding our data center footprint, largely to accommodate Gen AI. And to the extent those assets were placed into service related to depreciation does impact our margins.
As we've long said, we expect AWS operating margins to fluctuate over time, driven in part by the level of investments we're making at any point in time. Now turning to our cash CapEx, which was $34.2 billion in Q3. We've now spent $89.9 billion so far this year. This primarily relates to AWS as we invest to support demand for our AI and core services and in custom silicon, like Trainium as well as tech infrastructure to support our North America and international segments. We'll continue to make significant investments, especially in AI, as we believe it to be a massive opportunity with the potential for strong returns on invested capital over the long term.
Additionally, we continue to invest in our fulfillment and transportation network to support the growth of the business, improve delivery speeds and lower our cost to serve. These investments will support growth for many years to come. Looking ahead, we expect our full year cash CapEx to be approximately $125 billion in 2025, and we expect that amount will increase in 2026. I'll finish up my remarks with net income. While we primarily focus our comments on operating income, our third quarter net income of $21.2 billion includes a pretax gain of $9.5 billion related to our investment in Anthropic. This investment activity is not related to Amazon's ongoing operations and is included in nonoperating income.
We're encouraged by the start of the peak season and we are ready to serve customers in the coming months. I want to thank our teams across Amazon for their hard work as we get ready to delight customers during the holiday season. Our commitment to elevating the customer experience is the only reliable way to drive sustainable value for our shareholders. With that, let's move on to your questions.
Operator:
[Operator Instructions]
And our first question comes from the line of Justin Post with Bank of America.
Justin Post:
I'll ask on AWS. Can you just kind of go through how you're feeling about your capacity levels and how capacity constrained you are right now? And then in your prepared remarks, you mentioned Trainium3 demand and maybe broadening out your customer base. Can you talk about the demand you're seeing outside of your major customers for Trainium?
Andrew Jassy:
Yes. On the capacity side, we brought in quite a bit of capacity, as I mentioned in my opening comments, 3.8 gigawatts of capacity in the last year with another gigawatt plus coming in the fourth quarter and we expect to double our overall capacity by the end of 2027. So we're bringing in quite a bit of capacity today, overall in the industry, maybe the bottleneck is power. I think at some point, it may move to chips, but we're bringing in quite a bit of capacity. And as fast as we're bringing in right now, we are monetizing it. And then on the Trainium demand, outside of our major customers.
So first of all, as I mentioned on Trainium2, it's really doing well. It's fully subscribed on Trainium2. We have -- it's a multibillion-dollar business at this point. It grew 150% quarter-over-quarter in revenue. And you see really big projects at scale now, like our Project Rainier that we're doing with Anthropic, where they're running their next version of -- they're training the next version of Claude on top of Trainium2 on 500,000 Trainium2 chips going to 1 million Trainium2 chips by the end of the year. As I mentioned, we have -- today, with Trainium2, we have a small number of very large customers on it.
But because Trainium is 30% to 40% more price performance than other options out there, and because as customers, as they start to contemplate broader scale of their production workloads, moving to being AI-focused and using inference, they badly care about price performance. And so we have a lot of demand for Trainium. Trainium3 should preview at the end of this year with much fuller volumes coming in the beginning of '26, we have a lot of customers, both very large, and I'll call it, medium-sized who're quite interested in Trainium3.
Operator:
And the next question comes from the line of Brian Nowak with Morgan Stanley.
Brian Nowak:
Congrats on the quarter, guys. So maybe 2. One, Andy, sort of a philosophical chip question. There's a lot of questions in the market about Trainium and sort of its positioning versus other third-party chips. So how do you think about the key hurdles of Trainium3 need to overcome to really make Trainium adoption broader, to your point on the last question and continue to drive Trainium as opposed to satisfying what could be broader demand with third-party chips in the near term?
Andrew Jassy:
Yes. Well, first of all, we're always going to have multiple chip options for our customers. It's been true in every major technology building block or component that we've had in AWS. Really in the history of AWS, it's never just one player that over a long period of time has the entire market segment and then can satisfy everybody's needs on every dimension. And so we have a very deep relationship with NVIDIA. We have for a very long time. And we will for as long as I can foresee the future. We buy a lot of NVIDIA.
We are not constrained in any way in buying NVIDIA, and I expect that we'll continue to buy more NVIDIA both next year and in the future. But we're different from most technology companies in that we have our own very strong chip team, and this is our Annapurna team. And you saw it first on the CPU side with what we built with Graviton which is about 40% better price performance than the other x86 processors, and you're seeing it again on the custom silicon on the AI side with Trainium, which is about the same amount of price performance benefit for customers relative to other GPU options.
And our customers to be able to use AI as expansively as they want. And remember, it's still relatively early days at this point. They're going to need better price performance and they care about it deeply. And so I mentioned earlier the momentum that Trainium2 has. And I think that for us, as we think about Trainium3, I expect Trainium3 will be about 40% better than Trainium2 and Trainium2 is already very advantaged on price performance. So we have to, of course, deliver the chip. We have to deliver it in volumes and deliver it quickly. And we have to continue to work on the software ecosystem, which gets better all the time.
And as we have more proof points like we have with Project Rainier with what Anthropic's doing on Trainium2, it builds increasing credibility for Trainium. And I think customers are very bullish about it. I'm bullish about it as well.
Operator:
And our next question comes from the line of Doug Anmuth with JPMorgan.
Douglas Anmuth:
I'll stick with basically the same topic, Andy. But can you just talk a little bit about the architecture of Project Rainier and how it's differentiated and what that means for customers and for AWS? And do you expect Rainier to expand beyond Anthropic? And how do you replicate Rainier with Trainium3 chips?
Andrew Jassy:
Yes. I think what is compelling for entropic around Project Rainier is really is the Trainium2 chip, which we built a very -- first of all, we built a very large cluster that they can use in a very expansive way. And it's not simple to be able to build a cluster that has 500,000 plus chips going to 1 million. That's an infrastructure feet that's hard to do at scale. And so some piece of it is the infrastructure capabilities that we've built over a long period of time in AWS that is unusual in the industry. But it's just also the performance of the chip and the price performance, both of which matter.
And I think that Project Rainier is something that is specific for anthropic, but we have a lot of other customers who are interested in employing large clusters of Trainium chips that we're going to hopefully give them a chance to do so with Trainium3.
Operator:
The next question comes from the line of Mark Mahaney with Evercore ISI.
Mark Stephen Mahaney:
I want to ask about 2 topics, groceries and then how to think about head count in the future. And on groceries, I want to -- the perishables, I think last quarter, you talked about 70% or something of users had never purchased from perishables from Amazon before. Just talk about whether you -- I think you used the term, Game Changer, before. Does this mean that maybe we don't -- you no longer need to Amazon Fresh stores. You always had this DVD delivery van density advantage.
And have you kind of reached a point you think of scale and speed that you really can change people habit and really have them consider Amazon as one of their first grocery options? Do you really feel like you're at that point? And then secondly, just on the head count, some of the recent news. Just talk to us about how you think about head count going forward? Are you seeing -- is the level of efficiencies that you're getting from AI such that you can keep head count relatively flattish for the foreseeable future? Just talk about the pros and cons or the wins and losses in terms of that head count going forward?
Andrew Jassy:
Yes. So I'll start with grocery, Mark. We have a very large grocery business. If you look at our entire grocery business, if I don't even count Whole Foods Market and Fresh, in the last 12 months to over $100 billion of gross merchandising sales, which would make us a top 3 grocery in the U.S. A good chunk of it is a lot of the items that you'd find in the middle aisle so consumables and canned goods and pet food and health and beauty, very significant and continues to grow at a very good clip.
But then we also have Whole Foods Market, which is the pioneer in organic foods, which is also growing at a faster clip than most grocery companies with an attractive trajectory on profitability, and we'll expand our Whole Foods physical presence over the coming years here. And I'm also very excited about this new concept, daily shop that we have, which is a smaller version of Whole Foods in urban settings, which we have 3 that we've launched that are off to very good starts that you should expect to see more of as well. And we have always been -- as you referenced, we've talked a lot about having a larger mass physical presence.
And we continue to experiment with various formats. But the one that we are most excited about is what you referenced, which is the ability to provide perishable groceries with same-day deliveries. And if you think about how many of our customers are buying from us multiple times a week and who are buying things like shampoo or detergent or paper cups or water, where the ability to add milk and eggs and yogurt and other perishables to their order and have it live in the same shop in cart and then show up a few hours later, is very compelling.
And we started with a few markets about a year ago, and we were really taken aback at the adoption, not just the number of people that started buying perishables from us very quickly but how often they came back downstream to buy perishables and groceries from us in the future. And so we've now expanded that to 1,000 cities around the U.S. and will be in 2,300 by the end of the year. And it's really changing the trajectory and the size of our grocery business. And I also believe that this many years tradition of the weekly stock up grocery stock up is changing. And I think we're a big part of that.
And I think there's a lot of potential there for the grocery side. It doesn't mean that we won't continue to experiment with other physical formats, but we're on to something very significant with what we're doing with perish both from our same-day facilities. And then on your head count question, what I would tell you is the announcement that we made a few days ago was not really financially driven and it's not even really AI-driven, not right now, at least. It really -- its culture.
And if you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers. And when that happens, sometimes without realizing that you can weaken the ownership of the people that you have who are doing the actual work and who own most of the 2-way door decisions, the ones that should be made quickly and right at the front line, and it can lead to slowing you down.
And as a leadership team, we are committed to operating like the world's largest start-up. And that means removing layers. It means increasing the amount of ownership that people have, and it means inventing and moving quickly. And I don't know if there's ever been a time in the history of Amazon or maybe business in general with the technology transformation happening right now, where it's important to be lean, it's important to be flat, and it's important to move fast, and that's what we're going to do.
Operator:
And the next question comes from the line of Eric Sheridan with Goldman Sachs.
Eric Sheridan:
Wanted to know, Andy, if you could reflect on the opportunity that's continuing to present itself in terms of rolling out more robotics and automation and the broader theme of physical AI across your operations? And how should we be thinking about that as a driver of potential efficiencies, but also as a driver of the ability to possibly reinvest back in the business over the long term?
Andrew Jassy:
Robotics is a very substantial area of investment for us. We have over 1 million robots in our fulfillment network at this point. And I would say that while that's significant, we have a lot of invention in flight. So I expect that we'll have more over a period of time. Robotics are very important for us and for our customers and for our teammates because they improve safety, they boost productivity, they increased speed, and they let our human teammates focused on problem solving and what they do best. And we expect that our people remain at the heart in the center of our fulfillment network as they have from when we first started working the robotics.
And we expect that over time, we will have a fulfillment network where robots and humans complement each other and work together. But I think you're going to continue to see us advance invest very significantly in robotics. It's going to help on the safety, the productivity, the speed and ultimately some of the cost pieces, which will allow us to continue to improve the customer experience.
Operator:
And the next question comes from the line of John Blackledge with TD Cowen.
John Blackledge:
How does Amazon think about agentic commerce going forward? And how do you think Amazon will serve customers using agents to purchase goods on Amazon in the future?
Andrew Jassy:
I'm very excited about -- and as a business, we're very excited about in the long term the prospect of agentic commerce. And it has a chance to be good for customers has a chance to be really good for e-commerce. And I think if you're -- if you know what you want to buy, there are a few experiences that are better than coming to Amazon. But if you don't know what you want, it's a physical store with a physical salesperson still has some advantages. Obviously, lots of people do it on Amazon all the time. But you very often want to ask questions and help get help narrowing what you're going to look for.
And as you keep asking new questions, having a whole bunch of different options presented to you. And I think AI and agentic commerce are going to change the experience online where that experience where you're narrowing what you want when you don't know is going to get better online than it even is in physical environments. Now we obviously have our own efforts here in agentic commerce. We have Rufus, which I talked about in my opening comments, which is continuing to get better and better and used more broadly. And we have features like Buy for Me where we will surface on Amazon, even items that we don't stock that other merchants have.
And then if customers want us to go and buy it for them on those merchants websites, we will do that. And both of those have been successful for us. But we're also having conversations with and expect over time to partner with third-party agents. And I think that it reminds me in some ways of the beginning of search engines many years ago being sources of discovery for commerce. And you had to kind of figure out the right way to work together. And today, search engines are a very small part of our referral traffic and third-party agents are a very small subset of that. But I do think that we will find ways to partner.
We have to find a way, though, that makes the customer experience good. Right now, I would say the customer experience is not -- there's no personalization. There's no shopping history. The delivery estimates are frequently wrong. The prices are often wrong. So we've got to find a way to make the customer experience better and have the right exchange value. But I do think that the exciting part of this and the promise is that AI and agentic commerce solutions are going to expand the amount of shopping that happens online.
And I think that's really good for customers, and I think it's really good for Amazon because at the end of the day, you're going to buy from the outfit that allows you to have the broadest selection, great value and continues to deliver for you very quickly and reliably. And I think that bodes well for us.
Operator:
And our final question comes from the line of Colin Sebastian with Baird.
Colin Sebastian:
I guess first on AWS, following up there. How much of this acceleration is driven by core infrastructure versus AI workload monetization? And I think part of it is trying to understand how important newer services like AgentCore are becoming and bringing enterprises to AWS to build agents? And then I guess, secondly, regarding the acceleration in advertising, if you could potentially disaggregate the core advertising contribution versus DSP and Prime video. That would be helpful as well.
Andrew Jassy:
I'll start on the AWS side, we are seeing -- we're really pleased with the results from this quarter, 20% year-over-year on a annualized run rate of $132 billion is unusual. And we have momentum. You can see it. And we see the growth in both our AI area, where we see it in inference. We see it in training. We see it in the use of our Trainium custom silicon. Bedrock continues to grow really quickly. SageMaker continues to grow quickly. And I think that the number of companies who are working on building agents is very significant. I do believe that a lot of the value that companies will realize over time and AI will come from agents.
And I think that building agents today is still harder than it should be. You need tools to make it easier, which is why we built strands, which is an open source capability that lets people build agents from any model that they can imagine. But even more so, when you talk to enterprises or companies that care a lot about security and scale. They're starting to build agents, and they don't really feel like they've got -- they've had building blocks that allow them to have the type of secure scalable agents that they need to bet their businesses and their customer experience and their data.
And that's why -- that was really the inspiration behind AgentCore was to build another set of primitive building blocks like we built in the early days of AWS, where it was compute and storage and database. We defined a set of building blocks that you needed to be able to deploy agents securely and scalably that we provide in AgentCore. And then when we talk to our customers, it really resonates. There is not anything else like it, it's changing their time frame and their receptivity to building agents, and it's very compelling for them.
So I do think the combination of what we're doing to enable agents to be built and run securely and scalably as well as some of the agents that we're building ourselves that our customers are excited about are compelling for them. And I think the other place we see a lot of growth in AWS also is just the number of enterprises who are -- who have gotten back to moving from on-premises infrastructure to the cloud. And we continue to earn the lion's share of those transformations. And I look at the momentum we have right now, and I believe that we can continue to grow at a clip like this for a while.
I think on the advertising side, that is also an area where I think collectively, we feel very pleased about the progress. Every single one of our advertising offerings this quarter grew in a meaningful way. I think there's a few things going on for us. We have what I think of as a pretty unusual full funnel offering.
And if you look at the top of the funnel, which typically tends to be awareness building and broad scale to be able to use our own Prime Video and our live sports capabilities as well as going all the way down to the bottom of the funnel at point of sale being able to use sponsored products, that's -- most people don't have a full funnel offering as robust as that. And then when you layer on top of it, the combination of the audience curation and development we can do, along with the advantage measurement, it just all leads to a return on advertising spend is very unusual.
And I think there are multiple places where we can expect to continue to grow. One is in our stores business. I still think if you look at the worldwide market segment share of retail, still 80% to 85% of it lives in physical stores. And that equation is going to flip over time. And I think AI is going to only accelerate that. So I think we have an opportunity -- a significant opportunity still in our existing stores. And then I think video, we've only been at this for a little bit of time, but it's already a very large amount of advertising revenue, and we're still relatively early stage.
I think that will continue to be a big area of growth. And then as you referenced, the amount -- their demand-side platform or Amazon DSP, that is growing really quickly as well. And some of it had to do with the fact that we had some features. We always had a number of the core components people wanted around some of our properties, the measurement capabilities, Amazon Marketing Cloud, but we lack some features for a while as we were building out our DSP that customers told us mattered and the team over the last 20 months have closed those gaps in a very significant way so that now people feel like our DSP is fully featured.
And then you look at some of the partnerships that we've done, the Roku partnership gives us the largest connected TV footprint in the U.S. And you layer on top of that, what we've recently done in providing our DSP customers, the opportunity to integrate with the ad inventory in Netflix and Spotify and SiriusXM, it's powerful. And so we are growing very quickly on the demand side platform. So very optimistic about what we're doing there. We've continued work to do, obviously, but I don't think we're close to being able to grow there.
Operator:
Thanks for joining us on the call today and for your questions. A replay will be available on our Investor Relations website for at least 3 months. We appreciate your interest in Amazon and look forward to speaking with you again next quarter."
Meta Platforms (META),Q3,2025,Meta Platforms (META) Q3 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/10/29/meta-platforms-meta-q3-2025-earnings-call-transcript/,"DATE
Wednesday, Oct. 29, 2025, at 4:30 p.m. ET
CALL PARTICIPANTS
Chief Executive Officer — Mark Zuckerberg
Chief Financial Officer — Susan Li
Need a quote from a Motley Fool analyst? Email pr@fool.com
RISKS
Susan Li stated, ""we cannot rule out the commission imposing further changes to that offering that could have a significant negative impact on our European revenue as early as this quarter.""
Susan Li noted, ""In The US, a number of youth-related trials are scheduled for 2026. And may ultimately result in a material loss.""
The tax rate reached 87% in Q3 2025 due to a one-time noncash reduction in deferred tax assets, with Susan Li cautioning this ""was unfavorably impacted"" and explaining the elevated rate was not recurring.
TAKEAWAYS
Daily Active Users
-- 3.5 billion people used at least one company-owned app per day, according to Mark Zuckerberg in Q3 2025, reflecting continued community expansion.
Instagram Monthly Actives
-- Instagram had 3 billion monthly active users; Threads daily active users surpassed 150 million, reflecting strong engagement in Q3 2025, signaling good momentum across our other apps.
Family of Apps Revenue
-- $50.8 billion, up 26% year-over-year, as reported by Susan Li.
Advertising Revenue (Family of Apps)
-- $50.1 billion, up 26% year-over-year, or 25% on a constant currency basis; average price per ad rose 10% year-over-year, driven by increased advertiser demand largely driven by improved ad performance.
Ad Impressions
-- Up 14% year-over-year; ""Impression growth was healthy across all regions driven by engagement and user growth particularly on video surfaces.""
Family of Apps Other Revenue
-- $690 million, a 59% increase, underpinned by WhatsApp paid messaging and Meta Verified subscriptions.
Reality Labs Revenue
-- $470 million, up 74% year-over-year, due to retail partners stocking up on Quest headsets ahead of the holiday season, and strong AI glasses revenue.
Consolidated Total Revenue
-- $51.2 billion, up 26% or 25% on a constant currency basis.
Total Expenses
-- $30.7 billion, up 32% compared to the prior year; Growth was driven by higher legal costs, technical hires -- especially in AI -- and increased infrastructure operating costs.
Employee Count
-- Over 78,400, up 8% year-over-year, driven by hiring in priority areas of monetization, infrastructure, Reality Labs, Meta Superintelligence Labs, as well as regulation and compliance.
Operating Income
-- $20.5 billion, yielding a 40% operating margin.
Interest and Other Income
-- $1.1 billion, primarily from unrealized gains on our marketable equity securities.
Tax Rate
-- 87% due to a one-time noncash reduction in deferred tax assets that we no longer anticipate using under new US tax law; excluding this charge, the tax rate would have been 14% and net income would have been $18.6 billion, or $7.25 per share.
Net Income
-- $2.7 billion, or $1.05 per share as reported, including the tax adjustment.
Capital Expenditures
-- $19.4 billion, reflecting server, data center, and network infrastructure investments.
Free Cash Flow
-- Free cash flow was $10.6 billion.
Shareholder Returns
-- $3.2 billion repurchased in Class A stock and $1.3 billion paid in dividends.
Cash and Marketable Securities
-- $44.4 billion on hand; $28.8 billion in debt.
Q4 2025 Revenue Guidance
-- Anticipated total revenue in the range of $56 billion to $59 billion for Q4 2025, with about a 1% FX tailwind; The forecast includes continued strong ad revenue growth partially offset by lower year-over-year Reality Labs revenue.
Full-Year 2025 Expense Outlook
-- Updated to $116 billion to $118 billion (22%-24% growth), up from $114 billion to $118 billion.
2025 CapEx Outlook
-- Raised to $70 billion to $72 billion from $66 billion to $72 billion.
2026 Spend Outlook
-- ""CapEx dollar growth will be notably larger in 2026 than 2025,"" and ""total expenses will grow at a significantly faster percentage rate in 2026 than 2025,"" according to Susan Li, referring to Meta's consolidated expenses, mainly due to ""infrastructure costs including incremental cloud expenses and depreciation,"" with employee compensation as the second-largest contributor.
AI and Ads Automation Metrics
-- The annual run rate for AI-powered ad tools has surpassed $60 billion; Reels' annual run rate is over $50 billion; Advertisers using Advantage Plus for lead campaigns saw a 14% lower cost per lead on average.
Product Engagement
-- Time spent on Facebook increased 5% and on Threads by 10%; video time spent on Instagram was up more than 30% year-over-year, according to Mark Zuckerberg.
SUMMARY
Meta Platforms
(
META
+5.63%
)
a reported robust double-digit top-line growth in Q3 2025, with notable gains in global user engagement and video monetization year-over-year. Management upgraded forward capital expenditure and expense guidance, citing escalating infrastructure and AI compute requirements as central drivers for 2025 and 2026. Aggressive hiring in technical and AI roles continued, while automation in ads and messaging segments showed expanding adoption and improved advertising efficiency.
but explicitly guided for lower Reality Labs revenue, reflecting product cycle timing and holiday demand shifts.
Reality Labs' growth benefited from retail pre-purchases and AI glasses, with headwinds in Q4 directly linked to product release cycles instead of ongoing demand.
The transition to new US tax regulations resulted in a substantially elevated tax rate, but management expects a 12%-15% tax rate in Q4 and ongoing cash tax savings.
Expansion of Meta's AI-driven Advantage Plus and Lattice model architectures continued to deliver lower costs per lead, improved conversions year-over-year, and further consolidation of ads ranking models, supporting incremental advertising revenue gains.
Management emphasized the likelihood of further upward pressure on expenses as they front-load data center and compute investments ""to be prepared for the most optimistic cases,"" according to Mark Zuckerberg in the AI cycle.
EU regulatory action and upcoming US youth-related legal proceedings were directly highlighted by management as potential sources of significant financial risk.
Mark Zuckerberg underscored the runway for AI improvements, noting persistent demand to ""absorb a very large amount"" of compute for both core business and new AI products, and that continued scaling is central to sustaining future growth.
Management confirmed that on-balance sheet and off-balance sheet financing, such as the Blue Owl joint venture, have been designed to provide flexible, long-term infrastructure capacity and will impact capital expenditure recognition going forward.
INDUSTRY GLOSSARY
Lattice
: Meta’s unified ads model architecture that consolidates smaller, specialized models into larger, generalizable models for improved ad ranking and marketing performance.
Advantage Plus
: Meta’s automated campaign solution that optimizes ad audience, placement, and budget allocation across objectives, providing end-to-end automation for sales, app, or lead campaigns.
Meta Superintelligence Labs (MSL)
: Meta’s advanced AI research group focused on developing next-generation artificial intelligence models and infrastructure.
Reality Labs
: Meta’s segment dedicated to augmented reality, virtual reality, and wearable hardware and software products.
Full Conference Call Transcript
Mark Zuckerberg:
We had another strong quarter with 3.5 billion people using at least one of our apps every day. Instagram hit a major milestone with 3 billion monthly actives. And we're seeing good momentum across our other apps as well, including Threads, which recently passed 150 million daily actives and remains on track to become the leader in its category. I am very focused on establishing Meta as the leading frontier AI lab. Building personal superintelligence for everyone, delivering the app experiences and computing devices that will improve the lives of billions of people around the world. Our approach of advancing open-source AI means that when Meta innovates, everyone benefits. Meta Superintelligence Labs is off to a strong start.
I think that we've already built the lab with the highest talent density in the industry. We're heads down developing our next generation of models and products. And I'm looking forward to sharing more on that front over the coming months. We're also building what we expect to be an industry-leading amount of compute. Now there's a range of timelines for when people think that we're gonna get superintelligence. Some people think that we'll get there in a few years. Others think it will be five, seven years, or longer. I think that it's the right strategy to aggressively front-load building capacity so that way we're prepared for the most optimistic cases.
That way, if superintelligence arrives sooner, we will be ideally positioned for a generational paradigm shift in many large opportunities. If it takes longer, then we'll use the extra compute to accelerate our core business, which continues to be able to profitably use much more compute than we've been able to throw at it. And we're seeing very high demand for additional compute both internally and externally. And in the worst case, we would just slow building new infrastructure for some period while we grow into what we build. The upside is extremely high for both our existing apps and new products and businesses that are becoming possible to build.
Across Facebook, Instagram, and Threads, our AI recommendation systems are delivering higher quality and more relevant content, which led to 5% more time spent on Facebook in Q3 and 10% on Threads. Video is a particular bright spot. With video time spent on Instagram up more than 30% since last year. And as video continues to grow across our apps, Reels now has an annual run rate of over $50 billion. Improvements in our recommendation systems will also become even more leveraged as the volume of AI-created content grows. Social media has gone through two eras so far. First was when all content was from friends, family, and accounts that you followed directly.
The second was when we added all of the creator content. Now as AI makes it easier to create and remix content, we're going to add yet another huge corpus of content on top of those. Recommendation systems that understand all this content more deeply and show you the right content to help you achieve your goals are going to be increasingly valuable. Our ads business continues to perform very well largely due to improvements in our AI ranking systems as well. This quarter, we saw meaningful advances from unifying different models into simpler, more general models, which drive both better performance and efficiency.
And now the annual run rate going through our completely end-to-end AI-powered ad tools has passed $60 billion. And one way that I think about our company overall is that there are three giant transformers that run Facebook, and ads recommendations. We have a very strong pipeline of lots of ways to improve these models by incorporating new AI advances and capabilities. And at the same time, we are also working on combining these three major AI systems into a single unified AI system that will effectively run our family of apps and business, using increasing intelligence to improve the trillions of recommendations that we'll make for people every day.
I'm also very excited about the new products that we're going to be able to build. More than a billion monthly actives already use Meta AI, and we see usage increase as we improve our underlying models. I'm very excited to get a frontier model into Meta AI. I think that the opportunity there is very large. The same goes for our business AI. Every day, people have more than 1 billion active threads with business accounts across our messaging platforms ranging from product questions to customer support. Our business AIs will enable tens of millions of businesses to scale these conversations and improve their sales at low cost.
And the better our models get, the better this is gonna work for all businesses. This quarter, we also launched Vibes, which is the next generation of our AI creation tools and content experiences. Retention is looking good so far. And its usage keeps growing quickly week over week. I'm looking forward to ramping up the growth of Vibes over the coming months. More broadly, I think that Vibes is an example of a new content type enabled by AI and I think that there are more opportunities to build many more novel types of content ahead as well.
As our new models become ready, I'm looking forward to starting to show everyone some of the new kinds of products that we're working on. At Connect, we announced our 2025 line of AI glasses. The response so far has been great. The new Ray-Ban Meta glasses and Oakley Meta Vanguards are both selling well. The people love the improved battery life, camera resolution, new AI capabilities, and the great design. And there's our new Meta Ray-Ban display glasses, our first glasses with a high-resolution display and the Meta Neural Band to interact with them. They sold out in almost every store within 48 hours, with demo slots fully booked through the end of next month.
So we're gonna have to invest in increasing manufacturing and selling more of those. This is an area where we are clearly leading and have a huge opportunity ahead. Taking a step back, if we deliver even a fraction of the opportunity ahead for our existing apps, and the new experiences that are possible. Then I think that the next few years will be the most exciting period in our history. We've got a lot to do, but we're making real progress delivering strong business results building the talent density and infrastructure needed for the next era, and leading the way on AI devices that will define the next computing platform.
I'm proud of how our teams are rising to the challenge, and I'm grateful for their dedication, hard work, and creativity. As always, thank you all for being a part of this journey with us. And now here's Susan. Thanks, Mark, and good afternoon, everyone.
Susan Li:
Let's begin with our segment results. All comparisons are on a year-over-year basis unless otherwise noted. Our community across the family of apps continues to grow, and we estimate more than 3.5 billion people use at least one of our family of apps on a daily basis in September. Q3 total family of apps revenue was $50.8 billion, up 26% year over year. Q3 family of apps ad revenue was $50.1 billion, up 26% or 25% on a constant currency basis. Q3, the total number of ad impressions served across our services increased 14%. Impression growth was healthy across all regions driven by engagement and user growth particularly on video surfaces.
The average price per ad increased 10% year over year, benefiting from increased advertiser demand largely driven by improved ad performance. This was partially offset by impression growth, particularly from lower monetizing regions and surfaces. Family of apps other revenue was $690 million, up 59%. Driven by WhatsApp paid messaging revenue growth, as well as Meta verified subscriptions. Within our Reality Labs segment, Q3 revenue was $470 million, up 74% year over year. The significant year-over-year growth in Q3 was partly due to retail partners stocking up on Quest headsets ahead of the holiday season. We did not have a similar benefit in the third quarter of last year since our Quest 3s headset launched in 2024.
Aside from this, strong AI glasses revenue also contributed to revenue growth Q3. Moving now to our consolidated results. Q3 total revenue was $51.2 billion, up 26% or 25% on a constant currency basis. Q3 total expenses were $30.7 billion, up 32% compared to last year. Year-over-year expense growth accelerated 20 percentage points from Q2. Due primarily to three factors. First, legal-related expense growth was higher than in Q2. Due to charges we recorded in the third quarter as well as us lapping a period of accrual reversals in the third quarter a year ago. Second, employee compensation growth accelerated, driven by technical hires, particularly AI talent.
Finally, growth in infrastructure costs accelerated due to increased infrastructure operating costs associated with our expanded data center fleet. Depreciation on our incremental CapEx spend, and third-party cloud spend. We ended Q3 with over 78,400 employees, up 8% year over year. Driven by hiring in priority areas of monetization, infrastructure, Reality Labs, Meta Superintelligence Labs, as well as regulation and compliance. Third quarter operating income was $20.5 billion, representing a 40% operating margin. Q3 interest and other income was $1.1 billion driven primarily by unrealized gains on our marketable equity securities.
Our tax rate for the quarter was 87% which was unfavorably impacted by a one-time noncash reduction in deferred tax assets that we no longer anticipate using under new US tax law. Our tax rate would have been 14% excluding this charge. Although the transition to the new US tax law resulted in an accounting charge in the third quarter, we continue to expect we will recognize significant cash tax savings for the remainder of the current year and future years, under the new law, and this quarter's charge reflects the total expected impact from the transition to the new US tax law. Net income was $2.7 billion or $1.05 per share.
Excluding the one-time tax charge, our net income and EPS would have been $18.6 billion and $7.25 share respectively. Capital expenditures including principal payments on finance leases were $19.4 billion, driven by investments in servers data centers, and network infrastructure. Free cash flow was $10.6 billion. We repurchased $3.2 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders. We ended the quarter with $44.4 billion in cash and marketable securities and $28.8 billion in debt. Turning now to the business outlook. There are two primary factors that drive our revenue performance. Our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time.
On the first, daily actives continue to grow year over year across Facebook, Instagram, and WhatsApp. We're continuing to see improvements to our products and recommendations, drive incremental engagement with year-over-year growth in global time spent accelerating On both Facebook and Instagram in Q3. In The US, overall time spent on Facebook and Instagram grew double digits year over driven by continued video strength as well as healthy growth in non-video time on Facebook. The engagement gains continue to be driven by product work and ongoing improvements to our recommendation systems, as we optimize our model architectures, implement advanced modeling techniques, and integrate more signals about people's interests. Also continue to focus on increasing the freshness of recommended content.
On Facebook, our systems are now surfacing twice as many reels published that day. At the start of the year. Looking to 2026, we expect to advance our recommendation systems across several dimensions. On Instagram, one focus is evolving our systems to surface content across a broader set of topics that cater to the diverse interests of each person. This follows a similar approach we've implemented on Facebook that has driven good results. We also expect to make significant progress on our longer-term ranking innovations in 2026.
We're seeing promising new results from our research efforts to create foundational ranking models and expect the new model innovations we're developing as part of this will enable us to significantly scale up the amount of data and compute we use to train our recommendation models in 2026. Yielding more relevant recommendations. Another large focus next year is leveraging LLMs to improve content understanding. We expect this is going to enable our systems to more precisely label the keywords and topics within videos and posts, which will allow our systems to both develop deeper intuition about a person's interests and retrieve the content. That matches them. Finally, we're making good progress with Meta AI and Threads.
The number of people using Meta AI across our family of apps continues to grow. And we're increasingly leveraging first-party content into Meta AI results with the majority of Meta AI's responses to Facebook deep dive queries in The US now showing related reels. We're also seeing a lot of traction with media generation. People have created over 20 billion images using our products, And since launching Vibes within Meta AI in September, we've seen media generation in the app increase more than tenfold. On Threads, we see strong growth in both daily actives and the depth of engagement as we continue to improve recommendations.
The ranking optimizations we made in Q3 alone drove a 10% increase in time spent on Threads. We also continue to ship new features, including launching direct message in Q3, so anyone on Threads can now message one another within the app. Now to the second driver of our revenue performance. Increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to refine ad supply across each of our major within Facebook and Instagram to better deliver ads at the time and place they are most relevant to people. Longer term, we have exciting ads supply opportunities on both Threads and WhatsApp status.
Ads are now running globally in feed on Threads, and we're following our typical monetization playbook, of optimizing the ads formats and performance before we ramp supply. Within WhatsApp status, we're continuing to gradually introduce ads. And expect to complete the rollout next year. The second part of increasing monetization efficiency is improving marketing performance. Advancing our ad systems remains a critical aspect of this work. And we are driving performance gains through ongoing improvements in our larger scale ads ranking models. For example, we continue to broaden the adoption of Lattice, our unified model architecture. In Q3, we rolled out Lattice to app ads which drove a nearly 3% gain in conversions for that objective.
Since introducing Lattice back in 2023, along with other back-end improvements, we have now cut the number of ads ranking in recommendation models by approximately 100. As we consolidated smaller and more specialized models into larger ones that use the lattice architecture, generalize learnings across surfaces and objectives. We continue to observe performance improvements as we combine models and expect to drive additional gains as we consolidate another 200 models over the coming years, into a smaller number of highly capable models. In addition to advancing our foundational ads models, we're innovating on our runtime models we use downstream of them for ads inference.
For example, we began piloting a new runtime ads ranking model in Q3 that leverages more compute and data than our prior models to select more relevant ads. In testing, we've seen this new model drive a more than 2% lift in conversions on Instagram. We also significantly improved performance of Andromeda in Q3, by combining models across retrieval and early stage ranking into a single model. Driving a 14% increase in ads quality on Facebook surfaces. Within our ads products, we're seeing continued momentum, which Advantage Plus. In Q3, we completed the rollout of our streamlined campaign creation flow for advantage plus lead campaigns.
So now advertisers running sales, app, or lead campaigns have end-to-end automation turned on from the beginning. Allowing our systems to look across our platform to optimize performance by automatically choosing criteria, like who to show the ads to, and where to show them. The annual run rate of revenue running through our end-to-end automated solutions has now reached $60 billion following the implementation of the new streamlined creation flow. As we continue to see more advertisers leverage the performance benefits of our solutions.
Within our advantage plus creative suite, the number of advertisers using at least one of our video generation features was up 20% versus the prior quarter as adoption of image animation and video expansion continues to scale. We've also added more generative AI features to make it easier for advertisers to optimize their ad creatives and drive increased performance. In Q3, we introduced AI-generated music. So advertisers can have music generated for their ad that aligns with the tone and message of the creative. Finally, business messaging remains a significant opportunity for us. We're seeing strong growth across our portfolio of solutions. Including with click to WhatsApp ads. Which grew revenue 60% year over year in Q3.
We're also making good progress on our business AI efforts. We've been focused on building a turnkey AI that helps businesses generate leads and drive sales. We've been opening access in recent months to more businesses within our initial test markets, The Philippines and Mexico, and have seen strong usage with millions of conversations between people and business AIs taking place since July. This month, we expanded availability within WhatsApp and to all eligible businesses in Mexico and The Philippines, respectively. In The US, we're also starting to roll out the ability for merchants to add their business AIs to their website so we can support the full sale funnel from ad to purchase.
Next, I would like to discuss our approach to capital allocation. Our primary focus is deploying capital to support the company's highest order priorities, including developing leading AI products models and business solutions. As we make significant investments in infrastructure to support this work, we are focused on preserving maximum long-term flexibility to ensure we can meet our future capacity needs while also being able to respond to how the market develops in the years ahead. We're doing so in several ways, including staging data center so we can spring up capacity quickly in future years as we need it, as well as establishing strategic partnerships that give us option value for future compute needs.
The strong financial position cash generation of our business enable us to make these investments while also accessing additional pools of cost-efficient capital. Moving to our financial outlook. We expect fourth quarter 2025 total revenue to be in the range of $56 billion to $59 billion. Our guidance assumes foreign currency is an approximately 1% tailwind to year-over-year total revenue growth. Based on current exchange rates. Our outlook reflects an expectation for continued strong ad revenue growth Partially offset by lower year-over-year Reality Labs revenue in Q4.
The anticipated reduction in Reality Labs revenue is due to us lapping the introduction of QUEST 3s in Q4 of last year, as well as retail partners procuring Quest headsets during Q3 of this year to prepare for the holiday season. Which were recorded as revenue in the third quarter. Turning to the expense and CapEx outlooks. I'll first start with 2025 before providing some commentary on our planning for 2026. We expect full year 2025 total expenses to be in the range of $116 billion to $118 billion updated from our prior outlook of $114 a $118 billion and reflecting a growth rate of 22% to 24% year over year.
We currently expect 2025 capital expenditures including principal payments on finance leases, to be in the range of $70 to $72 billion increased from our prior outlook of $66 to $72 billion. Onto tax. Absent any changes to our tax landscape, we expect our fourth quarter 2025 tax rate to be 12% to 15%. Turning now to 2026. We are at an exciting point for our company where we have continued runway to improve our core services today as well as the opportunity to build new AI-powered experiences and services that will transform how people engage with our products in the future.
We expect the set of investments we're making within our ads and organic engagement initiatives next year will enable us to continue to deliver strong revenue growth in 2026. While our progress on AI models and products will position us to capitalize on new revenue opportunities in the years to come. A central requirement to realizing these opportunities is infrastructure capacity. As we have begun to plan for next year, become clear that our compute needs have continued to expand meaningfully. Including versus our own expectations last quarter. We are still working through our capacity plans for next year.
But we expect to invest aggressively to meet these needs both by building our own infrastructure and contracting with third-party cloud providers. We anticipate this will provide further upward pressure on our CapEx and expense plans next year. As a result, our current expectation is that CapEx dollar growth will be notably larger in 2026 than 2025. We also anticipate total expenses will grow at a significantly faster percentage rate in 2026 than 2025, with growth primarily driven by infrastructure costs including incremental cloud expenses and depreciation. Employee compensation costs will be the second largest contributor to growth. As we recognize a full year of compensation for employees hired throughout 2025, particularly AI talent.
And add technical talent in priority areas. Finally, we continue to monitor legal and regulatory matters. Including the increasing headwinds in The EU and The US that could significantly impact our business and financial results. For example, the EU, we continue to engage constructively with the European Commission on our less personalized ads offering. However, we cannot rule out the commission imposing further changes to that offering that could have a significant negative impact on our European revenue as early as this quarter. In The US, a number of youth-related trials are scheduled for 2026. And may ultimately result in a material loss. In closing, this was another good quarter for our business.
We have an exciting set of opportunities to continue improving our core business delivering innovative new experiences and services for the people and businesses using our products in the years to come. With that, Christa, let's open up the call for questions.
Krista:
Thank you. We will now open the lines for question and answer session. If you are streaming today's call, please mute your computer speakers. And your first question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.
Brian Nowak:
Thanks for taking my questions. I have a two for Susan. The first one, Susan, so the pipeline for core improvements to come in '26 with models and ad ranking models and more types of compute, seems very exciting and the infrastructure build seems sizable behind that. So, you help us a little understand some of the early quantifiable signals you're seeing on AB tests from some of these improvements to come that sort of make you most excited and give you confidence you're gonna get ROIC from all this CapEx? That's the first one. Second one is a little faster. How large is the Reality Labs revenue headwind in the 4Q guidance? Thanks.
Susan Li:
Thanks, Brian, for the question. I think your first question had a couple parts to it. So I'm gonna try to disaggregate those parts and let me know if this addresses what you're getting to. I will say that the growth in 2026 CapEx relative to 2025 comes from growth in each of the core areas, MSL, CoreAI, as well as non-AI spend. So all of those areas are growing, but these MSL AI needs are growing the most. In terms of the core AI pipeline, you know, I think we talked about, last year, we were going into the 2025 budget process, we had a road map of resource investments across both headcount and compute.
That we thought would pay off, you know, in 2026. And it's really a very broad range of sort of different ads ranking and performance efforts. And we're continuing to see that, you know, those have paid off through the course of the year. There is a long list of specific efforts, but one of the measures that we look at to monitor this is, you know, how are we driving ad performance, How are conversions growing? Conversions is a complex metric for us because advertisers optimize for so many different conversions. With different values. But when we control for that and look at value-weighted conversion rates, we're seeing very strong year-over-year growth and conversions continue.
Weighted conversions continue to grow faster than impressions. We also talked about some of the new model architecture over the course of the year and the degree to which the new model architecture is enabling us also to take advantage of having more data and more compute to drive ads performance. So we expect that's going to be a continued story in 2026. We are in fact at the beginning of our 2020 budgeting process now, and we, you know, see a similar list of revenue investments. That we you know, that we're excited to be able to invest in.
And so we think that's going to be a big part of our ability to continue to drive strong revenue performance throughout the year. On your second question, which is the Reality Labs revenue headwind. I don't think we have quantified the exact size of that. We expect that Q4 Reality Labs revenue will be lower than last year for a couple reasons that I alluded to. The biggest factor is we're lapping the introduction of Quest 3s in Q4 of last year, and we don't have a new headset in the market this year. We also recorded all of our holiday-related Quest 3s sales in Q4 2024 since the headset was launched in October 2024.
This year, we're recognizing some of those Quest 3s sales in Q3 as retail partners have procured Quest headsets in advance of the holiday season. We're still expecting significant year-over-year growth in AI glasses revenue in Q4 as we benefit from strong demand for the recent products that we've introduced, but that is more than offset by the headwinds to the Quest headsets.
Krista:
Your next question comes from the line of Doug Anmuth with JPMorgan. Please go ahead.
Doug Anmuth:
Great. Thanks for taking the question. I appreciate the strategy to front-load capacity for superintelligence. Can you just talk about your thought process and kind of triangulating the CapEx dollar growth and the significantly faster expense growth next year with core growth in the business and then the impact on earnings and free cash flow? And do you even do you have targets that we should be thinking about for cash on hand or net cash overall? Thanks.
Susan Li:
Thanks, Doug. We're right now, I would say, in the process of we're relatively early, actually, still in the process of putting together our budget for 2026. And it is on the on the side, a particularly, you know, dynamic process. We're certainly seeing that we wish we had more capacity today than we do. We would be able to put it towards good use. Certain not only with the MSL team, having more capacity, but we'd be able to put it towards good and ROI positive use in the core business as well.
So we're really trying to plan ahead not only to ensure that we have the capacity we need in 2026, but also to give ourselves sort of flexibility and option value to have the capacity that we think we could need in '27 and '28. So that said, you know, there are lots of moving pieces in the budget. It's not baked yet. It's still sort of in the process of coming together. We don't have, you know, specific targets to share.
But we do feel like, you know, our strategic priority is really making sure that we have the compute that we need to be well positioned to succeed at AI, you know, that's that's sort of the foremost priority as we're putting together the budget.
Mark Zuckerberg:
Yeah. I mean, I'll add a few thoughts on this too, although as Susan said, we're still working through the actual budget, and I think we'll typically have more to share on that early next year. But to date, we keep on seeing this pattern where we build some amount of infrastructure to what we think is an aggressive assumption and then we keep on having more demand to be able to use more compute, especially in the core business. In ways that we think would be quite profitable then we end up having compute for.
So I think that suggests that being able to make a significant larger investment here is very likely to be a profitable thing over some period. Because if the primary use of it is going to be to accelerate the AI research and the new AI work that we're doing and how that relates to both the core business and new products. But any compute that we don't need for that, we feel pretty good that we're going to be able to absorb a very large amount of that to just convert into more intelligence and better recommendations in our family of apps and ads in a profitable way. Now, I mean, it's, of course, possible to overshoot that.
And if we do, I mean, this is what I mentioned in comments, then you know, we see that there's just a lot of demand for other new things that we build internally, externally, like, almost every week. People come to us from outside the company asking us to, you know, stand up an API service or asking if we have different compute that they could get from us and we haven't done that yet. But, obviously, if you got to a point where you overbuilt, you could have that as an option.
And then you know, the kind of the very worst case would be that we effectively have just prebuilt for a couple of years, in which case, of course, there would be some loss and depreciation. But we'd grow into that and use it over time.
So my view on this is that rather than continuing to be constrained on CapEx and feeling in the core business like, we have significant investments that we could make that we're not able to make, that would be profitable, the right thing to do is to try to accelerate this to make sure that we have the that we need both for the AI research and new things that we're doing and to try to get to a different state on our compute stance on the core business. So kind of how I'm thinking about that overall. Of course, there's a lot of operational constraints too on what one can build. Right?
So we're basically trying to work through this all, and I think we'll have more to share in the coming months and over the course of next year. But I think that there's just a huge, huge amount of opportunities ahead here.
Krista:
Your next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.
Eric Sheridan:
Thanks so much for taking the question. Mark, wanted to reflect on some of your comments with respect to scaling towards superintelligence and bringing it back to consumer AI. Maybe reflect a little bit the signals you've gotten on the way consumers across family of apps interact with Meta AI today and how you think about scaling and exiting models from the superintelligence effort might change the utility and behavior around Meta AI in the years ahead? Thanks.
Mark Zuckerberg:
Yeah. I mean, a lot of people use Meta AI today. I mean, as I said in my comments upfront, more than a billion people who use it on a monthly basis. And what we see is that as we improve the quality of the model, primarily for post-training LAMA four at this point, we continue to see improvements in usage. So our view is that when we get the new models that we're building in MSL, in there and get, like, truly frontier models novel capabilities that you don't have in other places, then I think that this is just a massive latent opportunity. Right?
We know mean, I would guess that you know, Meta I think, has the best track record of any company out there of taking a new product that people love and getting it to billions of people in terms of usage. So I think that the ability to plug in leading models is going to I would predict lead to a very large amount of use of these things over the coming years. So I'm very excited about that in terms of new products. It's not just Meta AI as an I think that there are gonna be all kinds of new products around different content formats, and we're starting to see that with video and content creation.
But I think that there's gonna be a lot more like that I'm quite excited about. And then there are the business versions of all these too, like business AI. And then know, that's, of course, one part of the story is the new things that will be possible to build. Then the other part, is how more intelligent models are just gonna improve the core business. And improve the recommendations that we make across the family of apps and improve the recommendations in advertising. And I think there's just a as we've shown, there's sort of this very large amount of headroom and the opportunity there keeps growing as we as we are improving and optimizing the AI there.
And I think that really shows no sign of being near the end. I think that there's quite a bit more to do there. And know, like I said, in response to the last question, we are sort of perennially operating the family of apps and ads business in a compute starved state at this point, which is, on the one hand, sort of an odd thing to say given the compute that we've built up. But we really are, you know, taking a lot of the resources and using them to advance future things that we're doing.
And we think that there's a lot more compute that we could put towards these that would just unlock a huge amount of opportunity in the core business as well.
Krista:
Your question comes from the line of Mark Shmulik with Bernstein. Please go ahead.
Mark Shmulik:
Yes. Hi. Thanks for taking the questions. Susan, as you about the visibility into kind of the runway next year of continued ad performance and engagement improvements, How do you think about kind of the scale of those improvements versus kind of the progress we've seen over the last two years? And then, as you think about kind of the timing of some of these newer efforts coming out of Superintelligence Labs, is that anchoring to kind of an updated Frontier model on sometime next year, like, the right way for us to think about it? Or should we be looking at kind of progress from new products you're excited to see ship like Vibes? Thank you.
Susan Li:
Thanks, Mark. So on the sort of ads improvement side, you know, some of the innovations that we have been launching actually involve sort of improving our larger scale models. So we, you know, don't use our larger model architectures like JEM for inference, because their size and complexity would make it too cost prohibitive. The way that we drive performance from those models by using them to transfer knowledge to smaller lightweight models that are used at runtime. And then in addition to the foundation model work, we are working on advancing our inference models by developing new techniques and architectures that then allow us to scale up compute and complexity. An ROI positive way.
So, in general, you know, we obviously have a very large base of advertisers. There's a lot of demand liquidity, in the system. And even, you know, small scale improvements that we are able to make in terms of driving, you know, basis point improvements in the performance of ads or single digit, you know, increases in conversions relative to impressions in a given quarter, you know, off of a large base mean that we're really able to continue to grow the absolute dollars of revenue growth in a pretty meaningful way.
Krista:
Your next question comes from the line of Justin Post with Bank of America. Please go ahead.
Justin Post:
Actually, you.
Mark Zuckerberg:
Hey, Justin. Just give us one second. I think there was a second question that we would just wanna get to on MSL. Yeah. I mean, I'll keep it quick. I mean, I don't think we have any specific timing to announce certainly on the models or products, but I expect that you will see both. We expect to build novel models and novel products, and I'm excited to share more when we have it.
Krista:
Krista, Justin, please go ahead.
Justin Post:
Great. Thanks. So, Mark, you mentioned the prior two concepts. Cycles and obviously you've been able to generate very attractive margins on them. As we get into the AI cycle, obviously some concerns on the investment, but can you talk a little bit about how you're thinking about tools that could be coming out for users? I know there's some new competition And then secondly, how you think about margins in this context cycle? Any reason to think they would be different versus prior cycles? Thank you.
Mark Zuckerberg:
I think it's too early to really understand what the margin are gonna be for the for the new products that we build. I mean, I think certainly every each product has somewhat different characteristics, and I think we'll kind of understand how that goes over time. Mean, my general goal is to build a business that maximizes value for the people who use our products and maximizes profit not margin. So I think we'll kind of just try to build the best things that we can and to deliver the most value that we can for most people.
Krista:
Your next question comes from the line of Ross Sandler with Barclays. Please go ahead.
Ross Sandler:
Great. Hey, Mark. Some of the goals for competing AI labs are around achieving AGI or these other milestones that are kind of, like, out there and a little esoteric. How are you setting up your new team in terms of achieving those types of goals versus products that can generate revenue from Meta kinda right out of the gate. And is the goal that you had articulated to us previously around giving billions of people kind of a personal AI to use the still the direction of travel that you see, or is there you know, other things like kind of this vibe or Sora angle that, you know, you think are potentially important?
How should we think about, like, the overall direction? Thank you.
Mark Zuckerberg:
Sure. So the way that I think about this is that the research is going to enable new technological capabilities to exist. And then those capabilities can get built into all kinds of different products. So the ability to reason more intelligently is for example, very important across a large number of things. It would be useful for an assistant. It will also be useful in business AI. It will also be useful in the AI agent that we're building to help advertisers figure out what their campaigns are gonna be. It will also have implications for eventually how we do ranking and recommendations of people's feeds and make different decisions there. That's just one example.
I mean, certainly, the capability to be able to produce very high-quality good video is going to be useful for giving people new creative tools, It will help increase the amount of content inventory that can be shown in Instagram and Facebook, and therefore, should enable an increase in engagement there. It should help advertisers be able to create creative that will help us monetize better. So you can just go kind of down the list of capabilities that you'd expect.
I think each one will enable a bunch of different things, and I think the art of product development here is looking at the list of technology capabilities and figuring out what new products are gonna be useful and prioritizing those. But fundamentally, I would sort of expect this exponential curve in new technology capabilities are gonna become available. And the other thing that I expect is that I think being the best a given area will drive great returns rather than this is not like a check the box exercise of, like, okay. Can generate some kind of content and someone else can.
I think that, like, the company that is the best at each of these capabilities, think, will get a large amount of the potential value for doing that. So are lots of different capabilities to build. I'm not sure that any one company is gonna be the best at all of them. I doubt that's gonna be the case. But a lot of what we're trying to do is not like not kind of do some things that others have done. We're really trying to build novel capabilities, and I'm this high level because I'm not don't wanna necessarily, from a competitive or strategic perspective, get into what we're prioritizing.
But that hopefully gives you a sense of how we're thinking about what we're doing. We wanna be able to kind of build novel things, build them into a lot of our products, and then have the compute to scale them to billions of people. And we think that's gonna both show up in terms of new products keep being possible, and new businesses. And very significant improvements to the current business too.
Krista:
Your next question comes from the line of Mark Mahaney with Evercore ISI. Please go ahead.
Mark Mahaney:
Thanks. Can I just ask just a question on Meta AI and both product and the monetization path? So when you look at it, what you've seen that's most encouraging to you in terms of the adoption and the use of Meta AI? And then when you think about I know you generally like to roll out and then, you know, deepen engagement and then later think about monetization. Like, where do you think you are on that path now? Is it clear to you what the monetization options are? For Meta AI? You very much.
Mark Zuckerberg:
I mean, I think the most promising thing that we're seeing is one that we were able to build something that a large number of people use and I think that's valuable. Then secondly, that as we there is a clear correlation as we improve the models in ways that we think make them better. That people use them more. So that shows that we have a runway to basically be able to improve engagement and turn this into a product that's leading over time.
In terms of where we are on this, and we basically just did this huge effort to boot up Meta Superintelligence Labs and build what I am very proud of is, I think, the highest talent density lab in the industry at this point. There were a lot of really great researchers and infrastructure folks and data folks who are now a part of this effort, are who are focused on training the next generation of work and doing some really novel work. And when that is ready, I think that we will be able to plug that into a number of products that we're building, and I think that will be very exciting.
But I think that's really the next thing that we're looking at. And then from there, I think that these models will also improve monetization in all of the different ways that we've talked about so far in terms of improving engagement, improving advertising, helping advertisers engage.
I mean, there's the one opportunity that we just we usually talk about on these calls, but hasn't come up as much here is just the ability to make it so that advertisers are increasingly just gonna be able to give us a business objective and give us a credit card or bank account and like, have the AI system basically figure out everything else that's necessary, including generating video or different types of creative that might resonate with people that are personalized in different ways. Finding who the right customers are. All of the capabilities that we're building, I think, go towards improving all of these different things. So quite optimistic about that.
Krista:
Your next question comes from the line of Ronald Josey with Citi. Please go ahead.
Ronald Josey:
Great. Thanks for taking the question. This maybe dovetails perfectly off Mark, what you just talked about. And we heard a lot about end-to-end automation here, I think, reaching a $60 billion ARR wanted to hear about if you can talk to us more just about adoption rates amongst the and then maybe bigger picture, as you incorporate ranking recommendation changes like Andromeda or GEMS or Lattice, So talk to us how this automation is driving, call it, a higher ROI for advertisers overall as we bring it all together. Thank you.
Susan Li:
Yeah. So we've been sort of laying the continued brick by brick build of Advantage Plus and extending the of objectives that it applies to over time. And so in Q3, we completed the global rollout of the streamlined campaign creation flow for Advantage Plus lead campaigns. So now advertisers who are running sales app or lead campaigns have end-to-end automation turned on from the beginning. And, like, you know, the kind of application of the streamlined campaign creation flow for other objectives, this generally allows advertisers to optimize, and automate several aspects of the campaign setup process at once.
That includes things like audience selection, where to show the ad, how the budget gets paced and distributed across ad sets to drive the most efficient outcomes. And, you know, we see that Advantage Plus continues to drive performance gains. Advertisers who run lead campaigns using Advantage Plus are seeing a 14% lower cost per lead, on average than those who are not. And I would say that we think that there is still a lot of opportunity generally to grow adoption of Advantage Plus. A lot of advertisers only use our end-to-end automated solutions for a portion of their campaigns so we can grow share there.
And to capture that opportunity, we're focused on driving continued performance improvements and addressing some of the key use cases that we still need in order to grow adoption. We're also working to broaden adoption among advertisers who use one of our single-step automated solutions For example, advertisers who might only use a piece of it, like Advantage Plus Audiences, by helping them understand, the benefits of using more than one automated solution, at this the same time. So I would say, Advantage Plus is sort of ongoing platform by which we both continue to expand the feature set that is available in Advantage Plus.
And then expand the extensibility or the coverage of that feature set to the sort of the broader set of advertisers. You know, I think Mark, mentioned that the annual revenue run rate now for advertisers who are using these automated options is, you know, $60 billion. And, we see that there's room to continue growing that.
Krista:
Your next question comes from the line of Youssef Squali with Truist Securities. Please go ahead.
Youssef Squali:
Great. Thank you very much. Mark, on wearables in particular, do you think you'll be able to sell enough hardware to recoup your investment, or is that dependent on maybe creating new avenues for revenue from things like advertising services and commerce through that new computing platform? And if so, what are kind of the gating factors there? And then, Susan, how do you see the on-balance sheet versus off-balance sheet financing on of your AI initiatives? You've recently struck a deal with Blue Owl. The Louisiana data center. Is that part of the CapEx guide for '26? And if it's not, how significant will that weigh a funding be for Meta going forward?
And basically, would that slow down your CapEx growth past 2026? Thank you.
Mark Zuckerberg:
Can talk about wearables, then and Susan can jump in on the other part. So I know there are a few pieces here. One is that the work that on Ray-Ban Meta and the Oakley Meta product is going very well. I think yeah, I mean, at some point, if these continue going as well as it has been, then I think it will be a very profitable investment. I think that there's some revenue that we get from basically selling the devices. And then some that will come from additional services and from the AI on top of it.
So I think that there's a big opportunity Certainly, the investment here is not just to kind of build a just the device. It's also to build these services on top. Right now, a lot of people get the devices. For a range of things that don't even include the AI, though they like the AI. But I think over time, the AI is going to become the main thing that people are using them for, and I think that's gonna end up having a big business opportunity by itself.
But, you know, as products like the Ray-Ban Meta and Oakley Metas are growing, We're also gonna keep on investing in things like the more full field of view product form of the Orion prototype that we showed at Connect last year. So those things are obviously earlier in their curve towards getting to being a sustaining business. And our general view is that we wanna build these out to reach many hundreds of millions or billions of people. And the point at which we think that this is gonna be just an extremely profitable business.
Susan Li:
Youssef, to your second question, so the JV that we announced with BlueOwl is sort of an example of finding a solution that enabled us to partner with external capital providers to co-develop data centers in a way that gives us long-term optionality. Supporting our future capacity needs just given both the magnitude, but also uncertainty of what the capacity outlook in years looks like. In terms of how that is recognized as CapEx, our prior CapEx reflected a portion of the data center build cost prior to the joint venture being established. Going forward, the construction cost of the data center will not be recorded in CapEx as the data center is constructed.
We will contribute 20% of the remaining construction costs required, which is line with our ownership stake, and those will be recorded as other investing cash flows.
Krista:
Your last question comes from the line of Ken Gawrelski with Wells Fargo. Please go ahead.
Ken Gawrelski:
Thank you. Just one for me, please. Mark, as you think about with the hopefully a leading frontier model next year in hand, could you talk about where you think the value will accrue in this evolving ecosystem will be with the platforms Or do you think that this will be mostly the value will accrue to the scaled first-party applications? Thank you.
Mark Zuckerberg:
I guess I'm not exactly sure what you mean by platform versus application in this context. But I mean, I think that I mean, I think there's just a lot of value to create. With AI overall. So, I mean, clearly, you're seeing the people who are making the hardware, I mean, NVIDIA is doing an amazing job. Right? I think extremely well-deserved success. The cloud partners and companies are doing very well. I think that will likely continue. I think there's a huge opportunity there. But if you look at it today, the companies that are building apps, I mean, a lot of the apps are still relatively small. And I think that's obviously gonna be a huge opportunity.
And I think what we've seen overall is basically people take individual technology advances, and build them into products that then build either communities or other kinds of network effect and then end up being very sustaining businesses. And I think what we haven't really seen as much in the history of the technology industry is the rate of new capabilities being introduced. Because around each of these capabilities, you can build many new products that I think each will turn into interesting businesses. So yes, I don't know. I mean, I'm generally pretty optimistic about there being a very large opportunity.
But in terms of new things to build, think being able to build them and then scale them to billions of people is a huge muscle that Meta has developed, and I think we do very well. And I certainly think that's gonna deliver a huge amount of value.
Both in the core business for all the ways that we talked about, how it's gonna improve recommendations and the quality of the services as well as unifying the models together and so that way, when these systems are deciding what to show, they can just pull from a wider pool And that we've these are things that we've just seen over the you know, twenty plus years of running the company that they just deliver consistent wins, and we're gonna keep on being able to make the systems more general and smarter and make better recommendations for people and have a larger pool of inventory. And that is all gonna be great.
There's gonna be a lot of new things that I think we're gonna be able to take and scale to billions of people over time and build new businesses, whether that's advertising or commerce supported or people paying for it or different kinds of things. So yeah, it's I think it's pretty early, but I think we're seeing the returns in the core business. That's giving us a lot of confidence that we should be investing a lot more. And we wanna make sure that we're not under investing.
Kenneth Dorell:
Great. Thank you everyone for joining us today. We look forward to speaking with you again soon.
Krista:
This concludes today's conference call. Thank you for your participation and you may now disconnect."
Apple (AAPL),Q4,2025,Apple Q4 2025 Earnings Call Transcript,https://www.fool.com/earnings/call-transcripts/2025/10/31/apple-q4-2025-earnings-call-transcript/,"Date
Oct. 30, 2025 at 5:00 p.m. ET
Call participants
Chief Executive Officer — Timothy Donald Cook
Chief Financial Officer — Kevan Parekh
Senior Director, Investor Relations — Suhasini Chandramouli
Need a quote from a Motley Fool analyst? Email pr@fool.com.
Takeaways
Total revenue
-- $102.5 billion in revenue for the fourth quarter of fiscal 2025 (period ended Sept. 27, 2025), an 8% year-over-year increase, representing a September quarter record and an all-time revenue record for the fiscal year at $416 billion.
Services revenue
-- $28.8 billion in services revenue, up 15% year-over-year, setting an all-time record, with double-digit growth across most categories and the vast majority of the markets tracked.
Earnings per share (EPS)
-- $1.85 (adjusted), a September quarter record, up 13% year-over-year on an adjusted basis.
iPhone revenue
-- $49 billion in revenue, up 6%, achieving a September quarter record and growth in most major markets; iPhone active installed base reached an all-time high.
Mac revenue
-- $8.7 billion in revenue, up 13% year-over-year, driven by MacBook Air, with double-digit growth in emerging markets and nearly half of Mac buyers new to the product.
iPad revenue
-- $7 billion in revenue, flat, with over half of buyers new to the device and a September quarter record for upgraders.
Wearables, home and accessories revenue
-- $9 billion in revenue, flat, with growth in Apple Watch and AirPods offset by accessory declines from the prior year’s iPad launches.
Gross margin
-- 47.2% company gross margin, up 70 basis points sequentially, above guidance, driven by favorable mix; gross margin for products was 36.2%, up 170 basis points sequentially, and for services was 75.3%, down 30 basis points sequentially.
Operating expenses
-- Operating expenses were $15.9 billion, up 11% year-over-year, attributed mainly to R&D increases.
Net income
-- Net income was $27.5 billion, a September quarter record for the fourth quarter of fiscal 2025.
Operating cash flow
-- $29.7 billion in operating cash flow, a September quarter record.
Cash and marketable securities
-- $132 billion at quarter end, with net cash of $34 billion after debt and commercial paper changes.
Capital return
-- $24 billion returned to shareholders through $3.9 billion in dividends and equivalents and $20 billion in share repurchases.
Guidance for next quarter
-- Revenue growth forecasted at 10%-12%, with iPhone revenue expected to achieve double-digit year-over-year growth and gross margin anticipated in the 47%-48% range for the December quarter, including a $1.4 billion tariff impact.
AI investment
-- Noted significant, ongoing increases in AI-related R&D spend and infrastructure expansion, including the recent opening of a manufacturing plant in Houston for private cloud compute servers.
Dividend declaration
-- $0.26 per share cash dividend, payable Nov. 13, 2025, to shareholders of record as of Nov. 10, 2025.
Summary
Apple
(
AAPL
+0.28%
)
established all-time quarterly and annual revenue records for the fourth quarter and fiscal year 2025, driven by double-digit services growth and continued iPhone strength despite disclosed supply constraints. Management detailed broad-based sales expansion across developed and emerging markets, identified favorable product mix as a primary margin driver, and highlighted strong customer satisfaction and device upgraders in key segments. Guidance signals a sequential margin uplift and record-setting December quarter revenue, with ongoing operating expense acceleration driven by increased artificial intelligence investment.
CEO Cook stated, ""We are incredibly excited about the strength we're seeing across our products and services and we expect the December quarter's revenue to be the best ever for the company and the best ever for iPhone. We are heading into the holiday season with a truly remarkable lineup.""
Supply constraints on iPhone 16 and 17 were explicitly cited as limiting device availability, with Cook noting, ""today, we are constrained on several 17 models. We're not predicting when the supply/demand will balance. We're obviously working very hard to achieve that because we want to get as many of these products out to the customers as possible. But today, I'm not going to predict.""
Apple introduced and began shipping private cloud compute servers from a new U.S. plant, directly supporting its AI capability ramp.
The company recorded a tariff cost increase, with the CFO projecting $1.4 billion for the December quarter and noting the mitigating effect of reduced China tariffs from 20% to 10%.
Industry glossary
Tariff-related costs
: Direct expenses associated with government-imposed import or export duties impacting product gross margin.
Installed base
: The total number of Apple devices actively in use by customers at a given time.
Private cloud compute (PCC)
: Apple’s internally deployed cloud infrastructure designed for processing AI and machine learning tasks in a private, controlled environment.
Upgraders
: Existing Apple customers who purchase a newer version of a device they already own, as specifically segmented and measured by the company.
Full Conference Call Transcript
Timothy Cook:
Thank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Today, Apple is proud to report $102.5 billion in revenue, up 8% from a year ago and a September quarter record. Services achieved an all-time revenue record of $28.8 billion, growing 15% from a year ago. EPS came in at $1.85 setting a September quarter record. We grew in the vast majority of markets we track and had September quarter revenue records in dozens of markets, including the U.S., Canada, Latin America, Western Europe, the Middle East, Japan, Korea and South Asia. We also set a September quarter revenue record in emerging markets and an all-time revenue record in India.
These results come at the close of an extraordinary year for Apple in which we achieved an all-time revenue record of $416 billion for the fiscal year. We set all-time revenue records in emerging and developed markets. We set an all-time revenue record for iPhone. And in Services, we achieved all-time records across every geographic segment. These results reflect the tremendous customer enthusiasm for Apple products and services as well as our deep commitment to innovation. We are incredibly excited about the strength we're seeing across our products and services and we expect the December quarter's revenue to be the best ever for the company and the best ever for iPhone.
We are heading into the holiday season with a truly remarkable lineup. That includes the biggest leap ever for iPhone, which has had a tremendous response from our users around the world. Our Apple Watch lineup is more capable than ever to giving users ways to take charge of their health like never before, through new features like hypertension notifications and sleep score. And the next level sound quality and active noise cancellation of AirPods Pro 3 are hitting all the right notes for our users.
In October, we also broke new ground and power-efficient performance with the uncomparably fast M5 chip, packed with neural accelerators in each GPU core to supercharge AI workflows. iPad Pro combines game-changing features in iPad OS 26 with the power of M5 to create our most capable iPad ever. At the same time, the M5 MacBook Pro raises the bar for what users can do with a laptop while the new M5 powered Apple Vision Pro opens up amazing possibilities on its infinite canvas. We also launched a beautiful new software design that creates a unified experience across all of our platforms for the very first time.
The design is crafted with a new material called liquid glass that brings fluidity, vitality and flexibility to our products. Along with the new design, we delivered powerful new features to enable users to do even more with their devices. That includes updates to the phone and messages apps in iOS 26 to help users stay connected, continuity enhancements in MAC to deliver an even more seamless experience across devices and a powerful new windowing system that fundamentally transforms the user experience in iPad OS 26. As we continue to expand our investment in AI, we're bringing intelligence to more of what people already love about our products and services, making every experience even more personal, capable and effortless.
At the heart of it all is Apple Silicon, and we were thrilled to launch new products powered by the A19 Pro chip and M5. These incredibly advanced chips make Apple products the very best place to experience the power of AI. With Apple Intelligence, we've introduced dozens of new features that are powerful, intuitive, private and deeply integrated into the things people do every day. Features like live translation, which help users communicate across languages in real time and visual intelligence, which opens new ways to learn about and explore the world. We also introduced Workout Buddy, a new experience that uses AI to provide personalized motivational insights based on a user's workout data and fitness history.
And these joined so many others from cleanup and photos and new image creation tools to powerful writing tools, we're also seeing developers take advantage of our own device foundation models to create entirely new experiences for users around the world. We're also excited for our more personalized Siri. We're making good progress on it. And as we've shared, we expect to release it next year.
Now let's take a closer look at the September quarter results across our lineup, starting with iPhone. iPhone set a revenue record for the September quarter at $49 billion, up 6% from a year ago, with growth in the vast majority of markets we track despite supply constraints we faced on several iPhone 16 and iPhone 17 models given strong demand. Redesigned from the inside out and powered by the outstanding A19 pro chip, the iPhone 17 Pro is by far the most powerful iPhone we've ever made, setting a whole new standard for the smartphone industry.
The iPhone 17 Pro also offers our best camera system ever with an all-new ADEX telephoto camera and look stunning with bold new finishes like COSMIC Orange. The iPhone Air introduces an incredibly breakthrough design and with a bigger and brighter display with promotion, the iPhone 17 is a fantastic upgrade packed with features users will love. In MAC, we had a strong September quarter with revenue of $8.7 billion, up 13% year-over-year driven by the strength of the MacBook Air. The MacBook Air enables users to get things done easily on the world's most popular laptop.
Mac mini users are loving how much performance is packed into our smallest Mac ever made while Mac Studio customers are pushing the envelope of what's possible with our most powerful Mac ever, and the latest 14-inch MacBook Pro unlocks incredible speed and next level performance with the all-new M5 chip, which delivers 3.5x faster AI performance than M4. Turning to iPad. Revenue was $7 billion for the September quarter. Last month, we released 1 of the most attention grabbing software updates we've had in years with iPad OS 26 and we recently gave iPad users even more to love with the launch of the incredible M5 iPad Pro, which offers an incredible boost in AI performance.
With an unmatched combination of power and versatility, the new iPad Pro makes every interaction delightful with its thin, light and portable design. In Wearables, Home and Accessories revenue was $9 billion. As I mentioned earlier, we were excited to unlock new possibilities for users with the launch of our newest Apple Watch lineup, making the world's most popular watch even better. That includes Apple Watch Ultra 3 with the largest display ever in an Apple watch, improved battery life and emergency SOS via satellite. Apple Watch Series 11 brings our users the most comprehensive set of health features yet. And Apple Watch SC3 delivers advanced capabilities at an incredible value.
AI and advanced machine learning are at the core of powerful health features like heart rate monitoring, fall detection, crash detection and more. With our latest Apple Watch lineup, we were proud to introduce hypertension notifications, developed using large-scale machine learning models. Hypertension is one of the leading risk factors for heart attack and stroke affecting more than 1 billion adults worldwide, and we expect to notify more than 1 million users of this life-threatening condition. We're also excited about sleep score, a simple, intuitive way to help users better understand their sleep quality and discover ways to improve it. That's something I'm sure we can all benefit from. Meanwhile, AirPods Pro 3 have been a huge hit.
You have to hear them to really understand just how remarkable they are. users and reviewers alike are praising their incredible sound quality and improved fit. They feature the world's best in-ear active noise cancellation, removing up to 2x as much noise as the previous generation. And with live translation powered by Apple Intelligence, AirPods deliver an incredibly new and exciting experience for users around the world. Turning to Services. As I mentioned earlier, revenue was $28.8 billion for the September quarter, 15% higher year-over-year and an all-time record. We saw double-digit growth in both developed and emerging markets and set new all-time records across advertising, App Store, cloud services, Music, payment services and video.
Apple TV celebrated a big night at this year's Emmy Awards with 22 wins. The studio led the night with 13 wins the most of any comedy series in Emmy's history. Severance topped all dramas with 8 wins, adding to the accolades for this landmark series. To date, Apple TV productions have now earned over 600 wins and 2,800 nominations in total, driven by powerful original storytelling. And we're excited for audiences to discover new productions like Pluribus and to catch returning favorites like slow horses and the morning show. And soon, Apple TV will be the destination for F1 fans across the U.S. on track Day, thanks to a new partnership with Formula One.
F1 is one of the most exciting and fastest-growing sports in the world. And starting next year, Apple TV will be the place for subscribers to follow every twist and turn of the new season. And in addition, F1, the movie, one of the year's biggest blockbusters will be coming to Apple TV on December 12. During the September quarter, we also marked the 10-year anniversary of Apple News. Apple News provides access to front page news from all around the world, putting hundreds of publications right at users' fingertips. Turning to retail. We're heading into our busiest time of year with our best ever lineup.
In the last few months, we've opened new stores in emerging markets like India and the UAE and new locations in the U.S. and China. I was also in Tokyo last month for the opening of the redesigned and reimagined Apple Ginza store and the energy among the crowd was truly remarkable. When it originally opened, it was our first store outside the United States, and so it was especially meaningful to come back to welcome customers to the beautiful new space.
Everywhere we operate, and in everything we do, we strive to give the best to our users while living by our values, whether that's building new accessibility features into our most recent software releases or advancing our environmental work by using even more recycled materials in our latest lineup or providing free educational programming to train and support American businesses with our new Apple Manufacturing Academy in Detroit. And we're continuing to invest in innovation and user experiences that will transform our future.
A great example is the work we're doing in the U.S. where we're committed to invest $600 billion over the next 4 years with a focus on innovation in strategic areas like advanced manufacturing, silicon engineering and artificial intelligence. These commitments build on our long-standing investments in America, while supporting more than 450,000 jobs with thousands of suppliers across all 50 states. We built a new factory in Houston for advanced AI service, for example, which just started shipping its first products off the line, and we're leading the creation of end-to-end silicon supply chain across the country.
In recent months, I've connected with developers, innovators, artists, entrepreneurs and so many others around the world, people passionate about innovation and all the things they can do with Apple products. Each one is another reminder of why we do what we do. We're driven to empower people to do more of the things that matter most to them and enrich their lives along the way. As we head into the holiday season with our most powerful lineup ever, I couldn't be more excited for what's to come. With that, I'll turn it over to Kevan.
Kevan Parekh:
Thanks, Tim, and good afternoon, everyone. Our revenue of $102.5 billion was up 8% year-over-year and is a new September quarter record. We set some temporal quarter records in the Americas, Europe, Japan and the rest of Asia Pacific and grew in the vast majority of markets we track. Products revenue was $73.7 billion, up 5% year-over-year, driven by growth across iPhone and MAC and reached a September quarter record. Thanks to our exceptional customer satisfaction and strong levels of loyalty, our installed base of active devices has reached another all-time high across all product categories and geographic segments. Services revenue was $28.8 billion, up 15% year-over-year and an all-time record.
The performance was broad-based, with double-digit growth in the vast majority of the markets we track and double-digit growth across most of our services categories. Company gross margin was 47.2%, above the high end of our guidance range and up 70 basis points sequentially, driven by favorable mix. This includes approximately $1.1 billion of tariff-related costs, which is in line with what we had estimated on our last call. Products gross margin was 36.2%, up 170 basis points sequentially driven by favorable mix. Services gross margin was 75.3%, down 30 basis points sequentially. Operating expenses landed at $15.9 billion, up 11% year-over-year, driven by increased investment in R&D.
These strong levels of business performance led to September quarter records for both net income and diluted earnings per share. Net income was $27.5 billion and diluted earnings per share was $1.85, up 13% year-over-year on an adjusted basis, excluding the onetime charge we recognized during the fourth quarter of 2024. Operating cash flow was also a September quarter record at $29.7 billion.
Now I'm going to provide some more details for each of our revenue categories. iPhone revenue was $49 billion, up 6% year-over-year, driven by the iPhone 16 family. iPhone grew in the vast majority of the markets we track with September quarter records in many emerging markets, including Latin America, the Middle East and South Asia and an all-time record in India. The iPhone active installed base grew to an all-time high, and we set a September quarter record for upgraders. According to the recent survey from World Panel, iPhone was a top-selling model in the U.S., Urban China, the U.K., France, Australia and Japan.
We continue to see very high levels of customer satisfaction in the U.S. at 98% as measured by 451 Research. Mac revenue was $8.7 billion, up 13% year-over-year, driven by MacBook Air. We grew in every geographic segment with strong double-digit growth in emerging markets. The Mac installed base reached another all-time high with nearly half of customers who purchased a Mac being new to the product. And the latest customer satisfaction for Mac in the U.S. was reported at 96%. iPad revenue was $7 billion, flat year-over-year. Keep in mind, we faced a difficult compare against the full quarter impact of the iPad Air and iPad Pro launch from last year, offset by the better-than-expected performance on the iPad.
The installed base reached an all-time high with a September quarter record for upgraders and over half of the customers who purchased an iPad during the quarter were new to the product. Based on the latest reports from 451 Research, customer satisfaction was 98% in the U.S. Wearables, Home and Accessories revenue was $9 billion, flat year-over-year. This was driven by growth on Watch and AirPods, offset by accessories, which was impacted by strong performance in the year ago quarter, driven by the iPad launches. Both the Apple Watch and AirPods installed bases reached new all-time highs.
Over half of the customers purchasing Apple Watch during the quarter were new to the product, and we also set a September record for upgraders an Apple Watch. And in the U.S., customer satisfaction was recently measured at 95%. Our services revenue reached an all-time high of $28.8 billion, up 15% year-over-year. We achieved all-time revenue records in the Americas, Europe, Japan and rest of Asia Pacific as well as a September quarter record in Greater China. The majority of categories saw a sequential acceleration. And as Tim mentioned, we set many all-time revenue records, including payment services, where we reached an all-time revenue record and saw a double-digit growth year-over-year on Apple Pay Active Users.
This strong momentum in the September quarter drove our total fiscal year services revenue to surpass $100 billion, up 14% year-over-year and our best ever. The growth of our installed base of active devices continues to offer us great opportunities for the future. Customer engagement across our services offerings also continue to grow both transacting and paid accounts reached new all-time highs, and we continue to improve the quality and expand the reach of our services offerings. From additional markets for Apple Pay, now available in nearly 90 countries, to AppleCare One, a great new way to cover multiple Apple products in a single plan. Turning to enterprise.
We are seeing an adoption of Apple products accelerate across industries to improve productivity and drive innovation. The BMW Group has been deploying tens of thousands of iPhones, including the factory employees to further strengthen its digital capabilities and advance innovation at the company. Capital One has expanded its Mac Choice program by adding thousands more MacBook Airs across its workforce. In the Czech Republic, its largest bank, [indiscernible], continues to invest in the Apple ecosystem with over 5,000 iPhones in addition to its existing thousands of iPads and Macs.
And Purdue University has launched a spatial computing hub built around Vision Pro, designed to help prepare students to lead the next wave of innovation in critical industries like semiconductor and pharmaceutical manufacturing. Let's turn to our cash position and capital return program. We ended the quarter with $132 billion in cash and marketable securities. We had $1.3 billion of debt maturities and decreased commercial paper by $1.9 billion, resulting in $99 billion in total debt. Therefore, at the end of the quarter, net cash was $34 billion. During the quarter, we returned $24 billion to shareholders. This included $3.9 billion in dividends and equivalents and $20 billion through open market repurchases of 89 million Apple shares.
Taking a step back, we are very pleased with our record fiscal year 2025 results. As Tim mentioned, total company revenue for the year was $416 billion with growth in iPhone, Mac, iPad and Services and all-time records in the vast majority of markets we track. This revenue performance led to very strong full year operating results with all-time records for net income and for diluted EPS, which grew double digits year-over-year on an adjusted basis. As we move ahead into the December quarter, I'd like to review our outlook, which includes the types of forward-looking information Suhasini referred to.
Importantly, the color we're providing assumes that the global tariff rates, policies and application remain in effect as of this call and the global macroeconomic outlook does not worsen from today. We expect our December quarter total company revenue to grow by 10% to 12% year-over-year, which will be our best quarter ever. We expect iPhone revenue to grow double digits year-over-year, which would be our best iPhone quarter ever. On Mac, keep in mind, we expect to face a very difficult compare against the M4 MacBook Pro, Mac Mini and iMac launches in the year ago quarter. We expect services revenue to grow at a year-over-year rate similar to what we reported in the fiscal year 2025.
We expect gross margin to be between 47% and 48%, which includes an estimated impact of $1.4 billion of tariff-related costs. And as we've said before, we are significantly increasing our investments in AI, while continuing to invest in our product road map. And so for the December quarter, we expect operating expenses to be between $18.1 billion and $18.5 billion. We expect OI&E to be around $150 million, excluding any potential impact from the mark-to-market of minority investments and our tax rate to be around 17%. Finally, today, our Board of Directors has declared a cash dividend of $0.26 per share of common stock payable on November 13, 2025, to shareholders of record as of November 10, 2025.
With that, let's open the call to questions.
Suhasini Chandramouli:
[Operator Instructions]
Operator, may we have the first question, please?
Operator:
Certainly, we will go ahead and take our first question from Erik Woodring with Morgan Stanley.
Erik Woodring:
Congrats on the results. Tim, can you maybe share a bit more detail on why you think the iPhone 17 is having the degree of success that it is at this point. And really, the question is, do you believe this is the aged installed base replacement cycle kicking in? Or are there specific features or functionality you believe stand out this cycle versus past cycles that consumers are really looking for? And then just a quick follow-up.
Timothy Cook:
Eric, thanks for your comments. I think it's all about the product. The product lineup is incredibly strong, our strongest ever. The 17 Pro is the most pro phone we've ever done. It's incredible in the design things. The iPhone air is -- feels so thin and so light in your hand, it feels like it's going to fly away. And then the 17 phone is an incredible value and takes several of the features that were reserved for Pro before and brings them down to the consumer lineup. So overall, strongest iPhone lineup ever, and it's resonating around the world.
Erik Woodring:
Great. And maybe a follow-up for you, Kevan. Can you maybe just discuss your approach to managing component cost inflation during this time, you're obviously increasing the memory content in your devices quite substantially at the same time. Memory prices are going through some pretty significant inflation. So just how are you managing through this cycle.
Kevan Parekh:
Erik, thanks for the question. Look, as you know, we've got a pretty incredible world-class procurement team as we're constantly finding ways to continue to drive cost opportunities. Right now on the commodity side, I would say we're seeing a slight tailwind on memory in storage prices and nothing really to note there. And as we saw from our gross margin performance, we landed in a pretty good spot above the high end of the guidance range we provided at 47.2%. And as well, we're guiding at 47% to 48%. So I think we're managing costs pretty well. As you'll recall, when we talked about this time in the cycle, we just launched a bunch of new products.
Those new products do have a slightly higher cost structure than the products they replace, but the team does a very good job of focusing our efforts on getting those costs down over time. And we feel pretty good about the performance we're seeing right now overall on material cost savings.
Suhasini Chandramouli:
Operator, can we get the next question, please?
Operator:
Our next question is from Ben Reitzes with Melius Research.
Benjamin Reitzes:
Tim, can you talk a little bit about iPhone in China specifically? How is that going to trend in the December quarter? And have you turned the corner there? And how do you think that trajectory is going? And then I have a quick follow-up.
Timothy Cook:
Yes. Ben, I was just there. It's incredibly vibrant and dynamic. The store traffic is up significantly year-over-year. The iPhone 17 has been -- the family has been very well received there. We do believe that we'll return to growth in Q1, and that is largely based on the reception of the iPhone there. And so I couldn't be more pleased with how things are going there in the early going.
Benjamin Reitzes:
All right. That's great. And then services, great upside there, a little surprising, right? We were a little worried about that one only a few quarters ago. I was wondering if there were any [indiscernible] payments in there or if the resolution that we saw with the antitrust ruling with one of your partners was a boost and if that played a role or if it was all really just organic outperformance with many of the things you mentioned.
Kevan Parekh:
Ben, it's Kevan here. Let me try to answer that question. You're referring -- I just wanted to clarify, when you're referring to the antitrust piece, you're talking about the Google trial? Is that what you're referring to?
Benjamin Reitzes:
Yes. Yes, sir.
Kevan Parekh:
Okay. Yes, there was no tax-related impact. And what I would say is our strong performance for the quarter is really organically driven. And again, just to reiterate, we had an all-time revenue record here for the quarter at $28.8 billion. And as well, we surpassed $100 billion, so best year ever at 14% year-on-year. So really that was all organic growth. As Tim outlined and I outlined in the prepared remarks, we saw a majority of the categories have sequential acceleration, and we had many all-time revenue records. But nothing abnormal at all, really pretty much all organic growth.
Suhasini Chandramouli:
Operator, could we get the next question, please?
Operator:
Our next question is from Michael Ng.
Michael Ng:
I just have two as well. First, just to follow up on the last one. the services revenue growth, I think, was the fastest across many categories and certainly the fastest in the last 2 years. I was just wondering if you could just unpack a little bit more of the drivers of the acceleration, was there kind of cross-selling with the new iPhone launch? Was it just installed base growth? I know you've been doing a lot of bundling with Apple One and Apple Care One. So any thoughts on that would be very helpful. And then I just have a quick follow-up.
Kevan Parekh:
Michael, it's Kevan. Thanks for the question. Yes, let me build on the answer there. I think that the way we look at it is not one thing to point to that would have driven this higher performance. You're right that it is slightly higher than we've seen in the last few quarters. But as you know, our services portfolio is very broad with a broad range of businesses, all that have different growth profiles and different performance characteristics. So those can vary in any given quarter. I would say our strength, again, was very broad-based, both across categories and also geographically. So I wouldn't point to any particular factor that drove any kind of outperformance at all.
We were just very pleased to see that result.
Michael Ng:
Great. And just on iPhone sell-through, I was wondering if you were seeing any notable shifts in trends between the sell-through coming from upgraders versus switchers? Is the U.S. carrier competitive dynamic helping at all in terms of promotional activity? And any thoughts on channel inventory.
Timothy Cook:
Okay. We did set a September quarter record for upgraders and so it was a great quarter from that point of view. It's really too early in the cycle on 17 to make any comments about upgraders or switchers. In terms of channel inventory, we ended the quarter toward the low end of the targeted range. Obviously, because we had constraints on several models of the 16 and 17. And for complete transparency and clarity, we're constrained today on several models of the iPhone 17. There's not a ramp issue. It's just we have very strong demand. And we're working very hard to fulfill all the orders that we have.
Suhasini Chandramouli:
Operator, could we get the next question, please.
Operator:
Our next question is from Amit Daryanani with Evercore.
Amit Daryanani:
I guess Kevan, maybe just start with gross margins. Can you just walk through the expectations for the December quarter. I think it implies up 30 basis points or so sequentially. Can you just talk about the puts and takes on gross margin given you do have very sizable operating leverage in the quarter. So just maybe what are the puts and takes around that would be really helpful.
Kevan Parekh:
Yes, sure. Amit, let me walk through the outlook. As we mentioned in our outlook, we are targeting a range of 47% to 48%. You take the midpoint of that range at 47.5%, you said it's roughly 25 basis points, 30 basis points higher. Really, there's a lot of puts and takes. As I talked about earlier, this is a quarter we launched a lot of new products. Those new products tend to have a higher cost structure than the products they replaced.
So there's definitely an impact from the cost side of thing, but that was more than offset by a favorable mix, especially on the product side as well as you outlined, we typically see higher leverage in this quarter. So I would say those are the 2 big drivers. And so the sequential increase is really going to be driven by favorable mix particularly from the product side.
Amit Daryanani:
Got it. And then if I just go back to the China discussion for a minute, the performance in China, at least in September quarter was a bit muted. Could you just talk about what resulted in the weakness over there? And do you think it was a bit more of a pause given iPhone Air, for example, I don't think was available until a few weeks ago. So just somewhat what drove the weakness in September? And is the uptick of that expectation for December there just from the iPhone Air coming out? Or are there other factors as well?
Timothy Cook:
Yes. The Greater China revenue was down 4% in the -- year-over-year in the September quarter. It was driven by iPhone and if you look at the iPhone, the majority of the sequential year-over-year change was due to supply constraints that I mentioned earlier. And so it was basically supply constraints that drove the results. We're thrilled with what we're seeing right now with traffic being up significantly year-over-year and the reception of the 17 family we expect to return to growth this quarter.
Suhasini Chandramouli:
Operator, could we have the next question, please?
Operator:
Our next question is from Wamsi Mohan with Bank of America.
Wamsi Mohan:
Tim, if I can follow up on your comments about the constrained supply in the quarter, just given the very strong demand for iPhones. Do you expect that as you can see your visibility across demand and supply, do you think that you will be exiting December at a point where you wouldn't be constrained anymore? Or do you still expect that there could be constraints as you exit the December quarter? And any way to quantify sort of what revenue could have been in this quarter without constraints?
Timothy Cook:
Yes. If you look at the supply constraints, today, we are constrained on several 17 models. We're not predicting when the supply/demand will balance. We're obviously working very hard to achieve that because we want to get as many of these products out to the customers as possible. But today, I'm not going to predict.
Wamsi Mohan:
Okay. Okay. And then as a follow-up, how do you talk about new records across a lot of categories and services. I didn't hear Search explicitly called out. So maybe it's a little bit of a follow-up to Ben's question, but given that there are some concerns around search volumes decelerating at the expense of AI. How do you think about the broader sustainability of these very strong mid-teens growth rates for services or an extended period of time, not just for next quarter where you're obviously guiding to [ 14 ].
Timothy Cook:
This is Tim. The advertising category, which is a combination of third-party and first-party did set a record during the quarter.
Wamsi Mohan:
Okay. And sorry, just to be clear, both Apple's own internal advertising and within the licensing individually set records?
Timothy Cook:
Actually I'm not saying that. I'm just saying that the combination of the 2 set of record. We don't -- I'm dodging the question intentionally because we don't split it at that level.
Suhasini Chandramouli:
Operator, could we get the next question, please?
Operator:
Our next question is from Samik Chatterjee with JPMorgan.
Samik Chatterjee:
Maybe for the first one, Tim, you talked about the strong momentum you're seeing in China, which is also driving your conference for the December quarter. Any thoughts on the role that the smartphone subsidies in that region are playing in this momentum? And how do you think about sort of what portion of consumers are maybe using some of those subsidies, leveraging the subsidies at this point? Any more insights into that? And I have a follow-up.
Timothy Cook:
Yes, the subsidies play a favorable role. The subsidies, as you know, are sort of across multiple categories from PCs to tablets, smart watches and smartphones. And however, it's important to note they only apply to certain price ranges. And so there's a maximum price, and there's several of our products that are -- that sell above that price and therefore, are not eligible for a subsidy, but it does have a favorable effect. And it's clearly and at least from our vantage point, driving some consumer demand.
Samik Chatterjee:
Okay. Got it. And a follow-up for Kevan here. On the OpEx increase going into the December quarter, a fairly sizable step-up. So if you could just dig into that number a bit more what are sort of the components towards what you're spending? And then that increase year-over-year in OpEx does sort of exceed your revenue growth. So is that sort of what we should expect on a going forward basis as well where you probably need to invest a bit more in the near future?
Kevan Parekh:
Yes, Samik, thanks for that question. As we've been outlining and reiterated in our last call, we are increasing our investments in AI. We're also continuing to invest in our product road map. So the vast majority of the increase to our operating expenses are driven by R&D. While we continue to manage the company in a thoughtful and disciplined way, we're also managing the business for the long term and are super excited about all the opportunities that we see ahead. As it relates to the question around OpEx and revenue growth, while OpEx has been growing at a faster rate than revenue, we have seen gross margin expansion.
And so when we look at that on a combined basis, it does allow us to have healthy operating leverage, and our operating income growth has been generally outpacing revenue growth for the past several years.
Suhasini Chandramouli:
Operator, could we get the next question, please?
Operator:
Our next question is from David Vogt with UBS.
David Vogt:
So maybe, Kevan, can I ask first. Can you help us understand sort of the tariff impact sequentially from the September quarter to the December quarter, particularly around iPhone supply constraints because I think I heard you say tariffs go from $1.1 billion to $1.4 billion, but the sequential uplift in iPhone revenue and presumably production given supply chain constraints is dramatically bigger. So you can help us understand how to think about the timing of those tariff headwinds as we move forward and sort of that correlation? And then I have a follow-up.
Timothy Cook:
David, I'll take this one. You're right, it goes from $1.1 billion to a projection of $1.4 billion. And the $1.4 billion is based on sort of what we know right now and where the tariff rates and policies and so forth are. So it assumes a stable kind of environment for the quarter. It does comprehend the change that was just made, which we're very encouraged to see with the tariffs moving from 20% to 10% in China. And so that is factored in. And that is one of the reasons why the it's not linear to volume, if you will. Does that make sense?
David Vogt:
No, that's helpful. That's what I was asking if the change is reflected in that outlook. And then just as a follow-up, when you think about -- I think on the Macs, I know people aren't asking about it, you talked about the tough comp, but you're going into sort of a holiday season, I understand that.
But when you think about the attached possibility for other products to the iPhone in the holiday season, how do we think about sort of where the consumers heads that and their wallet is at this point in the cycle and granted it is a tough comp, but is there an opportunity to see some maybe upside from an attach rate perspective given the strength in the iPhone portfolio?
Timothy Cook:
We always like to remind people that buy an iPhone, all the other things that we offer. And so you can bet that we're doing that. From a Mac point of view, the challenges that last year was sort of the mother of all Mac launches. All of these from Mac mini to iMac to all the Macbook Pros, all launched literally at the same time. And this year, that compares to launching the 14-inch MacBook Pro. And so there's a very difficult compare. Of course, in the long run, I'm very bullish on the Mac. And you can see that the Mac again last quarter outgrew the market.
And so we feel really well about how Mac is positioned, but this certain quarter is an extremely difficult compare.
Kevan Parekh:
Yes. And Tim, I'll add to that, that we also have the DRAM upgrades last year for the Mac lineup also is another factor.
Suhasini Chandramouli:
Operator, could we get the next question, please?
Operator:
Our next question is from Krish Sankar with TD Cowen.
Sreekrishnan Sankarnarayanan:
My first one is on the iPhone constraints. Is there a way to quantify how much this is you left on the table because of those constraints? And is the different iPhone manufacturing from 2 different regions contributing to the constraint? And then I have a follow-up for you.
Timothy Cook:
To be clear, the constraint was not related to manufacturing capacity per se. It was that we called the number of iPhone 16s that we were going to make, and we're a bit short of where the demand really was. So we could have sold more. We're not publicly at least estimating the extent of that. And then on iPhone 17 family, the demand is very strong. And so we obviously came out of the Q4 time frame with lots of back orders.
Sreekrishnan Sankarnarayanan:
Got it. And then a quick follow-up. Given like the prevalence of chatbots and now some of these AI-infused services, do you think that could change the consumer behavior on mobile app ecosystems or are you seeing any of that? And would that have any impact on your App Store?
Timothy Cook:
I think there are opportunities on the App Store with artificial intelligence. And so I think as we have made our on-device models available for developers, and we've seen developers begin to adopt them and so I think as you -- as that proliferates, there's an opportunity to -- for developers and for Apple to benefit from that from adding features to their apps and so forth.
Suhasini Chandramouli:
Operator, could we get the next question, please?
Operator:
Our next question is from Aaron Rakers with Wells Fargo.
Aaron Rakers:
I have two as well. I guess the first question is when we look at the iPhone 17 demand, which you've repeatedly highlighted is very strong. I'm curious if there's been any discernible kind of change in the mix within the iPhone 17 categories between the Pro and the Pro Max versions relative to prior cycles?
Timothy Cook:
It's really too early to call the mix, to be honest. And we don't like to publicly disclose that because of -- for competitive reasons. But frankly, we don't really know what the mix will be yet because we have constraints on both sides of the ledger at the top and at the entry. And so we'll see what happens as we get more supply.
Aaron Rakers:
Yes. And then as a quick follow-up. I'm curious, as we kind of work through kind of the AI narrative that continues to build. Is there -- could you provide any kind of updated thoughts around the build-out of Apple's private compute cloud and how we should think about that kind of as we look forward?
Timothy Cook:
Yes. We're obviously using PCC, our private cloud compute today for a number of queries for Siri, and we will continue to build it out. In fact, the manufacturing plant that makes the servers used for Apple Intelligence just started manufacturing in Houston a few weeks ago, and we've got a ramp plan there for use in our data centers and it's robust.
Kevan Parekh:
Yes. Aaron, I'll add maybe there are two since you asked a question about private cloud compute that we -- in '25, we did have CapEx costs associated with building out our private cloud compute environment in our first-party data centers. So you would have seen that in some of the CapEx investment in the year.
Suhasini Chandramouli:
Operator, can we get the next question, please?
Operator:
Our next question is from Atif Malik with Citi.
Atif Malik:
Great execution. The first question is on iPhone Air. Does the consumer reception and iPhone Air gives you a feel on perhaps the foldable corn market? Or are the 2 form factors very different?
Timothy Cook:
I'm not sure that one is a proxy for the other. The thing that I would say is that where we don't get into the model kind of demand. At the aggregate level, we are thrilled with how iPhone has been received, and that's the reason that we're expecting double-digit growth in the current quarter.
Atif Malik:
Great. And Tim, as a follow-up, good to know that the personalized Siri is making good progress and on track for next year. Will you continue to use a 3-pronged approach with your own foundation models and partner with other LLM providers and maybe potential M&A? Or is one strategy more emphasized over another?
Timothy Cook:
We're obviously creating Apple Foundation models within Apple. We ship them on device and use them in the private cloud compute as well. And we've got several in development. And so we also, from a continually to surveil the market on M&A and are open to pursuing M&A if we think that it will advance our road map.
Suhasini Chandramouli:
Operator, can we get our last question, please?
Operator:
Our last question is from Richard Kramer with Arete Research.
Richard Kramer:
Tim, we've often seen Apple be a fast follower with iPhone and new technology, whether large displays or 4G or 5G. But with all the height now around AI, are you seeing evidence that AI capabilities or features are a material purchase consideration for consumers or the record sales levels you're reporting simply reflecting other factors like the retention of your iOS space?
Timothy Cook:
I think that there are many factors that influence people's purchasing considerations. And so -- and we don't have a great in-depth survey yet on the current iPhone 17 because it's very new in the cycle, and we give it some time to formulate. But I would say that Apple Intelligence is a factor. And we're very bullish on it becoming a greater factor and so that's the way that we look at it.
Richard Kramer:
Okay. And then one for Kevan. In the wake of nearly every other large tech company massively increasing their CapEx in advance of AI demand and also mentioning that there's scarce capacity, do you anticipate Apple altering its sort of long-standing hybrid approach to your own and third-party data centers? And maybe can you talk a little bit about the role you see for Apple silicon with the new M5 series of chipsets?
Kevan Parekh:
Richard, thanks for the question. In general, I think as we've talked about before, we are expecting increases in our CapEx spending related to AI investments. For example, as I mentioned earlier, we did end up having investments this year to build out our private cloud compute environment. And we do believe this hybrid model has served us very well, and we continue to want to leverage it. And so I don't see us moving away from this hybrid model where we leverage both first-party capacity as well as leverage third-party capacity. We'll continue to want to build out private cloud compute, as Tim outlined, as we have more usage there over time.
But I think in general, we want to continue to have this hybrid model.
Suhasini Chandramouli:
A replay of today's call will be available for 2 weeks on Apple podcast as a webcast on apple.com/investor and via telephone. The number for the telephone replay is (866) 583-1035. Please enter confirmation code 0689794 followed by the pound sign. These replays will be available by approximately 05:00 p.m. Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at (408) 862-1142. And financial analysts can contact me, Suhasini Chandramouli with additional questions at (408) 974-3123. Thanks again for joining us.
Operator:
Once again, this does conclude today's conference. We do appreciate your participation."
